# ==============================================================
# â˜• Coffee ERP Dashboard â€” Company Showcase Edition (Tone-Down Blue)
# (ê¸°ì¡´ ì£¼ì„ ìƒëµ)
# ==============================================================

import os
import json
import re
import warnings
from math import ceil
from pathlib import Path
from datetime import datetime
import time # #[AI/ML í†µí•© ì¶”ê°€] (Mock ì‘ë‹µìš©)

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.io as pio
from datetime import datetime, timedelta
import plotly.graph_objects as go
import textwrap

import firebase_admin
from firebase_admin import credentials, firestore

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1 (AI ë¹„ì„œ) ë° SPRINT 2 (ìˆ˜ìš” ì˜ˆì¸¡) ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import openai
    import time
    from prophet import Prophet
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_absolute_percentage_error
except ImportError:
    st.error("""
    AI/ML ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.
    í„°ë¯¸ë„ì—ì„œ 'pip install openai prophet scikit-learn'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
    """)
    st.stop()
# === [AI/ML í†µí•© ì¶”ê°€] ===
# === [ë¹ˆí‹ˆ ìˆ˜ì •] ëˆ„ë½ëœ í•µì‹¬ ë„ìš°ë¯¸ í•¨ìˆ˜ (format_krw, safe_rerun) ===
def format_krw(x: float) -> str:
    """ìˆ«ìë¥¼ ì›í™” í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        return f"{x:,.0f} ì›"
    except Exception:
        return "-"

def safe_rerun():
    """Streamlit ë²„ì „ì— ë§ì¶° ì•±ì„ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤."""
    try:
        if hasattr(st, "rerun"):
            st.rerun()
        elif hasattr(st, "experimental_rerun"):
            st.experimental_rerun()
    except Exception as e:
        # (ìƒˆë¡œê³ ì¹¨ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ)
        pass
# ===================================================================


st.set_page_config(page_title="â˜• Coffee ERP Dashboard", layout="wide")


# (init_firebase í•¨ìˆ˜ ì›ë³¸)
def init_firebase():
    try:
        if "GOOGLE_APPLICATION_CREDENTIALS_JSON" in os.environ:
            cred_info = json.loads(os.environ["GOOGLE_APPLICATION_CREDENTIALS_JSON"])
            cred = credentials.Certificate(cred_info)
            if not firebase_admin._apps:
                firebase_admin.initialize_app(cred)
            return firestore.client(), "success"
        else:
            return None, "no_env"
    except Exception as e:
        return None, f"error: {e}"

# âœ… í•¨ìˆ˜ í˜¸ì¶œ í›„ UI í‘œì‹œ ë¶„ë¦¬
db, fb_status = init_firebase()

# --- Pylance/static analyzer guards (no runtime effect) ---
items = []  # type: ignore
sold_qty = 0  # type: ignore
summary = []  # type: ignore

# ----------------------
# 0ï¸âƒ£ ê²½ë¡œ/ìƒìˆ˜ (íŒ€ì›ì´ ì–´ë””ì„œ ë°›ì•„ë„ ë™ì‘)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
BASE_DIR = Path(__file__).resolve().parent

try:
    SECRETS = dict(st.secrets)
except Exception:
    SECRETS = {}

def _resolve_path(val, default: Path) -> Path:
    if not val:
        return default
    p = Path(str(val))
    return p if p.is_absolute() else (BASE_DIR / p)

DATA_DIR   = _resolve_path(SECRETS.get("DATA_DIR")   or os.environ.get("ERP_DATA_DIR"),   BASE_DIR / "data")
ASSETS_DIR = _resolve_path(SECRETS.get("ASSETS_DIR") or os.environ.get("ERP_ASSETS_DIR"), BASE_DIR / "assets")
KEYS_DIR   = _resolve_path(SECRETS.get("KEYS_DIR")   or os.environ.get("ERP_KEYS_DIR"),   BASE_DIR / "keys")

CSV_PATH     = DATA_DIR / "ë°ì´í„° ì¦ê°•.csv"
CSV_AUGMENTED_PATH = DATA_DIR / "ë°ì´í„° ì¦ê°•.csv"
CSV_PRODUCT_STATUS_PATH = DATA_DIR / "ìƒí’ˆë§¤ì¶œí˜„í™©.csv"
CSV_HOURLY_PATH = DATA_DIR / "ì‹œê°„ëŒ€ë³„ ë§¤ì¶œë¶„ì„.csv"
CSV_TOP5_PATH = DATA_DIR / "ì¹´í”¼ì—”ë“œ_ì»¤í”¼_Top5.csv"
PIPELINE_IMG = ASSETS_DIR / "pipeline_diagram.png"
SA_FILE_PATH = KEYS_DIR / "serviceAccount.json"

SALES_COLLECTION      = "coffee_sales"
INVENTORY_COLLECTION  = "inventory"
ORDERS_COLLECTION     = "orders"
SKU_PARAMS_COLLECTION = "sku_params"

RECIPES_COLLECTION      = "recipes"
STOCK_COUNTS_COLLECTION = "stock_counts"
STOCK_MOVES_COLLECTION  = "stock_moves"

USE_KRW_CONVERSION = True
KRW_PER_USD = 1350
DEFAULT_INITIAL_STOCK   = 10000
REORDER_THRESHOLD_RATIO = 0.15
SEED_INGREDIENTS = [
    {"ko": "ì—ìŠ¤í”„ë ˆì†Œ", "uom": "g"},
    {"ko": "í—¤ì´ì¦ ì‹œëŸ½", "uom": "g"},
    {"ko": "ë¬¼", "uom": "ml"},
    {"ko": "ì–¼ìŒ", "uom": "g"},
    {"ko": "ìš°ìœ ", "uom": "ml"},
    {"ko": "ì—°ìœ ", "uom": "g"},
    {"ko": "ë¹…íŠ¸ë ˆì¸ ë°”ë‹ë¼ íŒŒìš°ë”", "uom": "g"},
    {"ko": "ë°”ë‹ë¼ë¹ˆ ì‹œëŸ½", "uom": "g"},
    {"ko": "ì„¤íƒ• ì‹œëŸ½", "uom": "ml"},
]
SEED_MENUS = [
    "í—¤ì´ì¦ ì•„ë©”I",
    "ì¹´í˜ë¼ë–¼I",
    "ëŒì²´ë¼ë–¼I",
    "ë°”ë‹ë¼ë¹ˆë¼ë–¼I",
    "ì‚¬ì¼€ë¼ë˜I",
]


for p in (DATA_DIR, ASSETS_DIR, KEYS_DIR):
    p.mkdir(parents=True, exist_ok=True)

def safe_doc_id(name: str) -> str:
    """Firestore ë¬¸ì„œ IDì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ìœ„í—˜ ë¬¸ìë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    if not name:
        return "unknown"
    return re.sub(r"[/.#\\?\s]+", "_", str(name)).strip("_") or "unknown"


# ----------------------
# 0-1ï¸âƒ£ Firebase ì´ˆê¸°í™” (Secrets â†’ keys/ â†’ GOOGLE_APPLICATION_CREDENTIALS)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_resource
def init_firestore():
    """Firebase ì¸ì¦ ë° Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€ + ìºì‹œ ì ìš©)"""
    if firebase_admin._apps:
        return firestore.client()
    svc_dict = SECRETS.get("firebase_service_account")
    if isinstance(svc_dict, dict) and svc_dict:
        cred = credentials.Certificate(svc_dict)
        firebase_admin.initialize_app(cred)
        return firestore.client()
    if SA_FILE_PATH.exists():
        cred = credentials.Certificate(str(SA_FILE_PATH))
        firebase_admin.initialize_app(cred)
        return firestore.client()
    gac = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if gac and Path(gac).expanduser().exists():
        firebase_admin.initialize_app()
        return firestore.client()
    st.error(
        "Firebase ìê²©ì¦ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:\n"
        "â€¢ st.secrets['firebase_service_account'] ë”•ì…”ë„ˆë¦¬\n"
        "â€¢ keys/serviceAccount.json íŒŒì¼\n"
        "â€¢ í™˜ê²½ë³€ìˆ˜ GOOGLE_APPLICATION_CREDENTIALS=ìê²©ì¦ëª…íŒŒì¼ê²½ë¡œ"
    )
    st.stop()


db = init_firestore()

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í‚¤ ì„¤ì •
try:
    openai.api_key = st.secrets["openai"]["api_key"]
except (KeyError, AttributeError):
    st.warning("""
    OpenAI API í‚¤ê°€ 'secrets.toml'ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 
    AI ë¹„ì„œ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šê±°ë‚˜ Mock ë°ì´í„°ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
    [.streamlit/secrets.toml] íŒŒì¼ì— [openai] api_key = "sk-..."ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
    """)
    openai.api_key = None # í‚¤ê°€ ì—†ì–´ë„ ì•±ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡
# === [AI/ML í†µí•© ì¶”ê°€] ===

# ----------------------
# 0-2ï¸âƒ£ UI/ìŠ¤íƒ€ì¼
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
pio.templates.default = "plotly_white"
px.defaults.template = "plotly_white"
px.defaults.color_continuous_scale = "Blues"

st.markdown("""
    <style>
    /* ... (ê¸°ì¡´ ìŠ¤íƒ€ì¼ ì •ì˜) ... */
    </style>
""", unsafe_allow_html=True)


st.markdown("""
<div class="dashboard-header">
  <h1>â˜• Coffee ERP Dashboard</h1>
</div>
""", unsafe_allow_html=True)

# ----------------------
# 0-3ï¸âƒ£ í•œê¸€ ë§¤í•‘ í…Œì´ë¸”
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
category_map = {
    "Coffee": "ì»¤í”¼", "Tea": "ì°¨", "Bakery": "ë² ì´ì»¤ë¦¬",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Packaged Chocolate": "í¬ì¥ ì´ˆì½œë¦¿",
}
rev_category_map = {v: k for k, v in category_map.items()}
rev_category_map.update({
    "ë² ì´ì»¤ë¦¬": "Bakery",
    # ... (ê¸°ì¡´ ì—­ ë§¤í•‘) ...
    "ì»¤í”¼": "Coffee",
})

type_map = {
    "Barista Espresso": "ë°”ë¦¬ìŠ¤íƒ€ ì—ìŠ¤í”„ë ˆì†Œ",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Premium Brewed Coffee": "í”„ë¦¬ë¯¸ì—„ ë¸Œë£¨ë“œ ì»¤í”¼",
}
rev_type_map = {v: k for k, v in type_map.items()}

SIZE_SUFFIX_MAP = {"Lg": "ë¼ì§€", "Rg": "ë ˆê·¤ëŸ¬", "Sm": "ìŠ¤ëª°"}
REV_SIZE_SUFFIX_MAP = {"ë¼ì§€": "Lg", "ë ˆê·¤ëŸ¬": "Rg", "ìŠ¤ëª°": "Sm"}

detail_base_map = {
    "Almond Croissant": "ì•„ëª¬ë“œ í¬ë£¨ì•„ìƒ",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Traditional Blend Chai": "íŠ¸ë˜ë””ì…”ë„ ë¸”ë Œë“œ ì°¨ì´",
}
rev_detail_base_map = {v: k for k, v in detail_base_map.items()}

def to_korean_detail(name: str) -> str:
    s = str(name).strip()
    if re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s):
        return s
    m = re.search(r"\s+(Lg|Rg|Sm)$", s)
    size_en = m.group(1) if m else None
    base_en = s[: -len(size_en) - 1] if size_en else s
    base_ko = detail_base_map.get(base_en, base_en)
    if size_en:
        return f"{base_ko} ({SIZE_SUFFIX_MAP[size_en]})"
    return base_ko

def from_korean_detail(display: str) -> str:
    s = str(display).strip()
    if re.search(r"\s+(Lg|Rg|Sm)$", s):
        return s
    m = re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s)
    size_ko = m.group(1) if m else None
    base_ko = re.sub(r"\s*\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", "", s)
    base_en = rev_detail_base_map.get(base_ko, base_ko)
    if size_ko:
        return f"{base_en} {REV_SIZE_SUFFIX_MAP[size_ko]}"
    return base_en

weekday_map = {"Monday": "ì›”", "Tuesday": "í™”", "Wednesday": "ìˆ˜",
               "Thursday": "ëª©", "Friday": "ê¸ˆ", "Saturday": "í† ", "Sunday": "ì¼"}
weekday_order_kr = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]

def map_series(s: pd.Series, mapping: dict) -> pd.Series:
    return s.apply(lambda x: mapping.get(x, x))

# ----------------------
# âœ… UoM(ë‹¨ìœ„) ìœ í‹¸
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def normalize_uom(u: str | None) -> str:
    u = (u or "ea").strip().lower()
    if u in {"g", "gram", "grams", "ê·¸ë¨", "kg", "í‚¬ë¡œê·¸ë¨"}:
        return "g"
    if u in {"ml", "ë°€ë¦¬ë¦¬í„°", "l", "ë¦¬í„°"}:
        return "ml"
    return "ea"

def convert_qty(qty: float, from_uom: str, to_uom: str) -> float:
    fu = normalize_uom(from_uom)
    tu = normalize_uom(to_uom)
    if fu == tu:
        return float(qty)
    return float(qty)

def safe_float(x, default=0.0):
    if x is None:
        return default
    try:
        if isinstance(x, (int, float)):
            try:
                if pd.isna(x):
                    return default
            except Exception:
                pass
            return float(x)
        if isinstance(x, str):
            s = x.strip()
            if s == "" or s.lower() in {"nan", "none"}:
                return default
            s = s.replace(",", "")
            return float(s)
        return float(x)
    except Exception:
        return default

# ----------------------
# âœ… ë‚ ì§œ íŒŒì„œ: ëª…ì‹œ í˜•ì‹ ìš°ì„  + ê²½ê³ ì—†ëŠ” í´ë°±
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def parse_mixed_dates(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip()
    out = pd.Series(pd.NaT, index=s.index, dtype="datetime64[ns]")
    patterns = [
        (r'^\d{4}-\d{2}-\d{2}$', '%Y-%m-%d'),
        (r'^\d{4}/\d{2}/\d{2}$', '%Y/%m/%d'),
        (r'^\d{2}/\d{2}/\d{4}$', '%m/%d/%Y'),
        (r'^\d{2}-\d{2}-\d{4}$', '%m-%d-%Y'),
        (r'^\d{4}\.\d{2}\.\d{2}$', '%Y.%m.%d'),
        (r'^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}$', '%Y-%m-%d %H:%M:%S'),
        (r'^\d{2}/\d{2}/\d{4}\s+\d{2}:\d{2}:\d{2}$', '%m/%d/%Y %H:%M:%S'),
    ]
    for pat, fmt in patterns:
        mask = s.str.match(pat)
        if mask.any():
            out.loc[mask] = pd.to_datetime(s.loc[mask], format=fmt, errors='coerce')
    remain = out.isna()
    if remain.any():
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", UserWarning)
            out.loc[remain] = pd.to_datetime(s.loc[remain], errors='coerce')
    return out

# ----------------------
# 1ï¸âƒ£ CSV ë¡œë“œ (ìƒ˜í”Œ ìƒì„± ì—†ìŒ)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_data(ttl=3600) 
def load_csv_FINAL(path: Path): # [Pylance ì˜¤ë¥˜] íƒ€ì… íŒíŠ¸ ì œê±°
    """
    ì¦ê°•/í˜„ì¥ CSV(`ë°ì´í„° ì¦ê°•.csv`)ë¥¼ ë¡œë“œí•˜ê³  ìˆ˜ìµ ì»¬ëŸ¼ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì˜ˆìƒ ìŠ¤í‚¤ë§ˆ: timestamp, menu_item, price, day_of_week, hour, day_type (+optional quantity, category)
    """
    if not path.exists():
        st.error(f"CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {path})")
        st.stop()
    
    start_time = time.time()
    df_raw = pd.read_csv(path)

    required_cols = {'timestamp', 'menu_item', 'price'}
    if not required_cols.issubset(df_raw.columns):
        st.error(f"CSV ìŠ¤í‚¤ë§ˆê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. í•„ìˆ˜ ì»¬ëŸ¼: {required_cols}")
        st.stop()

    df = df_raw.copy()
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    df['ë‚ ì§œ'] = df['timestamp'].dt.normalize()
    df['ì‹œê°„'] = df['timestamp'].dt.strftime('%H:%M:%S')

    hour_series = df_raw['hour'] if 'hour' in df_raw.columns else df['timestamp'].dt.hour
    df['ì‹œ'] = pd.to_numeric(hour_series, errors='coerce')

    qty_series = df_raw['quantity'] if 'quantity' in df_raw.columns else pd.Series(1, index=df.index)
    df['ìˆ˜ëŸ‰'] = pd.to_numeric(qty_series, errors='coerce').fillna(1)
    df['ë‹¨ê°€'] = pd.to_numeric(df_raw['price'], errors='coerce')
    df['ìˆ˜ìµ'] = df['ìˆ˜ëŸ‰'] * df['ë‹¨ê°€']

    menu_series = df_raw['menu_item'] if 'menu_item' in df_raw.columns else pd.Series("ë¯¸í™•ì¸ ë©”ë‰´", index=df.index)
    df['ìƒí’ˆìƒì„¸'] = menu_series.fillna("ë¯¸í™•ì¸ ë©”ë‰´")

    type_series = df_raw['menu_item'] if 'menu_item' in df_raw.columns else pd.Series("ê¸°íƒ€", index=df.index)
    df['ìƒí’ˆíƒ€ì…'] = type_series.fillna("ê¸°íƒ€")

    category_series = df_raw['menu_item'] if 'menu_item' in df_raw.columns else pd.Series("ê¸°íƒ€", index=df.index)
    df['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = category_series.fillna("ê¸°íƒ€")

    dow_series = df_raw['day_of_week'] if 'day_of_week' in df_raw.columns else df['ë‚ ì§œ'].dt.day_name()
    df['ìš”ì¼'] = pd.Series(dow_series).fillna(df['ë‚ ì§œ'].dt.day_name())
    df['ì›”'] = df['ë‚ ì§œ'].dt.month

    df['ê±°ë˜ë²ˆí˜¸'] = df.index + 1
    df['ê°€ê²ŒID'] = "LOCAL"
    df['ê°€ê²Œìœ„ì¹˜'] = "ì¦ê°•ë°ì´í„°"

    df = df.dropna(subset=['ë‚ ì§œ', 'ìˆ˜ìµ'])
    
    end_time = time.time()
    load_time = end_time - start_time
    row_count_final = len(df)
    
    return df, load_time, row_count_final

df_csv, load_time, row_count = load_csv_FINAL(CSV_PATH)


@st.cache_data(ttl=600)
def load_augmented_sales(path: Path = CSV_AUGMENTED_PATH):
    """ë°ì´í„° ì¦ê°• CSVë¥¼ ë¡œë“œí•´ ê°„ë‹¨í•œ ë³€í™˜ ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤."""
    if not path.exists():
        return None
    df = pd.read_csv(path)
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    df['price'] = pd.to_numeric(df['price'], errors='coerce')
    df['hour'] = pd.to_numeric(df.get('hour'), errors='coerce')
    df['date'] = df['timestamp'].dt.date
    return df


@st.cache_data(ttl=600)
def load_product_status(path: Path = CSV_PRODUCT_STATUS_PATH):
    """ìƒí’ˆë§¤ì¶œí˜„í™© CSVë¥¼ ë¡œë“œí•´ ìˆ«ì í•„ë“œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
    if not path.exists():
        return None
    df = pd.read_csv(path)
    df = df.rename(columns={
        'ìƒ í’ˆ ëª…': 'ìƒí’ˆëª…',
        'ìƒ í’ˆ ì½” ë“œ': 'ìƒí’ˆì½”ë“œ',
        'ìˆ˜    ëŸ‰': 'ìˆ˜ëŸ‰'
    })
    num_cols = ['ìˆ˜ëŸ‰', 'ì ìœ ìœ¨(ìˆ˜ëŸ‰)', 'íŒë§¤ê¸ˆì•¡', 'ì ìœ ìœ¨(ê¸ˆì•¡)']
    for col in num_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(
                df[col].astype(str).str.replace(',', '').str.replace('%', ''),
                errors='coerce'
            )
    return df


@st.cache_data(ttl=600)
def load_hourly_sales(path: Path = CSV_HOURLY_PATH):
    """ì‹œê°„ëŒ€ë³„ ë§¤ì¶œë¶„ì„ CSVë¥¼ ë¡œë“œí•´ ìˆ«ì í•„ë“œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
    if not path.exists():
        return None
    df = pd.read_csv(path)
    df = df.rename(columns={'ì‹œê°„': 'hour'})
    for col in df.columns:
        if col == 'hour':
            df[col] = pd.to_numeric(df[col], errors='coerce')
        else:
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce')
    return df


@st.cache_data(ttl=600)
def load_top5_recipe(path: Path = CSV_TOP5_PATH):
    """ì¹´í”¼ì—”ë“œ Top5 ë ˆì‹œí”¼ CSV ë¡œë“œ."""
    if not path.exists():
        return None
    df = pd.read_csv(path)
    num_cols = ['ë‹¨ê°€(ì›)', 'ìˆ˜ëŸ‰', 'ê°œë³„ê°€', 'ì‚¬ìš©ëŸ‰', 'ì‚¬ìš© ë‹¨ê°€', 'ì‚¬ìš©ë‹¨ê°€ í•©ê³„', 'íŒë§¤ê°€ê²©', 'ì›ê°€ìœ¨']
    for col in num_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce')
    return df


def build_recipes_from_top5(df_top: pd.DataFrame) -> dict:
    """ì¹´í”¼ì—”ë“œ Top5 CSVë¥¼ ë ˆì‹œí”¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
    if df_top is None or df_top.empty:
        return {}
    df = df_top.copy()
    df['ë©” ë‰´'] = df['ë©” ë‰´'].ffill()
    df['í’ˆ ëª©'] = df['í’ˆ ëª©'].ffill()
    df = df.dropna(subset=['ë©” ë‰´', 'í’ˆ ëª©'])
    df['ì‚¬ìš©ëŸ‰'] = pd.to_numeric(df.get('ì‚¬ìš©ëŸ‰'), errors='coerce')
    recipe_map: dict[str, list[dict]] = {}
    for _, row in df.iterrows():
        menu_kr = str(row.get('ë©” ë‰´', '')).strip()
        ing_kr = str(row.get('í’ˆ ëª©', '')).strip()
        qty = safe_float(row.get('ì‚¬ìš©ëŸ‰', 0))
        uom_raw = str(row.get('ë‹¨ìœ„', '')).strip()
        # ë‹¨ìœ„ ë¬¸ìì—´ì—ì„œ ì•ŒíŒŒë²³ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì˜ˆ: "40g" -> "g")
        uom_match = re.search(r'([a-zA-Z]+)', uom_raw)
        uom = uom_match.group(1) if uom_match else 'ea'
        if not menu_kr or not ing_kr or qty <= 0:
            continue
        menu_en = from_korean_detail(menu_kr)
        ing_en = from_korean_detail(ing_kr)
        recipe_map.setdefault(menu_en, []).append({
            "ingredient_en": ing_en,
            "qty": qty,
            "uom": normalize_uom(uom),
            "waste_pct": 0.0,
        })
    return recipe_map


def build_top5_cost_map(df_top: pd.DataFrame) -> dict:
    """Top5 CSVì—ì„œ ì¬ë£Œë³„ ë‹¨ìœ„ ì›ê°€ fallback ë§µì„ ìƒì„±."""
    if df_top is None or df_top.empty:
        return {}
    df = df_top.copy()
    df['í’ˆ ëª©'] = df['í’ˆ ëª©'].ffill()
    df = df.dropna(subset=['í’ˆ ëª©'])
    df['ì‚¬ìš©ëŸ‰'] = pd.to_numeric(df.get('ì‚¬ìš©ëŸ‰'), errors='coerce')
    df['ì‚¬ìš© ë‹¨ê°€'] = pd.to_numeric(df.get('ì‚¬ìš© ë‹¨ê°€'), errors='coerce')
    cost_map = {}
    for _, row in df.iterrows():
        ing_kr = str(row.get('í’ˆ ëª©', '')).strip()
        qty = safe_float(row.get('ì‚¬ìš©ëŸ‰', 0))
        use_cost = safe_float(row.get('ì‚¬ìš© ë‹¨ê°€', 0))
        uom_raw = str(row.get('ë‹¨ìœ„', '')).strip()
        uom_match = re.search(r'([a-zA-Z]+)', uom_raw)
        uom = uom_match.group(1) if uom_match else 'ea'
        if not ing_kr or qty <= 0 or use_cost <= 0:
            continue
        ing_en = from_korean_detail(ing_kr)
        # ì‚¬ìš© ë‹¨ê°€ë¥¼ ì‚¬ìš©ëŸ‰ìœ¼ë¡œ ë‚˜ëˆ  ë‹¨ìœ„ë‹¹ ì›ê°€ ì¶”ì •
        unit_cost_est = use_cost / qty if qty else 0
        cost_map[ing_en] = {
            "unit_cost": unit_cost_est,
            "uom": normalize_uom(uom),
            "use_qty": qty,
            "use_cost": use_cost,
        }
    return cost_map


@st.cache_data(ttl=3600)
def run_prophet_backtesting(df_input, test_days=30): # [Pylance ì˜¤ë¥˜] íƒ€ì… íŒíŠ¸ ì œê±°
    """
    'ì˜ˆì¸¡'ì´ ì•„ë‹Œ 'ì—°êµ¬ ê²€ì¦'ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    if df_input is None or df_input.empty:
        return None, None, "ì˜¤ë¥˜: ì…ë ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
    # 1. ë°ì´í„° ì „ì²˜ë¦¬ (Prophet í˜•ì‹: ds, y)
    if 'ìˆ˜ìµ' not in df_input.columns or 'ë‚ ì§œ' not in df_input.columns:
        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: ë°±í…ŒìŠ¤íŒ…ì— í•„ìš”í•œ 'ë‚ ì§œ' ë˜ëŠ” 'ìˆ˜ìµ' ì»¬ëŸ¼ì´ dfì— ì—†ìŠµë‹ˆë‹¤.")
        return None, None, "ë°ì´í„° ì»¬ëŸ¼ëª… ì˜¤ë¥˜"
        
    df_prophet = df_input[['ë‚ ì§œ', 'ìˆ˜ìµ']].copy()
    
    df_prophet = df_prophet.rename(columns={'ë‚ ì§œ': 'ds', 'ìˆ˜ìµ': 'y'})
    df_prophet = df_prophet.groupby('ds').sum().reset_index()
    total_points = len(df_prophet)

    if total_points < 5:
        return None, None, "ë°ì´í„° í¬ì¸íŠ¸ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤."

    max_test_days = max(1, total_points - 10)
    if max_test_days < 3:
        return None, None, "ê²€ì¦í•  ë§Œí¼ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    effective_test_days = min(test_days, max_test_days)

    # 2. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    split_date = df_prophet['ds'].max() - pd.to_timedelta(effective_test_days, 'D')
    train_data = df_prophet[df_prophet['ds'] <= split_date]
    test_data = df_prophet[df_prophet['ds'] > split_date]

    if len(train_data) < 10:
        return None, None, "ì˜¤ë¥˜: í›ˆë ¨ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤."

    # 3. ëª¨ë¸ í›ˆë ¨ (ë°ì´í„° ê¸°ê°„ì´ ì§§ìœ¼ë¯€ë¡œ yearly_seasonality=False)
    m = Prophet(daily_seasonality=True, yearly_seasonality=False, weekly_seasonality=True)
    m.fit(train_data)

    # 4. ì˜ˆì¸¡
    future_frame = m.make_future_dataframe(periods=test_days, freq='D')
    forecast = m.predict(future_frame)
    
    # 5. ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³‘í•©
    comparison_df = pd.merge(test_data[['ds', 'y']], forecast[['ds', 'yhat']], on='ds')

    # 6. MAPE ê³„ì‚°
    comparison_df = comparison_df[comparison_df['y'] > 0] # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    if comparison_df.empty:
        return None, None, "ì˜¤ë¥˜: MAPE ê³„ì‚°ì„ ìœ„í•œ ìœ íš¨í•œ ë¹„êµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ('ìˆ˜ìµ' ì»¬ëŸ¼ì´ 0 ë˜ëŠ” NaNì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"
        
    mape = mean_absolute_percentage_error(comparison_df['y'], comparison_df['yhat']) * 100
    
    # 7. ì‹œê°í™”
    fig = m.plot(forecast)
    ax = fig.gca()
    ax.plot(test_data['ds'], test_data['y'], 'r.', label='Actual Test Data (ì‹¤ì œê°’)')
    ax.legend()

    return mape, fig, f"ëª¨ë¸ ê²€ì¦ ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_days}ì¼)"


# ----------------------
# 2ï¸âƒ£ Firestore(íŒë§¤) ë¡œë“œ
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def load_sales_from_firestore() -> pd.DataFrame:
    docs = db.collection(SALES_COLLECTION).stream()
    data = [d.to_dict() for d in docs]
    df_fb = pd.DataFrame(data)
    if df_fb.empty:
        return df_fb
    if 'ë‚ ì§œ' in df_fb.columns:
        df_fb['ë‚ ì§œ'] = parse_mixed_dates(df_fb['ë‚ ì§œ'])
    if 'ìˆ˜ìµ' in df_fb.columns:
        df_fb['ìˆ˜ìµ'] = pd.to_numeric(df_fb['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_fb.columns:
        df_fb['ë‹¨ê°€'] = pd.to_numeric(df_fb['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_fb.columns:
        df_fb['ìˆ˜ëŸ‰'] = pd.to_numeric(df_fb['ìˆ˜ëŸ‰'], errors='coerce')
    if 'ì‹œê°„' in df_fb.columns:
        df_fb['ì‹œ'] = pd.to_datetime(df_fb['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df_fb['ì‹œ'] = None
    df_fb['ìš”ì¼'] = df_fb['ë‚ ì§œ'].dt.day_name()
    df_fb['ì›”'] = df_fb['ë‚ ì§œ'].dt.month
    return df_fb

df_fb = load_sales_from_firestore()

def load_sales_with_id():
    docs = db.collection(SALES_COLLECTION).stream()
    rows = []
    for d in docs:
        rec = d.to_dict()
        rec["_id"] = d.id
        rows.append(rec)
    df_raw = pd.DataFrame(rows)
    if df_raw.empty:
        return df_raw, df_raw
    if 'ë‚ ì§œ' in df_raw.columns:
        df_raw['ë‚ ì§œ'] = parse_mixed_dates(df_raw['ë‚ ì§œ'])
    if 'ìˆ˜ìµ' in df_raw: df_raw['ìˆ˜ìµ'] = pd.to_numeric(df_raw['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_raw: df_raw['ë‹¨ê°€'] = pd.to_numeric(df_raw['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_raw: df_raw['ìˆ˜ëŸ‰'] = pd.to_numeric(df_raw['ìˆ˜ëŸ‰'], errors='coerce')
    df_view = df_raw.copy()
    if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df_view: df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
    if 'ìƒí’ˆíƒ€ì…' in df_view: df_view['ìƒí’ˆíƒ€ì…'] = map_series(df_view['ìƒí’ˆíƒ€ì…'], type_map)
    if 'ìƒí’ˆìƒì„¸' in df_view: df_view['ìƒí’ˆìƒì„¸'] = df_view['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)
    return df_raw, df_view

# ==============================================================
# === [L4 ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë”© ë¸”ë¡] ===
# (ìˆœì„œ ë¬¸ì œ í•´ê²°: 'ì •ì˜'ë¥¼ 'í˜¸ì¶œ'ë³´ë‹¤ ì•ìœ¼ë¡œ ì´ë™)
# ==============================================================

# --- 1. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 1: Inventory) ---
@st.cache_data(ttl=60)
def load_inventory_df() -> pd.DataFrame:
    inv_docs = db.collection(INVENTORY_COLLECTION).stream()
    rows = []
    for d in inv_docs:
        doc = d.to_dict() or {}
        en = doc.get("ìƒí’ˆìƒì„¸_en", d.id)
        ko = to_korean_detail(en)
        
        # [L4] ì›ê°€ ì •ë³´ ë¡œë“œ
        cost_unit_size = safe_float(doc.get("cost_unit_size", 1.0), 1.0)
        cost_per_unit = safe_float(doc.get("cost_per_unit", 0.0), 0.0)
        
        # 1g/1ml/1eaë‹¹ ì›ê°€ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        unit_cost = cost_per_unit / cost_unit_size if cost_unit_size > 0 else 0.0
        
        rows.append({
            "ìƒí’ˆìƒì„¸_en": en,
            "ìƒí’ˆìƒì„¸": ko,
            "ì´ˆê¸°ì¬ê³ ": doc.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "í˜„ì¬ì¬ê³ ": doc.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "uom": normalize_uom(doc.get("uom", "ea")),
            "is_ingredient": bool(doc.get("is_ingredient", False)),
            
            # [L4] ì›ê°€ ì»¬ëŸ¼ ì¶”ê°€
            "cost_unit_size": cost_unit_size, # ë§¤ì… ë‹¨ìœ„ (e.g., 1000)
            "cost_per_unit": cost_per_unit,  # ë§¤ì…ê°€ (e.g., 30000)
            "unit_cost": unit_cost           # 1g/ml/eaë‹¹ ì›ê°€ (e.g., 30)
        })
    
    # === [ë¹ˆí‹ˆ ìˆ˜ì •] inventoryê°€ ë¹„ì–´ìˆì–´ë„ ì»¬ëŸ¼ì€ ìœ ì§€ ===
    df = pd.DataFrame(rows, columns=[
        "ìƒí’ˆìƒì„¸_en", "ìƒí’ˆìƒì„¸", "ì´ˆê¸°ì¬ê³ ", "í˜„ì¬ì¬ê³ ", "uom", "is_ingredient",
        "cost_unit_size", "cost_per_unit", "unit_cost" # [L4]
    ])
    return df

# --- 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 2: SKU Params) ---
@st.cache_data(ttl=60)
def load_sku_params() -> pd.DataFrame:
    try:
        docs = db.collection(SKU_PARAMS_COLLECTION).stream()
    except Exception:
        docs = []
    rows = []
    for d in docs:
        item = d.to_dict() or {}
        try:
            item["_id"] = d.id
        except Exception:
            item["_id"] = item.get("_id", "")
        rows.append(item)
    dfp = pd.DataFrame(rows)
    if dfp.empty:
        dfp = pd.DataFrame(columns=[
            "_id","sku_en","lead_time_days","safety_stock_units","target_days","grams_per_cup","expiry_days"
        ])
    defaults = {
        "lead_time_days": 3,
        "safety_stock_units": 10,
        "target_days": 21,
        "grams_per_cup": 18.0,
        "expiry_days": 28,
    }
    for col, default in defaults.items():
        if col not in dfp.columns:
            dfp[col] = default
        else:
            dfp[col] = pd.to_numeric(dfp[col], errors="coerce").fillna(default)
    return dfp

# --- 3. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 3: Ensure Inventory Doc) ---
def ensure_inventory_doc(product_detail_en: str, uom: str = "ea", is_ingredient: bool = False):
    ref = db.collection(INVENTORY_COLLECTION).document(safe_doc_id(product_detail_en))
    snap = ref.get()
    if snap.exists:
        data = snap.to_dict() or {}
        patch = {}
        if normalize_uom(data.get("uom")) != normalize_uom(uom):
            patch["uom"] = normalize_uom(uom)
        if bool(data.get("is_ingredient", False)) != bool(is_ingredient):
            patch["is_ingredient"] = bool(is_ingredient)
        if patch:
            ref.update(patch)
        return ref
    else:
        ref.set({
            "ìƒí’ˆìƒì„¸_en": product_detail_en,
            "ì´ˆê¸°ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "í˜„ì¬ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "uom": normalize_uom(uom),
            "is_ingredient": bool(is_ingredient),
            # [L4] ì›ê°€ ê¸°ë³¸ê°’
            "cost_unit_size": 1.0,
            "cost_per_unit": 0.0,
            "unit_cost": 0.0,
        })
        return ref

def ensure_ingredient_sku(ingredient_en: str, uom: str = "ea"):
    return ensure_inventory_doc(ingredient_en, uom=uom, is_ingredient=True)


def ensure_seed_ingredients():
    """Top5 ë ˆì‹œí”¼ í•µì‹¬ ì¬ë£Œë¥¼ inventoryì— ê¸°ë³¸ ë“±ë¡í•©ë‹ˆë‹¤."""
    for item in SEED_INGREDIENTS:
        ko = item["ko"]
        uom = item["uom"]
        en = from_korean_detail(ko)
        ensure_inventory_doc(en, uom=uom, is_ingredient=True)

def ensure_seed_menus():
    """Top5 ë©”ë‰´ë¥¼ inventoryì— 'ì™„ì œí’ˆ'ìœ¼ë¡œ ê¸°ë³¸ ë“±ë¡í•©ë‹ˆë‹¤."""
    for menu_ko in SEED_MENUS:
        menu_en = from_korean_detail(menu_ko)
        ref = db.collection(INVENTORY_COLLECTION).document(safe_doc_id(menu_en))
        snap = ref.get()
        if snap.exists:
            continue
        ref.set({
            "ìƒí’ˆìƒì„¸_en": menu_en,
            "ìƒí’ˆìƒì„¸": menu_ko,
            "is_ingredient": False,
            "uom": "ea",
            "ì´ˆê¸°ì¬ê³ ": 0.0,
            "í˜„ì¬ì¬ê³ ": 0.0,
            "cost_unit_size": 1.0,
            "cost_per_unit": 0.0,
            "unit_cost": 0.0,
        })


def reset_inventory_to_seed():
    """ëª¨ë“  inventory ë¬¸ì„œë¥¼ ì‚­ì œ í›„ ì‹œë“œ ì¬ë£Œë§Œ ë‹¤ì‹œ ì±„ì›ë‹ˆë‹¤."""
    try:
        docs = list(db.collection(INVENTORY_COLLECTION).stream())
        for d in docs:
            db.collection(INVENTORY_COLLECTION).document(d.id).delete()
        ensure_seed_ingredients()
        ensure_seed_menus()
        return len(docs)
    except Exception as e:
        st.error(f"ì¸ë²¤í† ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


# --- 4. ë©”ì¸ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (í˜¸ì¶œ 1) ---
@st.cache_data(ttl=60)
def load_all_core_data():
    """
    [L4 ìˆ˜ì •] ì•± ì‹¤í–‰ ì‹œ ëª¨ë“  í•µì‹¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    (ì´ì œ ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ì–´ë„, í•„ìš”í•œ í•¨ìˆ˜ë“¤ì´ 'ìœ„ì—' ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.)
    """
    # 0. í•µì‹¬ ì¬ë£Œê°€ inventoryì— ì—†ìœ¼ë©´ ì„ ë“±ë¡
    ensure_seed_ingredients()
    ensure_seed_menus()

    # 1. Sales (df)
    df = pd.concat([df_csv, df_fb], ignore_index=True)
    if 'ìš”ì¼' in df.columns:
        df['ìš”ì¼'] = map_series(df['ìš”ì¼'], weekday_map)
    if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df.columns:
        df['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
    if 'ìƒí’ˆíƒ€ì…' in df.columns:
        df['ìƒí’ˆíƒ€ì…'] = map_series(df['ìƒí’ˆíƒ€ì…'], type_map)
    if 'ìƒí’ˆìƒì„¸' in df.columns:
        df['ìƒí’ˆìƒì„¸'] = df['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)
    
    # 2. Inventory (df_inv) - [L4] ì›ê°€ ê³„ì‚°ì´ í¬í•¨ëœ í•¨ìˆ˜ë¡œ í˜¸ì¶œ
    df_inv = load_inventory_df() 
    
    # 3. Recipes (recipes)
    recipes = {}
    try:
        recipe_docs = db.collection(RECIPES_COLLECTION).stream()
        for d in recipe_docs:
            data = d.to_dict()
            if data and "ingredients" in data:
                recipes[d.id] = data["ingredients"]
    except Exception as e:
        st.error(f"ë ˆì‹œí”¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

    # 3-1. Top5 CSVë¥¼ ë ˆì‹œí”¼/ì›ê°€ë¡œ ë³‘í•© (Firestore ì—†ì„ ë•Œ ê¸°ë³¸ ë ˆì‹œí”¼/ì›ê°€)
    df_top_local = load_top5_recipe()
    top5_cost_map = build_top5_cost_map(df_top_local) if df_top_local is not None else {}
    csv_recipes = build_recipes_from_top5(df_top_local) if df_top_local is not None else {}
    for menu_en, ing_list in csv_recipes.items():
        if menu_en not in recipes or not recipes[menu_en]:
            recipes[menu_en] = ing_list
        
    # 4. Params (df_params)
    df_params = load_sku_params()
    
    return df, df_inv, recipes, df_params, top5_cost_map

# --- 5. ë©”ì¸ ë°ì´í„° ë¡œë“œ 'ì‹¤í–‰' ---
try:
    #data_load_state = st.info("ëª¨ë“  í•µì‹¬ ë°ì´í„°(íŒë§¤, ì¬ê³ , ë ˆì‹œí”¼) ë¡œë“œ ì¤‘... â³")
    df, df_inv, RECIPES, df_params, TOP5_COST_MAP = load_all_core_data()
    #data_load_state.success("âœ… ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
except Exception as e:
    #data_load_state.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()
    

# --- 6. ì›ê°€(COGS) ê³„ì‚° í•¨ìˆ˜ (ì •ì˜ 4) ---
@st.cache_data(ttl=600)
def calculate_menu_cogs(df_inv: pd.DataFrame, recipes: dict, cost_override: dict | None = None) -> dict:
    """
    (L4) 'df_inv'ì˜ 'unit_cost'ì™€ 'recipes'ë¥¼ ì‚¬ìš©í•´
    ëª¨ë“  ë©”ë‰´ì˜ COGS(ë§¤ì¶œ ì›ê°€)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    if 'unit_cost' not in df_inv.columns:
        st.error("calculate_menu_cogs: df_invì— 'unit_cost' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {}
        
    # 1. ì¬ë£Œ ì›ê°€ ë§µ ìƒì„± (sku_en -> unit_cost)
    ingredient_costs = df_inv[df_inv['is_ingredient'] == True].set_index('ìƒí’ˆìƒì„¸_en')['unit_cost'].to_dict()
    
    menu_cogs = {}
    
    # 2. ëª¨ë“  ë ˆì‹œí”¼ë¥¼ ìˆœíšŒí•˜ë©° ì›ê°€ ê³„ì‚°
    for menu_sku_en, ingredients in recipes.items():
        total_cogs = 0.0
        for item in ingredients:
            ing_sku_en = item["ingredient_en"]
            qty = safe_float(item.get("qty", 0.0))
            waste_pct = safe_float(item.get("waste_pct", 0.0))
            
            # 3. ì¬ë£Œ ì›ê°€ ê°€ì ¸ì˜¤ê¸°
            unit_cost = safe_float(ingredient_costs.get(ing_sku_en, 0.0))
            if unit_cost == 0 and cost_override:
                fallback = cost_override.get(ing_sku_en)
                if fallback:
                    # ì‚¬ìš© ë‹¨ê°€ / ì‚¬ìš©ëŸ‰ìœ¼ë¡œ ì¶”ì •í•œ ë‹¨ìœ„ ì›ê°€
                    unit_cost = safe_float(fallback.get("unit_cost", 0.0))
            
            # 4. ì†ì‹¤ë¥ (waste_pct)ì„ ì›ê°€ì— ë°˜ì˜
            cost_with_waste = unit_cost * (1 + (waste_pct / 100.0))
            
            # 5. ì´ ì¬ë£Œì˜ ì´ ì›ê°€ = (ì›ê°€ * ìˆ˜ëŸ‰)
            total_cogs += (cost_with_waste * qty)
        
        menu_cogs[menu_sku_en] = total_cogs
        
    return menu_cogs

# --- 7. ì›ê°€(COGS) 'ì‹¤í–‰' ë° 'df'ì— í†µí•© ---
try:
    #cogs_load_state = st.info("ë©”ë‰´ë³„ ì›ê°€(COGS) ë° ë§ˆì§„ ê³„ì‚° ì¤‘... ğŸ’°")
    
    # 1. ë©”ë‰´ë³„ COGS ë”•ì…”ë„ˆë¦¬ ìƒì„± (e.g., {'Americano': 600.0})
    menu_cogs_map = calculate_menu_cogs(df_inv, RECIPES, cost_override=TOP5_COST_MAP)
    
    # 2. 'ìƒí’ˆìƒì„¸'(í•œê¸€) <-> 'menu_sku_en' ë§µ ìƒì„±
    cogs_map_kr = {to_korean_detail(sku_en): cogs for sku_en, cogs in menu_cogs_map.items()}

    # 3. 'df'ì— 'ì›ê°€' ì»¬ëŸ¼ ì¶”ê°€
    df['ì›ê°€'] = df['ìƒí’ˆìƒì„¸'].map(cogs_map_kr).fillna(0.0)
    
    # 4. 'ìˆœì´ìµ' ë° 'ë§ˆì§„ìœ¨' ê³„ì‚°
    df['ìˆ˜ìµ'] = pd.to_numeric(df['ìˆ˜ìµ'], errors='coerce').fillna(0)
    df['ìˆœì´ìµ'] = df['ìˆ˜ìµ'] - df['ì›ê°€']
    df['ë§ˆì§„ìœ¨(%)'] = (df['ìˆœì´ìµ'] / df['ìˆ˜ìµ']).replace([pd.NA, float('inf'), float('-inf')], 0).fillna(0) * 100
    
    #cogs_load_state.success("âœ… ì›ê°€ ë° ë§ˆì§„ ê³„ì‚° ì™„ë£Œ!")

except Exception as e:
    #cogs_load_state.error(f"ì›ê°€ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
    # ì›ê°€ ì—†ì´ë„ ì•±ì€ ê³„ì† ì‘ë™í•´ì•¼ í•¨
    df['ì›ê°€'] = 0.0
    df['ìˆ˜ìµ'] = pd.to_numeric(df['ìˆ˜ìµ'], errors='coerce').fillna(0)
    df['ìˆœì´ìµ'] = df['ìˆ˜ìµ']
    df['ë§ˆì§„ìœ¨(%)'] = 0.0

# --- 8. 'load_recipe' (L4) í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---
def load_recipe(menu_sku_en: str) -> list[dict]:
    """[L4 ìˆ˜ì •] DBë¥¼ ë§¤ë²ˆ ì¡°íšŒí•˜ëŠ” ëŒ€ì‹ , ì „ì—­ 'RECIPES' ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©"""
    global RECIPES
    return RECIPES.get(menu_sku_en, [])

# --- 9. (ê¸°ì¡´ í•¨ìˆ˜) ì¬ê³  ì°¨ê° í•¨ìˆ˜ë“¤ (ìˆœì„œ ë³€ê²½) ---
def deduct_stock(product_detail_en: str, qty: int):
    ref = ensure_inventory_doc(product_detail_en)
    snap = ref.get()
    data = snap.to_dict() if snap.exists else {}
    init_stock = int(data.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    cur_stock = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    new_stock = max(cur_stock - int(qty), 0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return init_stock, new_stock

def get_all_recipe_ingredients() -> set:
    ingredients = set()
    try:
        docs = db.collection(RECIPES_COLLECTION).stream()
        for d in docs:
            items = (d.to_dict() or {}).get("ingredients", [])
            for it in items:
                ingredients.add(it["ingredient_en"])
    except Exception:
        pass
    return ingredients

def deduct_inventory(ingredient_en: str, qty: float, uom: str):
    ref = ensure_inventory_doc(ingredient_en, uom=uom)
    snap = ref.get()
    data = snap.to_dict() or {}
    cur = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    inv_uom = normalize_uom(data.get("uom", "ea"))
    use_qty = convert_qty(qty, from_uom=uom, to_uom=inv_uom)
    new_stock = max(cur - use_qty, 0.0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return cur, new_stock, inv_uom

def apply_recipe_deduction(menu_sku_en: str, sold_qty: int, commit: bool = True) -> list[dict]:
    items = load_recipe(menu_sku_en)
    summary: list[dict] = []
    if not items:
        ref = ensure_inventory_doc(menu_sku_en, uom="ea")
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used = float(sold_qty)
        after = max(before - used, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": menu_sku_en, "used": used, "uom": inv_uom, "before": before, "after": after})
        return summary
    for it in items:
        ing = it["ingredient_en"]
        uom = normalize_uom(it["uom"])
        qty_per_unit = safe_float(it["qty"])
        waste_pct = safe_float(it["waste_pct"], 0)
        total_used = (qty_per_unit * sold_qty) * (1 + (waste_pct / 100.0))
        ref = ensure_inventory_doc(ing, uom=uom, is_ingredient=True)
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used_converted = convert_qty(total_used, from_uom=uom, to_uom=inv_uom)
        after = max(before - used_converted, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": ing, "used": used_converted, "uom": inv_uom, "before": before, "after": after})
    return summary

def adjust_inventory_by_recipe(menu_sku_en: str,
                               qty_diff: int,
                               move_type: str = "manual_adjust",
                               note: str = ""):
    if qty_diff == 0:
        return
    details = apply_recipe_deduction(menu_sku_en, qty_diff, commit=True)
    log_doc = {
        "ts": datetime.now().isoformat(),
        "type": move_type,
        "menu_sku_en": menu_sku_en,
        "qty": qty_diff,
        "note": note,
        "details": details,
    }
    db.collection(STOCK_MOVES_COLLECTION).add(log_doc)

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í˜¸ì¶œ í—¬í¼
def call_openai_api(user_prompt: str, data_context: str, model="gpt-3.5-turbo"):
    """
    [AI ìˆ˜ì • 2] data_context(ì‚¬ì‹¤)ì™€ user_prompt(ìš”ì²­)ë¥¼ ë¶„ë¦¬í•˜ì—¬ AIê°€ 'ê±°ì§“ë§'ì„ í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì •.
    data_contextëŠ” 'system' ë©”ì‹œì§€ë¡œ, user_promptëŠ” 'user' ë©”ì‹œì§€ë¡œ ì „ë‹¬.
    """
    
    # 1. API í‚¤ê°€ ì—†ëŠ” ê²½ìš°
    if not openai.api_key:
        time.sleep(1.5) 
        st.error("OpenAI API í‚¤ê°€ 'secrets.toml'ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return (f"âš ï¸ **[AI ì‘ë‹µ ì‹¤íŒ¨ (API í‚¤ ì—†ìŒ)]**\n\n"
                f"'secrets.toml'ì— OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
                f"--- (ë°ì´í„° ì»¨í…ìŠ¤íŠ¸) ---\n{data_context}\n\n"
                f"--- (ì‚¬ìš©ì ìš”ì²­) ---\n{user_prompt}")

    # 2. API í˜¸ì¶œ ì‹œë„
    try:
        # [ìˆ˜ì •] ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëª…í™•íˆ ë¶„ë¦¬
        response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": (
                    "ë‹¹ì‹ ì€ ì¹´í˜ ìš´ì˜ ë° ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                    "ë‹¤ìŒì€ í˜„ì¬ ì¹´í˜ì˜ ì‹¤ì œ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ 'ì‚¬ì‹¤'ë¡œ ê°„ì£¼í•˜ê³ , "
                    "ì´ 'ì‚¬ì‹¤'ì— ê¸°ë°˜í•´ì„œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì ˆëŒ€ ë°ì´í„°ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.\n\n"
                    f"--- [ì¹´í˜ ì‹¤ì œ ë°ì´í„°] ---\n{data_context}\n--- [ë°ì´í„° ë] ---"
                )},
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.choices[0].message.content
        
    # 3. [ìˆ˜ì •] ì”ì•¡ ë¶€ì¡± ë˜ëŠ” API ì˜¤ë¥˜ ë°œìƒ ì‹œ
    except openai.InsufficientQuotaError as e:
        # "ê°€ì§œ ì‘ë‹µ"ì´ ì•„ë‹Œ, ëª…í™•í•œ 'ì˜¤ë¥˜'ì™€ 'ì‹œë„í–ˆë˜ ë‚´ìš©'ì„ ë°˜í™˜
        st.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: ì”ì•¡(Quota)ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì˜¤ë¥˜: {e.message})")
        return (f"âš ï¸ **[AI ì‘ë‹µ ì‹¤íŒ¨ (ì”ì•¡ ë¶€ì¡±)]**\n\n"
                f"OpenAI ê³„ì •ì˜ ì”ì•¡ì´ ë¶€ì¡±í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"--- (AIê°€ ì „ë‹¬ë°›ì€ ë°ì´í„°) ---\n{data_context}\n\n"
                f"--- (AIê°€ ìš”ì²­ë°›ì€ ì‘ì—…) ---\n{user_prompt}")
        
    except openai.AuthenticationError as e:
        st.error("âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: API í‚¤ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. 'secrets.toml'ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    
# ==========================================
# [AI/ML í†µí•© ì¶”ê°€] ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ ë¶„ì„ í—¬í¼ í•¨ìˆ˜
# ==========================================
import base64

def analyze_receipt_image(uploaded_file):
    """
    ì—…ë¡œë“œëœ ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ë¥¼ GPT-4o(Vision)ì—ê²Œ ë³´ë‚´ì„œ
    ìƒí˜¸ëª…, ë‚ ì§œ, ì‹œê°„, í’ˆëª© ë¦¬ìŠ¤íŠ¸, ì´ì•¡ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    if not openai.api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    # 1. ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
    bytes_data = uploaded_file.getvalue()
    base64_image = base64.b64encode(bytes_data).decode('utf-8')

    # 2. í”„ë¡¬í”„íŠ¸ ì„¤ì • (JSON í˜•ì‹ ê°•ì œ)
    system_prompt = """
    You are a receipt OCR assistant. Analyze the receipt image and extract the following information in JSON format:
    {
        "store_name": "Store Name",
        "date": "YYYY-MM-DD",
        "time": "HH:MM",
        "items": [
            {"name": "Item Name 1", "qty": 1, "price": 1000, "total": 1000},
            {"name": "Item Name 2", "qty": 2, "price": 2000, "total": 4000}
        ],
        "total_amount": 5000
    }
    If date/time is missing, use null. Prices should be numbers (remove currency symbols).
    """

    # 3. API í˜¸ì¶œ
    try:
        response = openai.chat.completions.create(
            model="gpt-4o", # ë˜ëŠ” gpt-4-turbo
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": [
                    {"type": "text", "text": "Analyze this receipt image and extract data."},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]}
            ],
            response_format={"type": "json_object"} # JSON ëª¨ë“œ í™œì„±í™”
        )
        
        result_text = response.choices[0].message.content
        return json.loads(result_text) # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜

    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# SPRINT 2: Prophet ìˆ˜ìš” ì˜ˆì¸¡ í—¬í¼
@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
# SPRINT 2: Prophet ìˆ˜ìš” ì˜ˆì¸¡ í—¬í¼
@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
def get_item_forecast(df_all_sales: pd.DataFrame, menu_sku_en: str, days_to_forecast: int):
    """Prophetì„ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ë©”ë‰´ì˜ ë¯¸ë˜ íŒë§¤ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    
    try:
        # === [ìˆ˜ì •] ë‚ ì§œ ë°ì´í„° ì•ˆì •í™” ===
        df_all_sales = df_all_sales.copy()
        df_all_sales['ë‚ ì§œ'] = pd.to_datetime(df_all_sales['ë‚ ì§œ'], errors='coerce')
        df_all_sales = df_all_sales.dropna(subset=['ë‚ ì§œ'])
        # === [ìˆ˜ì • ë] ===

        # === [ë²„ê·¸ ìˆ˜ì •] ì´ë¦„ ë¶ˆì¼ì¹˜ í•´ê²° ===
        base_sku_en = re.sub(r"\s+(Lg|Rg|Sm)$", "", menu_sku_en.strip())
        menu_name_kr_base = to_korean_detail(base_sku_en) # This should now be 'ì•„ë©”ë¦¬ì¹´ë…¸'
        
        original_menu_name_kr = to_korean_detail(menu_sku_en)
        if original_menu_name_kr != menu_name_kr_base:
            st.info(f"AI ì˜ˆì¸¡: '{original_menu_name_kr}' ë©”ë‰´ì˜ ì˜ˆì¸¡ì„ ìœ„í•´, íŒë§¤ ë°ì´í„°ì—ì„œ '{menu_name_kr_base}'(ìœ¼)ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.")
        # === [ë²„ê·¸ ìˆ˜ì • ë] ===

        df_item = df_all_sales[
            df_all_sales['ìƒí’ˆìƒì„¸'] == menu_name_kr_base
        ].copy()
        
        if df_item.empty:
            st.warning(f"íŒë§¤ ë°ì´í„°(df)ì—ì„œ '{menu_name_kr_base}' ì´ë¦„ì˜ íŒë§¤ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„° 0ê±´)")
            return None, None # íŒë§¤ ë°ì´í„° ì—†ìŒ

        # Prophetì´ ë‚ ì§œ ë°ì´í„°ë¥¼ ì‹ ë¢°í•˜ë„ë¡ ì „ì²˜ë¦¬
        df_agg = df_item.groupby('ë‚ ì§œ')['ìˆ˜ëŸ‰'].sum().reset_index()
        df_agg['ë‚ ì§œ'] = pd.to_datetime(df_agg['ë‚ ì§œ'])
        
        if not df_agg.empty:
            date_range = pd.date_range(start=df_agg['ë‚ ì§œ'].min(), end=df_agg['ë‚ ì§œ'].max())
            df_agg = df_agg.set_index('ë‚ ì§œ').reindex(date_range, fill_value=0).reset_index()
            df_agg.rename(columns={'index': 'ë‚ ì§œ'}, inplace=True)
        
        df_prophet = df_agg[['ë‚ ì§œ', 'ìˆ˜ëŸ‰']].rename(columns={"ë‚ ì§œ": "ds", "ìˆ˜ëŸ‰": "y"})

        if len(df_prophet) < 7: # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜ˆì¸¡ ë¶ˆê°€
            return None, None

        m = Prophet(weekly_seasonality=True, yearly_seasonality=False, daily_seasonality=False)
        m.fit(df_prophet)
        
        # [ìˆ˜ì •] freq='D'ë¥¼ ì¶”ê°€í•˜ì—¬ 'ì¼(Daily)' ë‹¨ìœ„ ì˜ˆì¸¡ì„ì„ ëª…ì‹œ
        future = m.make_future_dataframe(periods=days_to_forecast, freq='D')
        forecast = m.predict(future)
        
        # === [ë¹ˆí‹ˆ ìˆ˜ì •] 'y' ì»¬ëŸ¼ì´ ë¹ ì§€ëŠ” ì˜¤ë¥˜ ìˆ˜ì • ===
        forecast_chart_data = forecast.merge(df_prophet, on='ds', how='left')
        
        # ìŒìˆ˜ ì˜ˆì¸¡ì€ 0ìœ¼ë¡œ
        forecast_chart_data['yhat'] = forecast_chart_data['yhat'].clip(lower=0) 
        
        # ì˜ˆì¸¡ëœ ê¸°ê°„(target_days)ì˜ ì´ ì†Œì§„ëŸ‰ í•©ê³„ ë°˜í™˜
        predicted_sum = forecast_chart_data.iloc[-days_to_forecast:]['yhat'].sum()
        
        return max(predicted_sum, 0), forecast_chart_data 

    except Exception as e:
        st.warning(f"Prophet ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None
# === [AI/ML í†µí•© ì¶”ê°€] ===

# ----------
# [AI/ML í†µí•© ìˆ˜ì • 6] 
# ( compute_ingredient_metrics_for_menu )
# SPRINT 2: ML ìˆ˜ìš” ì˜ˆì¸¡ ë¡œì§ ìˆ˜ì •
# - [ë¹ˆí‹ˆ ìˆ˜ì •] "ì „ì²´ ê±°ë˜ ë‚´ì—­"ì´ ê·¸ë˜í”„ì— ë°˜ì˜ë˜ë„ë¡ .iloc[-90:] ì‚­ì œ
# - [ê¸°ëŠ¥ ì¶”ê°€] 'ì‹¤ì œ íŒë§¤ëŸ‰(y)'ê³¼ 'AI ì˜ˆì¸¡(yhat)'ì„ ê·¸ë˜í”„ì— ë™ì‹œ í‘œì‹œ
# ----------
def compute_ingredient_metrics_for_menu(
    menu_sku_en: str,
    df_all_sales: pd.DataFrame, # ì „ì²´ íŒë§¤ ë°ì´í„°(df)
    df_inv: pd.DataFrame,
    df_params: pd.DataFrame,
    window_days: int = 28 # [ìˆ˜ì •] ì´ ê°’ì€ ì´ì œ AI ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©ë¨
) -> pd.DataFrame:
    """
    [AI ìˆ˜ì •ë¨] íŠ¹ì • ë©”ë‰´ì˜ ë ˆì‹œí”¼ì™€ *ë¯¸ë˜ ì˜ˆì¸¡ íŒë§¤ëŸ‰* ê¸°ë°˜ìœ¼ë¡œ ì¬ë£Œë³„ ì§€í‘œ ê³„ì‚°.
    ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ ê³¼ê±° ìœˆë„ìš°(window_days) í‰ê· ìœ¼ë¡œ ëŒ€ì²´.
    """
    items = load_recipe(menu_sku_en)
    if not items:
        return pd.DataFrame()

    # === [ë²„ê·¸ ìˆ˜ì •] ì´ë¦„ ë¶ˆì¼ì¹˜ í•´ê²° (Historical) ===
    base_sku_en = re.sub(r"\s+(Lg|Rg|Sm)$", "", menu_sku_en.strip())
    menu_name_kr_base = to_korean_detail(base_sku_en) # 'ì•„ë©”ë¦¬ì¹´ë…¸'
    # === [ë²„ê·¸ ìˆ˜ì • ë] ===

    # === [ìˆ˜ì •] ì˜ˆì¸¡ ê¸°ê°„ì„ 21ì¼ë¡œ ê³ ì •í•˜ì—¬ ë²„ê·¸ í•´ê²° ===
    target_days_forecast = 21
    window_days_fallback = 21 # AI ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„ë„ 21ì¼ë¡œ í†µì¼
    st.info(f"ğŸ¤– AI ìˆ˜ìš” ì˜ˆì¸¡ì„ í–¥í›„ **{target_days_forecast}ì¼** ê¸°ì¤€ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    # === [ìˆ˜ì • ë] ===

    # 1. (Fallbackìš©) ê³¼ê±° ìœˆë„ìš° íŒë§¤ëŸ‰ ì§‘ê³„
    sold_sum_historical = 0.0
    if "ë‚ ì§œ" in df_all_sales.columns and pd.api.types.is_datetime64_any_dtype(df_all_sales["ë‚ ì§œ"]):
        max_day = df_all_sales["ë‚ ì§œ"].max()
        min_day = max_day - pd.Timedelta(days=window_days_fallback - 1)
        df_win = df_all_sales[(df_all_sales["ë‚ ì§œ"] >= min_day) & (df_all_sales["ë‚ ì§œ"] <= max_day)]
        sold_sum_historical = df_win[df_win['ìƒí’ˆìƒì„¸'] == menu_name_kr_base]['ìˆ˜ëŸ‰'].sum()
    
    # 2. [AI/ML] ë¯¸ë˜ ìˆ˜ìš” ì˜ˆì¸¡
    predicted_menu_sales, forecast_chart_data = get_item_forecast(
        df_all_sales, menu_sku_en, days_to_forecast=target_days_forecast
    )

    # 3. ì‚¬ìš©í•  íŒë§¤ëŸ‰(sold_sum) ë° ê¸°ì¤€ì¼(days) ê²°ì •
    use_historical_fallback = False
    
    if predicted_menu_sales is None or predicted_menu_sales == 0:
        st.warning(f"ğŸ¤– AI ì˜ˆì¸¡: '{to_korean_detail(menu_sku_en)}'ì˜ íŒë§¤ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ê³¼ê±° {window_days_fallback}ì¼ íŒë§¤ëŸ‰: {sold_sum_historical}ê°œ)ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        sold_sum = sold_sum_historical # ê³¼ê±° ë°ì´í„° ì‚¬ìš©
        days = window_days_fallback
        use_historical_fallback = True
    else:
        st.success(f"ğŸ¤– **AI ì˜ˆì¸¡**: '{to_korean_detail(menu_sku_en)}'ì˜ í–¥í›„ **{target_days_forecast}ì¼ê°„** ì˜ˆìƒ íŒë§¤ëŸ‰ì„ **{predicted_menu_sales:,.0f}ê°œ**ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.")
        sold_sum = predicted_menu_sales # ì˜ˆì¸¡ê°’ìœ¼ë¡œ ëŒ€ì²´
        days = target_days_forecast # ê¸°ì¤€ì¼ë„ ì˜ˆì¸¡ ê¸°ê°„ìœ¼ë¡œ ë³€ê²½
        
        # [ë³µì›] 'ì˜ˆì „ ê·¸ë˜í”„' ë¡œì§ì„ ì—¬ê¸°ì— ë‹¤ì‹œ ì¶”ê°€í•©ë‹ˆë‹¤.
        if forecast_chart_data is not None:
            try:
                fig = px.line(forecast_chart_data, x='ds', y='yhat', 
                                title=f"'{to_korean_detail(menu_sku_en)}' ì „ì²´ ê¸°ê°„ ìˆ˜ìš” ì˜ˆì¸¡", 
                                labels={'ds':'ë‚ ì§œ', 'yhat':'ì˜ˆì¸¡ íŒë§¤ëŸ‰'})
                
                actual_data = forecast_chart_data.dropna(subset=['y'])
                fig.add_scatter(x=actual_data['ds'], y=actual_data['y'], 
                                mode='markers', 
                                name='ì‹¤ì œ íŒë§¤ëŸ‰', 
                                marker=dict(color='rgba(0,0,255,0.5)', size=5))
                
                fig.add_scatter(x=forecast_chart_data['ds'], y=forecast_chart_data['yhat_lower'], fill='tozeroy', mode='lines', line=dict(color='rgba(0,0,0,0)'), name='ë¶ˆí™•ì‹¤ì„±(í•˜í•œ)')
                fig.add_scatter(x=forecast_chart_data['ds'], y=forecast_chart_data['yhat_upper'], fill='tonexty', mode='lines', line=dict(color='rgba(0,0,0,0)'), fillcolor='rgba(231, 234, 241, 0.5)', name='ë¶ˆí™•ì‹¤ì„±(ìƒí•œ)')
                
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

    # 4. ë ˆì‹œí”¼ ê¸°ë°˜ ì›ì¬ë£Œ ì†Œì§„ëŸ‰ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ í™œìš©)
    rows = []
    for item in items:
        # ... (ì´í•˜ ëª¨ë“  ê³„ì‚° ë¡œì§ì€ ì›ë³¸ê³¼ ë™ì¼) ...
        sku_en = item["ingredient_en"]
        qty_per_unit = safe_float(item.get("qty", 0.0))
        uom = normalize_uom(item.get("uom", "ea"))
        waste_pct = safe_float(item.get("waste_pct", 0.0))
        
        total_used = (qty_per_unit * sold_sum) * (1 + (waste_pct / 100.0))
        
        rows.append({
            "sku_en": sku_en,
            "uom_recipe": uom,
            "total_consumption": total_used
        })

    if not rows:
        return pd.DataFrame()
    
    use_df = pd.DataFrame(rows).groupby("sku_en").agg({
        "total_consumption": "sum",
        "uom_recipe": "first" 
    }).reset_index()
    
    base = use_df.rename(columns={"total_consumption": "ìµœê·¼ì†Œì§„í•©"})

    # 5. ì¬ê³  ì§€í‘œ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ í™œìš©)
    base["ì¼í‰ê· ì†Œì§„"] = (base["ìµœê·¼ì†Œì§„í•©"] / max(days, 1)).round(3)
    base.loc[base["ì¼í‰ê· ì†Œì§„"].eq(0), "ì¼í‰ê· ì†Œì§„"] = 0.01

    base = base.merge(df_inv[['ìƒí’ˆìƒì„¸_en', 'í˜„ì¬ì¬ê³ ', 'ì´ˆê¸°ì¬ê³ ', 'uom']], left_on='sku_en', right_on='ìƒí’ˆìƒì„¸_en', how='left')
    base['í˜„ì¬ì¬ê³ '] = base['í˜„ì¬ì¬ê³ '].fillna(0)
    base['ì´ˆê¸°ì¬ê³ '] = base['ì´ˆê¸°ì¬ê³ '].fillna(DEFAULT_INITIAL_STOCK)
    base['uom'] = base['uom'].fillna('ea').apply(normalize_uom)

    base["ì»¤ë²„ì¼ìˆ˜"] = (base["í˜„ì¬ì¬ê³ "] / base["ì¼í‰ê· ì†Œì§„"]).round(1)

    # 6. ROP ë° ê¶Œì¥ ë°œì£¼ëŸ‰ ê³„ì‚°
    base = base.merge(df_params, on="sku_en", how="left")
    
    base['lead_time_days'] = base['lead_time_days'].fillna(3)
    base['safety_stock_units'] = base['safety_stock_units'].fillna(0)
    base['target_days'] = base['target_days'].fillna(21)

    base["ROP"] = (base["ì¼í‰ê· ì†Œì§„"] * base["lead_time_days"] + base["safety_stock_units"]).round(0).astype(int)
    target_need = base["ì¼í‰ê· ì†Œì§„"] * base["target_days"]
    base["ê¶Œì¥ë°œì£¼"] = (target_need + base["safety_stock_units"] - base["í˜„ì¬ì¬ê³ "]).apply(lambda x: max(int(ceil(x)), 0))
    # ì¬ê³ =0ì´ê³  ì†Œì§„ì´ ìˆëŠ” ê²½ìš° ìµœì†Œ 1ê°œ ì£¼ë¬¸í•˜ë„ë¡ ë³´ì •
    base.loc[(base["ê¶Œì¥ë°œì£¼"] == 0) & (base["ì¼í‰ê· ì†Œì§„"] > 0), "ê¶Œì¥ë°œì£¼"] = 1
    base["ìƒíƒœ"] = base.apply(lambda r: "ğŸš¨ ë°œì£¼ìš”ë§" if r["í˜„ì¬ì¬ê³ "] <= r["ROP"] else "âœ… ì •ìƒ", axis=1)

    base["ìƒí’ˆìƒì„¸"] = base["sku_en"].apply(to_korean_detail)
    cols = ["ìƒí’ˆìƒì„¸","sku_en","í˜„ì¬ì¬ê³ ","ì´ˆê¸°ì¬ê³ ","uom","ìµœê·¼ì†Œì§„í•©","ì¼í‰ê· ì†Œì§„","ì»¤ë²„ì¼ìˆ˜",
            "lead_time_days","safety_stock_units","target_days","ROP","ê¶Œì¥ë°œì£¼","ìƒíƒœ"]
    for c in cols:
        if c not in base.columns:
            base[c] = None
            
    return base[cols].sort_values(["ìƒíƒœ","ì»¤ë²„ì¼ìˆ˜"])

# =============================================================
# === [AI/ML ì—…ê·¸ë ˆì´ë“œ] í”„ë¡œì•¡í‹°ë¸Œ ë¶„ì„ í•¨ìˆ˜ (L3 + L4) ===
# =============================================================

@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
def find_inventory_risks(df, df_inv, df_params):
    """(AI ë ˆë²¨ 3) AI ì˜ˆì¸¡ ê¸°ë°˜, ì¬ê³  ìœ„í—˜ í’ˆëª© ìƒìœ„ 3ê°œ ì°¾ê¸°"""
    try:
        # 1. ë ˆì‹œí”¼ê°€ ìˆëŠ” ë©”ë‰´ë§Œ
        # [L4] ì „ì—­ RECIPES ì‚¬ìš©
        menu_list_en = list(RECIPES.keys())
        if not menu_list_en:
            return "ë ˆì‹œí”¼ê°€ ë“±ë¡ë˜ì§€ ì•Šì•„ ì¬ê³  ìœ„í—˜ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        all_risks = []
        
        for menu_sku_en in menu_list_en:
            # 2. ëª¨ë“  ë©”ë‰´ì— ëŒ€í•´ 'AI ì˜ˆì¸¡' ë° 'ì¬ê³  ê³„ì‚°' ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
            report_df = compute_ingredient_metrics_for_menu(
                menu_sku_en, df, df_inv, df_params, window_days=21
            )
            
            # 3. 'ë°œì£¼ìš”ë§' ìƒíƒœì¸ ì¬ë£Œ í•„í„°ë§
            risk_items = report_df[report_df['ìƒíƒœ'] == 'ğŸš¨ ë°œì£¼ìš”ë§']
            
            if not risk_items.empty:
                for _, row in risk_items.iterrows():
                    all_risks.append(
                        f"- '{row['ìƒí’ˆìƒì„¸']}' (ë©”ë‰´ '{to_korean_detail(menu_sku_en)}'ìš©): "
                        f"í˜„ì¬ ì¬ê³  {row['í˜„ì¬ì¬ê³ ']}{row['uom']}, "
                        f"AI ì˜ˆì¸¡ ê¸°ë°˜ ê¶Œì¥ ë°œì£¼ëŸ‰ {row['ê¶Œì¥ë°œì£¼']}{row['uom']}. (ì»¤ë²„ì¼ìˆ˜: {row['ì»¤ë²„ì¼ìˆ˜']}ì¼)"
                    )
                    
        if not all_risks:
            return "AI ì˜ˆì¸¡ ê²°ê³¼, í˜„ì¬ ì¬ê³ ê°€ ì¶©ë¶„í•©ë‹ˆë‹¤. (ìœ„í—˜ 0ê±´)"
        
        # ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
        return "\n".join(list(set(all_risks))[:3])

    except Exception as e:
        return f"ì¬ê³  ìœ„í—˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_slow_moving_items(df, df_inv):
    """(AI ë ˆë²¨ 3) ì•…ì„± ì¬ê³  (30ì¼ê°„ 5ê°œ ì´í•˜ íŒë§¤) ì°¾ê¸°"""
    try:
        # 1. 30ì¼ê°„ ë©”ë‰´ë³„ íŒë§¤ëŸ‰ ì§‘ê³„
        min_day = df["ë‚ ì§œ"].max() - pd.Timedelta(days=29)
        df_30d = df[df["ë‚ ì§œ"] >= min_day]
        sales_counts = df_30d.groupby('ìƒí’ˆìƒì„¸')['ìˆ˜ëŸ‰'].sum()
        
        # 2. 30ì¼ê°„ 5ê°œ ì´í•˜ë¡œ íŒ”ë¦° 'ë¹„ì¸ê¸° ë©”ë‰´'
        slow_menus_kr = sales_counts[sales_counts <= 5].index.tolist()
        if not slow_menus_kr:
            return "ì§€ë‚œ 30ì¼ê°„ íŒë§¤ê°€ ë¶€ì§„í•œ ë©”ë‰´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # 3. ë¹„ì¸ê¸° ë©”ë‰´ì˜ ë ˆì‹œí”¼ -> ì¬ë£Œ ì°¾ê¸°
        slow_ingredients = set()
        for menu_kr in slow_menus_kr:
            menu_en = from_korean_detail(menu_kr)
            items = load_recipe(menu_en) # [L4] ì „ì—­ RECIPES ì‚¬ìš©
            for item in items:
                slow_ingredients.add(item['ingredient_en'])
        
        if not slow_ingredients:
            return "ì§€ë‚œ 30ì¼ê°„ íŒë§¤ê°€ ë¶€ì§„í•œ ë©”ë‰´ê°€ ìˆìœ¼ë‚˜, ë ˆì‹œí”¼ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
        # 4. í•´ë‹¹ ì¬ë£Œë“¤ì˜ í˜„ì¬ ì¬ê³  í™•ì¸
        df_ing_stock = df_inv[df_inv['ìƒí’ˆìƒì„¸_en'].isin(list(slow_ingredients))]
        df_ing_stock = df_ing_stock.sort_values('í˜„ì¬ì¬ê³ ', ascending=False)
        
        if df_ing_stock.empty:
            return "íŒë§¤ ë¶€ì§„ ë©”ë‰´ì™€ ì—°ê²°ëœ ì¬ë£Œ ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
            
        report = []
        for _, row in df_ing_stock.head(3).iterrows(): # ì¬ê³  ë§ì€ ìƒìœ„ 3ê°œ
            report.append(
                f"- '{row['ìƒí’ˆìƒì„¸']}' (ë¹„ì¸ê¸° ë©”ë‰´ìš© ì¬ë£Œ): "
                f"í˜„ì¬ ì¬ê³  {row['í˜„ì¬ì¬ê³ ']}{row['uom']}"
            )
        return "\n".join(report)

    except Exception as e:
        return f"ì•…ì„± ì¬ê³  ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_top_correlations(df):
    """(AI ë ˆë²¨ 3) í•¨ê»˜ ì˜ íŒ”ë¦¬ëŠ” ë©”ë‰´ (ìƒê´€ê´€ê³„) ì°¾ê¸°"""
    try:
        # 1. ë‚ ì§œ-ìƒí’ˆë³„ íŒë§¤ëŸ‰ í”¼ë²— í…Œì´ë¸” ìƒì„±
        df_pivot = df.pivot_table(
            index='ë‚ ì§œ', 
            columns='ìƒí’ˆìƒì„¸', 
            values='ìˆ˜ëŸ‰', 
            aggfunc='sum'
        ).fillna(0)
        
        # (ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 20ê°œë§Œ)
        top_20_items = df_pivot.sum().nlargest(20).index
        df_pivot = df_pivot[top_20_items]
        
        # 2. ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        corr_matrix = df_pivot.corr()
        
        # 3. ìê¸° ìì‹ (1.0)ì„ ì œì™¸í•˜ê³ , 0.5 ì´ìƒë§Œ ì·¨ë“
        corr_pairs = corr_matrix.unstack()
        corr_pairs = corr_pairs[(corr_pairs < 0.99) & (corr_pairs >= 0.5)]
        corr_pairs = corr_pairs.sort_values(ascending=False)
        
        if corr_pairs.empty:
            return "ìœ ì˜ë¯¸í•œ ë™ì‹œ íŒë§¤ íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        top_3 = corr_pairs.head(3)
        report = []
        for (item1, item2), corr_val in top_3.items():
            report.append(f"- '{item1}' + '{item2}' (ìƒê´€ê´€ê³„: {corr_val:.2f})")
        return "\n".join(report)
        
    except Exception as e:
        return f"íŒë§¤ íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_profit_insights(df_with_margin: pd.DataFrame):
    """(AI ë ˆë²¨ 4) 'ìˆœì´ìµ'ê³¼ 'ë§ˆì§„ìœ¨' ê¸°ë°˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
    
    if 'ìˆœì´ìµ' not in df_with_margin.columns or df_with_margin['ì›ê°€'].sum() == 0:
        return ("'ì›ê°€' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ì›ê°€ & ë ˆì‹œí”¼ í—ˆë¸Œ' íƒ­ì—ì„œ "
                "ë¨¼ì € 'ì¬ë£Œ ì›ê°€'ì™€ 'ë ˆì‹œí”¼'ë¥¼ ë“±ë¡í•´ì•¼ 'ìˆœì´ìµ' ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    try:
        # 1. ë©”ë‰´ë³„ ì§‘ê³„
        df_agg = df_with_margin.groupby('ìƒí’ˆìƒì„¸').agg(
            ì´íŒë§¤ìˆ˜ëŸ‰=('ìˆ˜ëŸ‰', 'sum'),
            ì´ë§¤ì¶œ=('ìˆ˜ìµ', 'sum'),
            ì´ìˆœì´ìµ=('ìˆœì´ìµ', 'sum')
        ).reset_index()
        
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] = (df_agg['ì´ìˆœì´ìµ'] / df_agg['ì´ë§¤ì¶œ']).replace([pd.NA, float('inf'), float('-inf')], 0).fillna(0) * 100
        
        # 2. íš¨ì ìƒí’ˆ (ìˆœì´ìµ ê¸°ì—¬ë„ Top 3)
        stars = df_agg.sort_values('ì´ìˆœì´ìµ', ascending=False).head(3)
        star_report = "\n".join([
            f"- '{row['ìƒí’ˆìƒì„¸']}' (ì´ ìˆœì´ìµ: {format_krw(row['ì´ìˆœì´ìµ'])}, ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
            for _, row in stars.iterrows()
        ])
        
        # 3. ìˆ˜ìµì„± í•¨ì • (ë§ˆì§„ìœ¨ í•˜ìœ„ 3ê°œ - ë‹¨, ì›ê°€ê°€ 0ì´ ì•„ë‹Œ ë©”ë‰´ ì¤‘)
        traps = df_agg[df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] > 0].sort_values('í‰ê· ë§ˆì§„ìœ¨(%)', ascending=True).head(3)
        trap_report = "\n".join([
            f"- '{row['ìƒí’ˆìƒì„¸']}' (ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
            for _, row in traps.iterrows()
        ])

        # 4. ì†ì‹¤ ìƒí’ˆ (ë§ˆì§„ìœ¨ì´ 0 ë˜ëŠ” ë§ˆì´ë„ˆìŠ¤)
        loss = df_agg[df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] <= 0]
        loss_report = "ì†ì‹¤ ë°œìƒ ë©”ë‰´ ì—†ìŒ."
        if not loss.empty:
            loss_report = "\n".join([
                f"- '{row['ìƒí’ˆìƒì„¸']}' (ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
                for _, row in loss.iterrows()
            ])

        return f"""
[íš¨ì ìƒí’ˆ (ìˆœì´ìµ Top 3)]
{star_report}

[ìˆ˜ìµì„± í•¨ì • (ë§ˆì§„ìœ¨ í•˜ìœ„ 3)]
{trap_report}

[ì†ì‹¤ ë°œìƒ ë©”ë‰´ (ë§ˆì§„ìœ¨ <= 0)]
{loss_report}
"""
    except Exception as e:
        return f"ë§ˆì§„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"


# ----------------------
# 5ï¸âƒ£ ì‚¬ì´ë“œë°” ë©”ë‰´
# ----------------------
# 1. ëª¨ë“  ë©”ë‰´ ì˜µì…˜ ì •ì˜
# 1. ëª¨ë“  ë©”ë‰´ ì˜µì…˜ ì •ì˜
MENU_OPTIONS = [
    "í™ˆ", "ê²½ì˜ í˜„í™©", "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ", "ê¸°ê°„ë³„ ë¶„ì„", "ê±°ë˜ ì¶”ê°€", 
    "ì¬ê³  ê´€ë¦¬", "AI ë¹„ì„œ", "ë°ì´í„° í¸ì§‘", "ê±°ë˜ ë‚´ì—­", "ì—°êµ¬ ê²€ì¦", "ë„ì›€ë§"
]

# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•± ì‹¤í–‰ ì‹œ 'í™ˆ'ìœ¼ë¡œ ì„¤ì •)
if "current_page" not in st.session_state:
    st.session_state.current_page = "í™ˆ"

# 3. í˜ì´ì§€ ë³€ê²½ í—¬í¼ í•¨ìˆ˜ (ë²„íŠ¼ í´ë¦­ ì‹œ ì‚¬ìš©)
def set_page(page_name):
    st.session_state.current_page = page_name

# 4. ì‚¬ì´ë“œë°” ì œê±°ë¨
# st.sidebar.radio(...) ê´€ë ¨ ì½”ë“œê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.

# 5. í˜„ì¬ í˜ì´ì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´
menu = st.session_state.current_page


# ==============================================================
# ğŸ  í™ˆ (ë©”ì¸ í™”ë©´)
# ==============================================================
if menu == "í™ˆ":
    st.header("ğŸ  ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë¦¬ ì‹œìŠ¤í…œ")
    st.write("ì›í•˜ì‹œëŠ” ë©”ë‰´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    # CSS ìŠ¤íƒ€ì¼ (ë²„íŠ¼ ë†’ì´ ë° í…ìŠ¤íŠ¸) - (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    st.markdown("""
    <style>
    /* 'border=True' ì»¨í…Œì´ë„ˆì˜ íŒ¨ë”©ì„ ì¡°ì ˆ */
    div[data-testid="stVerticalBlock"] > [data-testid="stVerticalBlockBorderWrapper"] {
        padding-top: 10px;
    }
    /* ë²„íŠ¼ ë†’ì´, í°íŠ¸ í¬ê¸° ì¡°ì ˆ */
    div[data-testid="stButton"] > button {
        height: 70px;
        font-size: 1.1rem;
        font-weight: 600;
    }
    .stButton p { /* ë²„íŠ¼ ë‚´ì˜ í…ìŠ¤íŠ¸(ì´ëª¨ì§€ í¬í•¨) */
        font-size: 1.1rem;
        font-weight: 600;
    }
    /* ë¶€ì œëª© í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ */
    .home-desc {
        text-align: center; 
        font-size: 0.9rem; 
        color: #555;
        margin-top: -10px; 
        padding-bottom: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

    # ë©”ë‰´ ì•„ì´í…œ ì •ì˜ (ì•„ì´ì½˜, ì´ë¦„, ì„¤ëª…)
    menu_items = {
        "ê²½ì˜ í˜„í™©": ("ğŸ“ˆ", "ì „ì²´ ê²½ì˜ í˜„í™© í™•ì¸"),
        "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ": ("ğŸ“Š", "ë§¤ì¶œ ë°ì´í„° ë¶„ì„"),
        "ê¸°ê°„ë³„ ë¶„ì„": ("ğŸ“…", "ê¸°ê°„ë³„ ë°ì´í„° ë¶„ì„"),
        "ê±°ë˜ ì¶”ê°€": ("â•", "ìƒˆë¡œìš´ ê±°ë˜ ë“±ë¡"),
        "ì¬ê³  ê´€ë¦¬": ("ğŸ“¦", "ì¬ê³  í˜„í™© ê´€ë¦¬"),
        "AI ë¹„ì„œ": ("ğŸ¤–", "AI ê¸°ë°˜ ì—…ë¬´ ì§€ì›"),
        "ë°ì´í„° í¸ì§‘": ("âœï¸", "ë°ì´í„° ìˆ˜ì • ë° ê´€ë¦¬"),
        "ê±°ë˜ ë‚´ì—­": ("ğŸ§¾", "ê±°ë˜ ì´ë ¥ ì¡°íšŒ"),
        "ì—°êµ¬ ê²€ì¦": ("ğŸ”¬", "ë°ì´í„° ê²€ì¦ ë° ì—°êµ¬"),
        "ë„ì›€ë§": ("â“", "ì‚¬ìš© ê°€ì´ë“œ ë° ì§€ì›"),
    }
    
    menu_keys = list(menu_items.keys())
    
    # 5x2 ê·¸ë¦¬ë“œ ìƒì„±
    for i in range(0, len(menu_keys), 5):
        cols = st.columns(5)
        current_row_keys = menu_keys[i:i+5]
        
        for col_index, key in enumerate(current_row_keys):
            icon, desc = menu_items[key]
            
            with cols[col_index].container(border=True):
                # [í•µì‹¬] ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ set_page í•¨ìˆ˜ê°€ í˜¸ì¶œë¨
                st.button(
                    label=f"{icon} {key}",
                    on_click=set_page,
                    args=(key,), # ğŸ‘ˆ This is the page name to pass to set_page
                    use_container_width=True,
                )
                # ë²„íŠ¼ ì•„ë˜ì— ì„¤ëª… ì¶”ê°€
                st.markdown(f"<div class='home-desc'>{desc}</div>", unsafe_allow_html=True)

# ==============================================================
# ğŸ§¾ ê±°ë˜ ì¶”ê°€ (ë²„íŠ¼ ê°€ì‹œì„± í–¥ìƒì„ ìœ„í•´ ìˆ˜ì •ëœ ì˜ˆì‹œ)
# ==============================================================

elif menu == "ê²½ì˜ í˜„í™©":
    # 1. st.columns()ì˜ ë°˜í™˜ê°’ì„ ì–¸íŒ¨í‚¹í•©ë‹ˆë‹¤. (í—¤ë”ê°€ í•„ìš” ì—†ìœ¼ë¯€ë¡œ, ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ë¬´ì‹œí•˜ê¸° ìœ„í•´ _ ì‚¬ìš©)
    _, col_button = st.columns([0.8, 0.2])
    
    # 2. ì´ì œ col_buttonì€ ë‘ ë²ˆì§¸ ì»¬ëŸ¼ ê°ì²´ì´ë¯€ë¡œ with êµ¬ë¬¸ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")
elif menu == "ê±°ë˜ ì¶”ê°€":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        # âœ¨ ì´ ì½”ë“œê°€ ë²„íŠ¼ì´ í—¤ë” ì˜†ì— ì˜ ë³´ì´ë„ë¡ ìˆ˜ì§ ì •ë ¬ì„ ë•ìŠµë‹ˆë‹¤.
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    
    st.markdown("---")

elif menu == "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
        
    st.markdown("---")

elif menu == "ê¸°ê°„ë³„ ë¶„ì„":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "ì¬ê³  ê´€ë¦¬":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "AI ë¹„ì„œ":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "ë°ì´í„° í¸ì§‘":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "ê±°ë˜ ë‚´ì—­":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")
    # try:
    #     df_raw, df_view = load_sales_with_id()

elif menu == "ì—°êµ¬ ê²€ì¦":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "ë„ì›€ë§":
    # 1. í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼ ì¶”ê°€ (ë‹¤ë¥¸ íƒ­ë“¤ê³¼ ë™ì¼í•œ íŒ¨í„´ ìœ ì§€)
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
        
    st.markdown("---")

# ==============================================================
# ğŸ§¾ ê±°ë˜ ì¶”ê°€
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
if menu == "ê±°ë˜ ì¶”ê°€":
    st.header(" ê±°ë˜ ë°ì´í„° ì¶”ê°€")
    
    # [ìˆ˜ì •] st.formì„ ì œê±°í•˜ê³ , ì¢…ì†í˜• ë©”ë‰´ë¥¼ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜í•©ë‹ˆë‹¤.
    df_order = df[df['ìƒí’ˆìƒì„¸'].isin(SEED_MENUS)].copy()
    if df_order.empty:
        # dfì— ë°ì´í„°ê°€ ì—†ì„ ë•Œë„ ì‹œë“œ ë©”ë‰´ 5ì¢…ì„ ì„ íƒí•  ìˆ˜ ìˆê²Œ ë”ë¯¸ ë°ì´í„° ìƒì„±
        st.info("ì£¼ë¬¸ ê°€ëŠ¥í•œ ë©”ë‰´ê°€ ì—†ì–´ì„œ ì‹œë“œ ë©”ë‰´ 5ì¢…ì„ ì„ì‹œë¡œ ì±„ì› ìŠµë‹ˆë‹¤.")
        df_order = pd.DataFrame({
            "ìƒí’ˆìƒì„¸": SEED_MENUS,
            "ìƒí’ˆìƒì„¸_en": [from_korean_detail(m) for m in SEED_MENUS],
            "ìƒí’ˆì¹´í…Œê³ ë¦¬": ["ê¸°íƒ€"] * len(SEED_MENUS),
            "ìƒí’ˆíƒ€ì…": ["ê¸°íƒ€"] * len(SEED_MENUS),
            "ë‹¨ê°€": [5000.0] * len(SEED_MENUS),  # ê¸°ë³¸ ë‹¨ê°€
            "ìˆ˜ëŸ‰": [1] * len(SEED_MENUS),
            "ìˆ˜ìµ": [5000.0] * len(SEED_MENUS),
            "ë‚ ì§œ": [pd.Timestamp.now()] * len(SEED_MENUS),
        })
    category_options = sorted(pd.Series(df_order['ìƒí’ˆì¹´í…Œê³ ë¦¬']).dropna().unique().tolist())
    
    # --- 1. ì¹´í…Œê³ ë¦¬ ì„ íƒ ---
    ìƒí’ˆì¹´í…Œê³ ë¦¬_ko = st.selectbox("1. ìƒí’ˆì¹´í…Œê³ ë¦¬ ì„ íƒ", category_options, index=None, placeholder="ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”...")

    # --- 2. íƒ€ì… ì„ íƒ (ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ í•„í„°ë§) ---
    if ìƒí’ˆì¹´í…Œê³ ë¦¬_ko:
        df_filtered_type = df_order[df_order['ìƒí’ˆì¹´í…Œê³ ë¦¬'] == ìƒí’ˆì¹´í…Œê³ ë¦¬_ko]
        type_options = sorted(pd.Series(df_filtered_type['ìƒí’ˆíƒ€ì…']).dropna().unique().tolist())
        
        ìƒí’ˆíƒ€ì…_ko = st.selectbox("2. ìƒí’ˆíƒ€ì… ì„ íƒ", type_options, index=None, placeholder="ìƒí’ˆíƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”...")

        # --- 3. ìƒì„¸ ë©”ë‰´ ì„ íƒ (íƒ€ì…ì— ë”°ë¼ í•„í„°ë§) ---
        if ìƒí’ˆíƒ€ì…_ko:
            df_filtered_detail = df_filtered_type[df_filtered_type['ìƒí’ˆíƒ€ì…'] == ìƒí’ˆíƒ€ì…_ko]
            detail_options = sorted(pd.Series(df_filtered_detail['ìƒí’ˆìƒì„¸']).dropna().unique().tolist())
            
            ìƒí’ˆìƒì„¸_ko = st.selectbox("3. ìƒí’ˆìƒì„¸ ì„ íƒ", detail_options, index=None, placeholder="ìƒì„¸ ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”...")

            # --- 4. ìˆ˜ëŸ‰ ë° ë‹¨ê°€ ì…ë ¥ (ë©”ë‰´ê°€ í™•ì •ëœ í›„) ---
            if ìƒí’ˆìƒì„¸_ko:
                
                # [UX ê°œì„  2] ì„ íƒí•œ ë©”ë‰´ì˜ 'ìµœê·¼ ë‹¨ê°€'ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
                try:
                    # dfì—ì„œ ì´ ë©”ë‰´ì˜ ê°€ì¥ ë§ˆì§€ë§‰(ìµœê·¼) 'ë‹¨ê°€'ë¥¼ ì°¾ì•„ ì œì•ˆ
                    last_price = df[df['ìƒí’ˆìƒì„¸'] == ìƒí’ˆìƒì„¸_ko]['ë‹¨ê°€'].iloc[-1]
                    last_price = float(last_price)
                except Exception:
                    last_price = 1000.0 # ëª»ì°¾ìœ¼ë©´ ê¸°ë³¸ê°’

                st.markdown("---")
                
                col1, col2 = st.columns(2)
                with col1:
                    ìˆ˜ëŸ‰ = st.number_input("ìˆ˜ëŸ‰", min_value=1, value=1)
                with col2:
                    ë‹¨ê°€ = st.number_input(
                        "ë‹¨ê°€(ì›)", 
                        min_value=0.0, 
                        value=last_price, # ğŸ‘ˆ ìë™ìœ¼ë¡œ ì°¾ì€ ìµœê·¼ ë‹¨ê°€ë¥¼ ì œì•ˆ
                        step=100.0
                    )
                
                ë‚ ì§œ = st.date_input("ë‚ ì§œ", value=datetime.now().date())
                
                ìˆ˜ìµ = ìˆ˜ëŸ‰ * ë‹¨ê°€
                st.markdown(f"### ğŸ’° ê³„ì‚°ëœ ìˆ˜ìµ: **{format_krw(ìˆ˜ìµ)}**")
                
                # [ìˆ˜ì •] st.form_submit_button ëŒ€ì‹  st.button ì‚¬ìš©
                submitted = st.button("ë°ì´í„° ì¶”ê°€")
                
                if submitted:
                    # ... (ì´í•˜ ë°ì´í„° ì €ì¥ ë¡œì§ì€ ë™ì¼) ...
                    ìƒí’ˆì¹´í…Œê³ ë¦¬_en = rev_category_map.get(ìƒí’ˆì¹´í…Œê³ ë¦¬_ko, ìƒí’ˆì¹´í…Œê³ ë¦¬_ko)
                    ìƒí’ˆíƒ€ì…_en = rev_type_map.get(ìƒí’ˆíƒ€ì…_ko, ìƒí’ˆíƒ€ì…_ko)
                    ìƒí’ˆìƒì„¸_en = from_korean_detail(ìƒí’ˆìƒì„¸_ko)
                    
                    new_doc = {
                        "ë‚ ì§œ": str(ë‚ ì§œ),
                        "ìƒí’ˆìƒì„¸": ìƒí’ˆìƒì„¸_en,
                        "ìƒí’ˆìƒì„¸_ko": ìƒí’ˆìƒì„¸_ko,
                        "ìƒí’ˆì¹´í…Œê³ ë¦¬": ìƒí’ˆì¹´í…Œê³ ë¦¬_en,
                        "ìƒí’ˆíƒ€ì…": ìƒí’ˆíƒ€ì…_en,
                        "ìˆ˜ëŸ‰": ìˆ˜ëŸ‰,
                        "ë‹¨ê°€": ë‹¨ê°€,
                        "ìˆ˜ìµ": ìˆ˜ìµ,
                        "ê°€ê²Œìœ„ì¹˜": "Firebase",
                        "ê°€ê²ŒID": "LOCAL",
                        "ì‹œê°„": datetime.now().strftime("%H:%M:%S"),
                    }
                    try:
                        db.collection(SALES_COLLECTION).add(new_doc)
                        st.success(f"âœ… '{ìƒí’ˆìƒì„¸_ko}' {ìˆ˜ëŸ‰}ê±´ ì¶”ê°€ ì™„ë£Œ!")
                        
                        with st.spinner("ì¬ê³  ìë™ ì°¨ê° ì ìš© ì¤‘..."):
                            adjust_inventory_by_recipe(
                                ìƒí’ˆìƒì„¸_en,
                                ìˆ˜ëŸ‰,
                                move_type="sale",
                                note=f"ê±°ë˜ ì¶”ê°€: {ìƒí’ˆìƒì„¸_ko} x{ìˆ˜ëŸ‰}"
                            )
                        st.success("âœ… ì¬ê³  ì°¨ê° ì™„ë£Œ!")
                        safe_rerun()
                    except Exception as e:
                        st.error(f"ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {e}")

# ==============================================================
# ğŸ“Š ê²½ì˜ í˜„í™©
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê²½ì˜ í˜„í™©":
    st.header("ğŸ“Š ê²½ì˜ í˜„í™©")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        total_revenue = df['ìˆ˜ìµ'].sum()
        total_sales_count = df.shape[0]
        avg_revenue_per_sale = total_revenue / total_sales_count if total_sales_count > 0 else 0
        
        st.markdown(
            f"""
            <div style="display:grid; grid-template-columns:1fr 1fr 1fr; gap:16px; margin-bottom:20px;">
                <div class="metric-card">
                    <div class="metric-title">ì´ ë§¤ì¶œ</div>
                    <div class="metric-value">{format_krw(total_revenue)}</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">ì´ íŒë§¤ ê±´ìˆ˜</div>
                    <div class="metric-value">{total_sales_count:,} ê±´</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">ê±´ë‹¹ í‰ê·  ë§¤ì¶œ</div>
                    <div class="metric-value">{format_krw(avg_revenue_per_sale)}</div>
                </div>
            </div>
            """, unsafe_allow_html=True
        )

        if not df.empty:
            try:
                top_cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
                top_prod = df.groupby('ìƒí’ˆíƒ€ì…')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
                st.info(f"ğŸ† ê°€ì¥ ë§¤ì¶œ ë†’ì€ ì¹´í…Œê³ ë¦¬: **{top_cat.index[0]}** ({format_krw(top_cat.iloc[0])}) / ìƒí’ˆ: **{top_prod.index[0]}**")
            except Exception:
                st.info("ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ìƒìœ„ í•­ëª©ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        col4, col5 = st.columns(2)
        with col4:
            # ì—¬ê¸°ëŠ” 'ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ' ë§‰ëŒ€ ì°¨íŠ¸
            cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().reset_index()
            
            # [ìˆ˜ì • 1] í´ ìˆ˜ë¡ ì˜¤ë¥¸ìª½ì— ìˆë„ë¡ 'ì˜¤ë¦„ì°¨ìˆœ(ascending=True)'ìœ¼ë¡œ ì •ë ¬
            cat = cat.sort_values('ìˆ˜ìµ', ascending=True) 
            
            fig_cat = px.bar(cat, x='ìƒí’ˆì¹´í…Œê³ ë¦¬', y='ìˆ˜ìµ', title="ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ")
            
            # [ìˆ˜ì • 2] í•˜ì´ë¸Œë¦¬ë“œ UX ì ìš©
            fig_cat.update_layout(
                yaxis_tickformat=None # Yì¶•: M/k ì¶•ì•½í˜•
            )
            fig_cat.update_traces(
                hovertemplate="ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>" # íˆ´íŒ: ì „ì²´ ìˆ«ì
            )
            
            st.plotly_chart(fig_cat, use_container_width=True)
        with col5:
            # [ë³µêµ¬] ì—¬ê¸°ê°€ 'ì¼ìë³„ ë§¤ì¶œ ì¶”ì´' ì›ë³¸ì…ë‹ˆë‹¤.
            daily = df.groupby('ë‚ ì§œ')['ìˆ˜ìµ'].sum().reset_index()
            
            # [ìˆ˜ì • 1] ìˆ˜ìµì´ 0ì¸ ë‚ ì§œ(ê·¸ë˜í”„ê°€ 0ìœ¼ë¡œ ë‚´ë ¤ê°€ëŠ” ì§€ì )ë¥¼ ì œì™¸í•©ë‹ˆë‹¤.
            daily_filtered = daily[daily['ìˆ˜ìµ'] > 0]
            
            fig_trend = px.line(
                daily_filtered,  # ğŸ‘ˆ 0ì›ì¸ ë‚ ì§œê°€ ì œì™¸ëœ ë°ì´í„° ì‚¬ìš©
                x='ë‚ ì§œ', 
                y='ìˆ˜ìµ', 
                title="ì¼ìë³„ ë§¤ì¶œ ì¶”ì´"
            )

            # [ìˆ˜ì • 2] í•˜ì´ë¸Œë¦¬ë“œ UX ì ìš©
            fig_trend.update_layout(
                yaxis_tickformat=None # Yì¶•: M/k ì¶•ì•½í˜•
            )
            fig_trend.update_traces(
                # íˆ´íŒ: "2025-01-15<br>ë§¤ì¶œ: 4,500,000ì›" í˜•ì‹
                hovertemplate="<b>%{x|%Y-%m-%d}</b><br>ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>" 
            )

            st.plotly_chart(fig_trend, use_container_width=True)

# ==============================================================
# ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ":
    st.header("ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        
        # [ìˆ˜ì •] 1. ì§‘ê³„ ì „, 'ë‚ ì§œ'ì™€ 'ìƒí’ˆì¹´í…Œê³ ë¦¬'ê°€ ë¹„ì–´ìˆëŠ”(NaN) ë°ì´í„°ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        df_clean = df.dropna(subset=['ë‚ ì§œ', 'ìƒí’ˆì¹´í…Œê³ ë¦¬'])

        if df_clean.empty:
            st.warning("ğŸ“ˆ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë‚ ì§œ ë˜ëŠ” ì¹´í…Œê³ ë¦¬ ì •ë³´ê°€ ë¹„ì–´ìˆìŒ)")
        else:
            # [ìˆ˜ì •] 2. 'ì›”'ê³¼ 'ìƒí’ˆì¹´í…Œê³ ë¦¬'ë³„ë¡œ ìˆ˜ìµì„ ì§‘ê³„í•©ë‹ˆë‹¤.
            try:
                monthly_stacked_df = df_clean.groupby([
                    df_clean['ë‚ ì§œ'].dt.to_period("M"), 
                    'ìƒí’ˆì¹´í…Œê³ ë¦¬'
                ])['ìˆ˜ìµ'].sum().reset_index()
                
                # [ìˆ˜ì •] 3. Plotlyë¥¼ ìœ„í•´ Period(ê¸°ê°„) ê°ì²´ë¥¼ Timestamp(ë‚ ì§œ)ë¡œ ë³€ê²½
                monthly_stacked_df['ë‚ ì§œ'] = monthly_stacked_df['ë‚ ì§œ'].dt.to_timestamp()

            except Exception as e:
                st.error(f"ë°ì´í„° ì§‘ê³„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.dataframe(df_clean[['ë‚ ì§œ', 'ìƒí’ˆì¹´í…Œê³ ë¦¬']]) # ì˜¤ë¥˜ íŒŒì•…ì„ ìœ„í•´ ì›ë³¸ ë°ì´í„° í‘œì‹œ
                monthly_stacked_df = pd.DataFrame() # ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì´ˆê¸°í™”

            # [ìˆ˜ì •] 4. ì§‘ê³„ëœ ë°ì´í„°ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸
            if monthly_stacked_df.empty:
                st.warning("ğŸ“ˆ ì›”ë³„/ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì§‘ê³„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                
                # [ìˆ˜ì • 1] Xì¶•ì„ í•œê¸€ë¡œ ë§Œë“¤ê¸° ìœ„í•´ 'ë‚ ì§œ' ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ê°€ê³µ
                # ì˜ˆ: '2025-01-01' -> '2025ë…„ 01ì›”'
                monthly_stacked_df['ì›”(í•œê¸€)'] = monthly_stacked_df['ë‚ ì§œ'].dt.strftime('%Yë…„ %mì›”')

                # [ìˆ˜ì • 2] 'px.bar'ë¥¼ ì‚¬ìš©í•´ ëˆ„ì  ë§‰ëŒ€ ê·¸ë˜í”„(Stacked Bar Chart) ìƒì„±
                fig_stacked_bar = px.bar(
                    monthly_stacked_df, 
                    x='ì›”(í•œê¸€)',      # ğŸ‘ˆ Xì¶•ì„ ìƒˆë¡œ ë§Œë“  í•œê¸€ ë¬¸ìì—´ ì»¬ëŸ¼ìœ¼ë¡œ ë³€ê²½
                    y='ìˆ˜ìµ',          
                    color='ìƒí’ˆì¹´í…Œê³ ë¦¬', 
                    title="ì›”ë³„/ì¹´í…Œê³ ë¦¬ë³„ ëˆ„ì  ë§¤ì¶œ",
                )
                
                # [ìˆ˜ì • 3] Yì¶•ì˜ 'M' ë‹¨ìœ„ë¥¼ ì‰¼í‘œ(,)ê°€ ìˆëŠ” ì „ì²´ ìˆ«ìë¡œ ë³€ê²½
                fig_stacked_bar.update_layout(
                    # [ì œê±°] 'yaxis_tickformat'ì„ ì œê±°í•˜ë©´
                    # Plotlyê°€ ìë™ìœ¼ë¡œ '100M'ì²˜ëŸ¼ ì¶•ì•½í•´ ì¤ë‹ˆë‹¤.
                    # yaxis_tickformat=',.0f', ğŸ‘ˆ ì´ ì¤„ì„ ì‚­ì œí•˜ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬
                    
                    xaxis_title="ì›”",        # Xì¶• ì œëª©
                    legend_itemclick=False # ë²”ë¡€ í´ë¦­ ë¹„í™œì„±í™”
                )
                
                # [ìˆ˜ì • 4] ë§ˆìš°ìŠ¤ ì˜¤ë²„(íˆ´íŒ)ì—ë„ 'M' ëŒ€ì‹  ì „ì²´ ìˆ«ìê°€ ë‚˜ì˜¤ë„ë¡ ìˆ˜ì •
                fig_stacked_bar.update_traces(
                    hovertemplate="<b>%{data.name}</b><br>ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>"
                )
                
                # ì°¨íŠ¸ê°€ ê°€ìš´ë°(ì „ì²´ ë„ˆë¹„)ì— ì˜¤ë„ë¡ ë°”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
                st.plotly_chart(fig_stacked_bar, use_container_width=True)

        
        # [ìˆ˜ì •] Sunburst ì°¨íŠ¸ë¥¼ Treemapìœ¼ë¡œ ë³€ê²½
        # [ìˆ˜ì •] Sunburst ì°¨íŠ¸ë¥¼ Treemapìœ¼ë¡œ ë³€ê²½
        prod_sales = df.groupby(['ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸'])['ìˆ˜ìµ'].sum().reset_index()
        
        # [ì¶”ê°€] ì§‘ê³„ëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not prod_sales.empty:
            fig_treemap = px.treemap(
                prod_sales, 
                path=['ìƒí’ˆíƒ€ì…', 'ìƒí’ˆìƒì„¸'], # ê³„ì¸µ êµ¬ì¡°: íƒ€ì… > ìƒì„¸
                values='ìˆ˜ìµ',               # íƒ€ì¼ í¬ê¸°
                title="ìƒí’ˆ êµ¬ì¡°ë³„ ë§¤ì¶œ (íŠ¸ë¦¬ë§µ)",
                
                # color='ìˆ˜ìµ',
                # color_continuous_scale=px.colors.sequential.Blues
            )
            
            # [UX ê°œì„ ] ìš”ì²­í•˜ì‹  3ê°€ì§€(íˆ´íŒ, ê°€ë…ì„±, í…ìŠ¤íŠ¸)ë¥¼ ì—¬ê¸°ì„œ ìˆ˜ì •í•©ë‹ˆë‹¤.
            fig_treemap.update_traces(
                
                # 1. íˆ´íŒ (ë§ˆìš°ìŠ¤ ì˜¬ë ¸ì„ ë•Œ) - "ì •í™•í•œ ì „ì²´ ìˆ«ì"
                # "k", "M" ì—†ì´ 1,234,567ì› í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                hovertemplate=(
                    "<b>%{label}</b><br>" +     
                    "ë§¤ì¶œ: %{value:,.0f}ì›" +   
                    "<extra></extra>"         
                ),
                
                # 2. íƒ€ì¼ ìœ„ í…ìŠ¤íŠ¸ (ë²„ê·¸ ìˆ˜ì • ë° UX ê°œì„ )
                # 'texttemplate' ëŒ€ì‹  'textinfo="label+value"'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                # íƒ€ì¼ ìœ„ì— "ì•„ë©”ë¦¬ì¹´ë…¸"ì™€ "150M"ì²˜ëŸ¼
                # ë ˆì´ë¸”ê³¼ 'ì¶•ì•½í˜•' ê°’ì´ í•¨ê»˜ í‘œì‹œë©ë‹ˆë‹¤.
                # (ì´ ë°©ì‹ì€ 'ë°”ê¹¥ íƒ­' ë²„ê·¸ë„ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)
                textinfo="label+value",
                textposition='middle center', 
                textfont_size=14
            )
            
            st.plotly_chart(fig_treemap, use_container_width=True) # ğŸ‘ˆ ê°œì„ ëœ ì°¨íŠ¸ë¥¼ í‘œì‹œ
        else:
            st.info("íŠ¸ë¦¬ë§µì„ í‘œì‹œí•  ìƒí’ˆ êµ¬ì¡° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
# ==============================================================
# ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê¸°ê°„ë³„ ë¶„ì„":
    # -----------------------------------------------------------
    # ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„ (React UI í¬íŒ… ë²„ì „)
    # -----------------------------------------------------------
    st.header("ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„")
    
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # [0] ë‚ ì§œ í•„í„° ìƒíƒœ ê´€ë¦¬ (ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì‚¬ìš©)
        # ì•±ì´ ë¦¬ë¡œë“œë˜ì–´ë„ ë‚ ì§œ ì„¤ì •ì´ ìœ ì§€ë˜ë„ë¡ í•©ë‹ˆë‹¤.
        if 'anl_start_date' not in st.session_state:
            st.session_state.anl_start_date = df['ë‚ ì§œ'].max().date() - pd.Timedelta(days=29) # ê¸°ë³¸ 1ê°œì›”
        if 'anl_end_date' not in st.session_state:
            st.session_state.anl_end_date = df['ë‚ ì§œ'].max().date()

        # [1] ìƒë‹¨ ì»¨íŠ¸ë¡¤ íŒ¨ë„ (ë‚ ì§œ ì„ íƒ + í€µ ë²„íŠ¼ + KPI ì¹´ë“œ)
        # Reactì˜ ë ˆì´ì•„ì›ƒ: ì¢Œì¸¡(ë‚ ì§œ ì»¨íŠ¸ë¡¤) / ìš°ì¸¡(ë§¤ì¶œ ìš”ì•½)
        
        # ì „ì²´ë¥¼ ê°ì‹¸ëŠ” ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼
        st.markdown("""
        <style>
        .control-panel {
            background-color: white;
            padding: 20px;
            border-radius: 12px;
            border: 1px solid #e2e8f0;
            box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
            margin-bottom: 24px;
        }
        .metric-box {
            padding: 16px 20px;
            border-radius: 12px;
            border: 1px solid;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
            color: #1e293b;
        }
        </style>
        """, unsafe_allow_html=True)

        with st.container():
            col_ctrl, col_kpi = st.columns([1, 1.2])

            # --- ì¢Œì¸¡: ë‚ ì§œ ì„ íƒ ë° í€µ ë²„íŠ¼ ---
            with col_ctrl:
                st.markdown("### ğŸ“… ì¡°íšŒ ê¸°ê°„ ì„¤ì •")
                
                # í€µ ë²„íŠ¼ ë¡œì§
                def set_period(days):
                    end = df['ë‚ ì§œ'].max().date() # ê¸°ì¤€ì€ ë°ì´í„°ì˜ ê°€ì¥ ìµœê·¼ ë‚ ì§œ
                    start = end - pd.Timedelta(days=days - 1) # inclusive ê³„ì‚° (7ì¼ì´ë©´ ì˜¤ëŠ˜ í¬í•¨ 7ì¼ì „)
                    st.session_state.anl_start_date = start
                    st.session_state.anl_end_date = end

                # í€µ ë²„íŠ¼ UI
                b_col1, b_col2, b_col3, _ = st.columns([1, 1, 1, 2])
                if b_col1.button("1ì£¼ì¼"): set_period(7); safe_rerun()
                if b_col2.button("1ê°œì›”"): set_period(30); safe_rerun()
                if b_col3.button("3ê°œì›”"): set_period(90); safe_rerun()

                # ë‚ ì§œ ì„ íƒê¸° (ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì™€ ì—°ë™)
                c_d1, c_d2 = st.columns(2)
                new_start = c_d1.date_input("ì‹œì‘ì¼", value=st.session_state.anl_start_date, max_value=df['ë‚ ì§œ'].max().date())
                new_end = c_d2.date_input("ì¢…ë£Œì¼", value=st.session_state.anl_end_date, min_value=new_start, max_value=df['ë‚ ì§œ'].max().date())
                
                # ìˆ˜ë™ ë³€ê²½ ê°ì§€ ì‹œ ì—…ë°ì´íŠ¸
                if new_start != st.session_state.anl_start_date or new_end != st.session_state.anl_end_date:
                    st.session_state.anl_start_date = new_start
                    st.session_state.anl_end_date = new_end
                    safe_rerun()

            # --- ë°ì´í„° í•„í„°ë§ ---
            # ì„ íƒëœ ë‚ ì§œë¡œ ë°ì´í„° í•„í„°ë§
            mask = (df['ë‚ ì§œ'].dt.date >= st.session_state.anl_start_date) & (df['ë‚ ì§œ'].dt.date <= st.session_state.anl_end_date)
            filtered_df = df[mask]
            
            # --- ìš°ì¸¡: KPI ì¹´ë“œ (ì´ ë§¤ì¶œ & ë¹„êµ ë¶„ì„) ---
            with col_kpi:
                if filtered_df.empty:
                    st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    total_revenue = 0
                    diff_revenue = 0
                    duration_days = 0
                    percent_change = 0
                else:
                    # 1. í˜„ì¬ ê¸°ê°„ ë§¤ì¶œ
                    total_revenue = filtered_df['ìˆ˜ìµ'].sum()

                    # 2. ì§ì „ ê¸°ê°„ ë§¤ì¶œ ë¹„êµ ë¡œì§
                    start_date = pd.to_datetime(st.session_state.anl_start_date)
                    end_date = pd.to_datetime(st.session_state.anl_end_date)

                    # ê¸°ê°„ ì¼ìˆ˜ ê³„ì‚° (inclusive)
                    duration_days = (end_date - start_date).days + 1

                    # ì§ì „ ê¸°ê°„ ê³„ì‚°
                    prev_end = start_date - pd.Timedelta(days=1)
                    prev_start = prev_end - pd.Timedelta(days=duration_days - 1)

                    prev_mask = (df['ë‚ ì§œ'] >= prev_start) & (df['ë‚ ì§œ'] <= prev_end)
                    prev_revenue = df[prev_mask]['ìˆ˜ìµ'].sum()

                    # ğŸ‘‰ ì´ì „ ê¸°ê°„ ë§¤ì¶œì´ 0ì´ë©´ 'ë¹„êµ ë¶ˆê°€' ìƒíƒœë¡œ ì²˜ë¦¬
                    if prev_revenue == 0:
                        diff_revenue = 0
                        compare_label = f"ì§€ë‚œ {duration_days}ì¼ ëŒ€ë¹„"
                        diff_text = "ì´ì „ ê¸°ê°„ ë°ì´í„° ì—†ìŒ"
                        is_comparable = False
                    else:
                        diff_revenue = total_revenue - prev_revenue
                        compare_label = f"ì§€ë‚œ {duration_days}ì¼ ëŒ€ë¹„"
                        diff_text = f"{abs(diff_revenue):,.0f}ì›"
                        is_comparable = True

                    
                    # HTML/CSSë¡œ KPI ì¹´ë“œ ë Œë”ë§ (React ë””ìì¸ í¬íŒ…)
                    # ìƒ‰ìƒ ê²°ì •
                    if diff_revenue > 0:
                        bg_color = "linear-gradient(135deg, #ecfdf5 0%, #ffffff 100%)" # Emerald-50
                        border_color = "#d1fae5" # Emerald-100
                        text_color = "#059669" # Emerald-600
                        icon = "â–²"
                    elif diff_revenue < 0:
                        bg_color = "linear-gradient(135deg, #fff1f2 0%, #ffffff 100%)" # Rose-50
                        border_color = "#ffe4e6" # Rose-100
                        text_color = "#e11d48" # Rose-600
                        icon = "â–¼"
                    else:
                        bg_color = "#f8fafc"
                        border_color = "#e2e8f0"
                        text_color = "#64748b"
                        icon = "-"
                    
                    st.markdown(
                            f"""<div style="display: flex; gap: 16px; margin-top: 10px;">
                        <!-- ì´ ë§¤ì¶œ ì¹´ë“œ -->
                        <div style="flex: 1; background: linear-gradient(135deg, #eff6ff 0%, #ffffff 100%); border: 1px solid #dbeafe; border-radius: 12px; padding: 16px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                            <div style="color: #2563eb; font-weight: 700; font-size: 0.9rem; text-transform: uppercase; letter-spacing: 0.05em; margin-bottom: 4px;">ì´ ë§¤ì¶œ</div>
                            <div style="display: flex; align-items: baseline; gap: 4px;">
                            <span style="font-size: 2.2rem; font-weight: 800; color: #0f172a;">{total_revenue:,.0f}</span>
                            <span style="font-size: 1.2rem; font-weight: 700; color: #64748b;">ì›</span>
                            </div>
                        </div>

                        <!-- ë¹„êµ ì¹´ë“œ -->
                        <div style="flex: 1; background: {bg_color}; border: 1px solid {border_color}; border-radius: 12px; padding: 16px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                            <div style="display: flex; align-items: center; justify-content: space-between;">
                            <div style="color: {text_color}; font-weight: 700; font-size: 0.9rem; text-transform: uppercase; letter-spacing: 0.05em; margin-bottom: 4px;">ì§€ë‚œ {duration_days}ì¼ ëŒ€ë¹„</div>
                            <div style="background-color: {text_color}20; color: {text_color}; padding: 2px 6px; border-radius: 99px; font-size: 0.75rem; font-weight: bold;">{icon}</div>
                            </div>
                            <div style="display: flex; align-items: baseline; gap: 4px;">
                            <span style="font-size: 1.8rem; font-weight: 800; color: #0f172a;">{abs(diff_revenue):,.0f}</span>
                            <span style="font-size: 1.0rem; font-weight: 700; color: #64748b;">ì›</span>
                            </div>
                        </div>
                        </div>""",
                            unsafe_allow_html=True,
                        )


            
        st.markdown("---")

        if not filtered_df.empty:
            c_chart1, c_chart2 = st.columns(2)
            
            # -----------------------------------------------------------
            # [Chart 1] ìš”ì¼ë³„ ë§¤ì¶œ (WeeklyChart.tsx í¬íŒ…)
            # -----------------------------------------------------------
            with c_chart1:
                st.subheader("ğŸ“Š ìš”ì¼ë³„ ë§¤ì¶œ")
                
                # ê¸ˆìš”ì¼ ì£¼ë§ í¬í•¨ í† ê¸€
                col_head, col_tog = st.columns([2, 1])
                with col_tog:
                    include_friday = st.toggle("ê¸ˆìš”ì¼ ì£¼ë§ í¬í•¨", value=True)
                
                # ë°ì´í„° ì§‘ê³„
                week_sales = filtered_df.groupby('ìš”ì¼')['ìˆ˜ìµ'].sum().reindex(weekday_order_kr).fillna(0)
                
                # ìƒ‰ìƒ ê²°ì • ë¡œì§
                colors = []
                for day in week_sales.index:
                    if day in ['í† ', 'ì¼']:
                        colors.append('#f97316') # ì£¼ë§ (Orange)
                    elif day == 'ê¸ˆ' and include_friday:
                        colors.append('#f97316') # ê¸ˆìš”ì¼ ì£¼ë§ í¬í•¨ ì‹œ
                    else:
                        colors.append('#3b82f6') # í‰ì¼ (Blue)

                # Yì¶• ìµœì†Œê°’ ê³„ì‚° (10ë§Œ ë‹¨ìœ„ ë‚´ë¦¼)
                min_rev = week_sales[week_sales > 0].min() if not week_sales[week_sales > 0].empty else 0
                max_rev = week_sales.max()
                y_min = (min_rev // 100000) * 100000
                y_max = max_rev * 1.1 # ì—¬ìœ  ê³µê°„

                # Plotly GO ì‚¬ìš© (ì„¸ë°€í•œ ì œì–´)
                fig_week = go.Figure()
                fig_week.add_trace(go.Bar(
                    x=week_sales.index,
                    y=week_sales.values,
                    marker_color=colors,
                    hovertemplate='<b>%{x}ìš”ì¼</b><br>ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>'
                ))
                
                fig_week.update_layout(
                    yaxis=dict(
                        range=[y_min, y_max],
                        tickformat=',.0f', # 'ë§Œ' ë‹¨ìœ„ ì²˜ë¦¬ëŠ” í…ìŠ¤íŠ¸ ëŒ€ì²´ê°€ ë³µì¡í•˜ë¯€ë¡œ ì½¤ë§ˆ í¬ë§· ì‚¬ìš©
                        title=None
                    ),
                    xaxis=dict(title=None),
                    plot_bgcolor='rgba(0,0,0,0.02)',
                    margin=dict(t=10, b=0, l=0, r=0),
                    showlegend=False,
                    height=350
                )
                
                st.plotly_chart(fig_week, use_container_width=True)
                
                # ë²”ë¡€ (HTML)
                st.markdown("""
                <div style="display: flex; justify-content: center; gap: 16px; margin-top: -10px; font-size: 0.8rem; color: #64748b;">
                    <div style="display: flex; align-items: center; gap: 4px;"><span style="width: 10px; height: 10px; background-color: #3b82f6; border-radius: 50%;"></span> í‰ì¼</div>
                    <div style="display: flex; align-items: center; gap: 4px;"><span style="width: 10px; height: 10px; background-color: #f97316; border-radius: 50%;"></span> ì£¼ë§</div>
                </div>
                """, unsafe_allow_html=True)

            # -----------------------------------------------------------
            # [Chart 2] ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ ì¶”ì´ (HourlyChart.tsx í¬íŒ…)
            # -----------------------------------------------------------
            with c_chart2:
                st.subheader("â° ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ ì¶”ì´ (ì´ìƒ ê°ì§€)")
                
                # ì˜ì—… ì‹œê°„ ì„¤ì • í•„í„°
                h_c1, h_c2 = st.columns(2)
                with h_c1:
                    start_h = st.selectbox("ì˜ì—… ì‹œì‘", range(0, 24), index=9)
                with h_c2:
                    end_h = st.selectbox("ì˜ì—… ì¢…ë£Œ", range(0, 24), index=22)
                
                if start_h > end_h:
                    st.error("ì‹œì‘ ì‹œê°„ì´ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ ëŠ¦ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    end_h = start_h
                
                # ë°ì´í„° ì§‘ê³„
                hourly_sales = filtered_df.groupby('ì‹œ')['ìˆ˜ìµ'].sum().reindex(range(24)).fillna(0).reset_index()
                
                # í•„í„°ë§
                hourly_sales = hourly_sales[(hourly_sales['ì‹œ'] >= start_h) & (hourly_sales['ì‹œ'] <= end_h)]
                
                # í†µê³„ ê³„ì‚° (í‰ê· , ì£¼ì˜, ìœ„í—˜)
                non_zero = hourly_sales[hourly_sales['ìˆ˜ìµ'] > 0]['ìˆ˜ìµ']

                if not non_zero.empty:
                    mean_val = non_zero.mean()
                else:
                    mean_val = 0

                warning_val = mean_val * 0.6
                critical_val = mean_val * 0.3
                
                # ìƒ‰ìƒ ê²°ì • ë¡œì§ (ì  ìƒ‰ìƒ)
                point_colors = []
                for val in hourly_sales['ìˆ˜ìµ']:
                    if val < critical_val:
                        point_colors.append('#ef4444') # Red (ì €ì¡°)
                    elif val < warning_val:
                        point_colors.append('#eab308') # Yellow (ì£¼ì˜)
                    else:
                        point_colors.append('#08519c') # Blue (ì •ìƒ)

                # ê·¸ë¼ë””ì–¸íŠ¸ ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ (Marker + Line)
                fig_hour = go.Figure()
                
                # 1. ì—°ê²° ì„  (ê¸°ë³¸ íšŒìƒ‰/íŒŒë€ìƒ‰ í†¤)
                fig_hour.add_trace(go.Scatter(
                    x=hourly_sales['ì‹œ'],
                    y=hourly_sales['ìˆ˜ìµ'],
                    mode='lines',
                    line=dict(color='#cbd5e1', width=2), # ê¸°ë³¸ ì„ ì€ ì—°í•˜ê²Œ
                    hoverinfo='skip'
                ))
                
                # 2. ë°ì´í„° í¬ì¸íŠ¸ (ìƒíƒœë³„ ìƒ‰ìƒ)
                fig_hour.add_trace(go.Scatter(
                    x=hourly_sales['ì‹œ'],
                    y=hourly_sales['ìˆ˜ìµ'],
                    mode='markers',
                    marker=dict(
                        color=point_colors,
                        size=8,
                        line=dict(color='white', width=1)
                    ),
                    hovertemplate='<b>%{x}ì‹œ</b><br>ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>'
                ))
                
                # 3. í‰ê· ì„  (Reference Line)
                fig_hour.add_shape(
                    type="line",
                    x0=start_h, x1=end_h,
                    y0=mean_val, y1=mean_val,
                    line=dict(color="#94a3b8", width=1, dash="dash"),
                )
                fig_hour.add_annotation(
                    x=end_h, y=mean_val,
                    text="í‰ê· ",
                    showarrow=False,
                    yshift=10,
                    font=dict(size=10, color="#64748b")
                )

                fig_hour.update_layout(
                    yaxis=dict(
                        tickformat=',.0f',
                        title=None
                    ),
                    xaxis=dict(
                        title="ì‹œê°„ (ì‹œ)",
                        tickmode='linear',
                        dtick=2 if (end_h - start_h) > 12 else 1
                    ),
                    plot_bgcolor='white',
                    margin=dict(t=10, b=0, l=0, r=0),
                    showlegend=False,
                    height=350
                )
                
                st.plotly_chart(fig_hour, use_container_width=True)
                
                # ë²”ë¡€ (HTML)
                st.markdown("""
                <div style="display: flex; justify-content: center; gap: 12px; margin-top: -10px; font-size: 0.75rem; color: #64748b;">
                    <div style="display: flex; align-items: center; gap: 4px;"><span style="width: 8px; height: 8px; background-color: #08519c; border-radius: 50%;"></span> ì •ìƒ</div>
                    <div style="display: flex; align-items: center; gap: 4px;"><span style="width: 8px; height: 8px; background-color: #eab308; border-radius: 50%;"></span> ì£¼ì˜ (<60%)</div>
                    <div style="display: flex; align-items: center; gap: 4px;"><span style="width: 8px; height: 8px; background-color: #ef4444; border-radius: 50%;"></span> ì €ì¡° (<30%)</div>
                </div>
                """, unsafe_allow_html=True)
# ==============================================================
# ğŸ“¦ ì¬ê³  ê´€ë¦¬
# (ì›ë³¸ ì½”ë“œ ìƒëµ, [AI/ML í†µí•© ìˆ˜ì •]ì´ ì ìš©ëœ í•¨ìˆ˜ë¥¼ ì‚¬ìš©)
# ==============================================================
# ==============================================================
# ğŸ“¦ ì¬ê³  ê´€ë¦¬
# ==============================================================
elif menu == "ì¬ê³  ê´€ë¦¬":
    st.header("ğŸ“¦ ì¬ê³  ê´€ë¦¬")
    
    # [ìˆ˜ì •] ëª¨ë“  ë¡œì§ ì „ì— ì¬ê³ /íŒŒë¼ë¯¸í„°ë¥¼ ë¨¼ì € ë¡œë“œ
    df_inv = load_inventory_df()
    df_params = load_sku_params()
    
    # [UX ê°œì„ ] 3ì¤‘ íƒ­ì„ 2ê°œì˜ ëª…í™•í•œ íƒ­ìœ¼ë¡œ ì¬êµ¬ì„±
    tab1, tab2 , tab3= st.tabs(["ğŸ“Š ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°", "ğŸ“œ ë ˆì‹œí”¼ í¸ì§‘ê¸° (BOM)", "ğŸ“¸ ì¬ê³  ì…ë ¥"])

    # ==============================================================
    # TAB 1: (ì‹ ê·œ) ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°
    # ==============================================================
    with tab1:
        st.subheader("ğŸ“Š ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„° ê´€ë¦¬")
        st.info("ì´ê³³ì—ì„œ ëª¨ë“  í’ˆëª©ì˜ **ì¬ê³ , ì›ê°€, ì¬ë£Œ ì—¬ë¶€**ë¥¼ í•œëˆˆì— ê´€ë¦¬í•©ë‹ˆë‹¤.")

        with st.expander("âš ï¸ ì¸ë²¤í† ë¦¬ ì´ˆê¸°í™” (ì‹œë“œ ì¬ë£Œë§Œ ë‚¨ê¹€)"):
            st.warning("ëª¨ë“  ì¬ê³  í’ˆëª©ì„ ì‚­ì œí•˜ê³  ì‹œë“œ ì¬ë£Œ 9ì¢…(ì—ìŠ¤í”„ë ˆì†Œ, í—¤ì´ì¦ ì‹œëŸ½ ë“±)ë§Œ ë‹¤ì‹œ ë“±ë¡í•©ë‹ˆë‹¤. ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            confirm = st.checkbox("ì •ë§ë¡œ ì¸ë²¤í† ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.", value=False, key="reset_inv_confirm")
            if st.button("ì¸ë²¤í† ë¦¬ ì´ˆê¸°í™” ì‹¤í–‰", type="secondary", disabled=not confirm):
                deleted = reset_inventory_to_seed()
                if deleted is not None:
                    st.success(f"âœ… ê¸°ì¡´ {deleted}ê°œ ë¬¸ì„œë¥¼ ì‚­ì œí•˜ê³  ì‹œë“œ ì¬ë£Œë¥¼ ë“±ë¡í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
                    safe_rerun()

        with st.expander("ğŸš€ (ì¬ë™ê¸°í™”) íŒë§¤ ë°ì´í„°ì—ì„œ í’ˆëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"):
            st.markdown("'ì•„ë©”ë¦¬ì¹´ë…¸'ì²˜ëŸ¼ íŒë§¤ ëª©ë¡ì—ëŠ” ìˆì§€ë§Œ, ì•„ë˜ ë§ˆìŠ¤í„° ëª©ë¡ì— ì—†ëŠ” í’ˆëª©ì„ ë™ê¸°í™”í•©ë‹ˆë‹¤.")
            
            if st.button("íŒë§¤ ëª©ë¡ê³¼ 'ì¬ë£Œ ë§ˆìŠ¤í„°' ë™ê¸°í™”í•˜ê¸°"):
                current_master_items_en = set(df_inv['ìƒí’ˆìƒì„¸_en'].unique())
                all_sales_items_kr = df['ìƒí’ˆìƒì„¸'].unique()
                all_sales_items_en = {from_korean_detail(name_kr) for name_kr in all_sales_items_kr if name_kr}
                new_items_to_add = list(all_sales_items_en - current_master_items_en)
                
                if not new_items_to_add:
                    st.success("âœ… ëª¨ë“  íŒë§¤ í’ˆëª©ì´ ì´ë¯¸ ë§ˆìŠ¤í„° ëª©ë¡ì— ìˆìŠµë‹ˆë‹¤. (ìƒˆ í•­ëª© 0ê±´)")
                else:
                    with st.spinner(f"{len(new_items_to_add)}ê°œì˜ ìƒˆ í’ˆëª©ì„ 'inventory'ë¡œ ì˜®ê¸°ëŠ” ì¤‘..."):
                        count = 0
                        for sku_en in new_items_to_add:
                            if sku_en:
                                ensure_inventory_doc(sku_en, uom="ea", is_ingredient=False)
                                count += 1
                    
                    st.success(f"âœ… ì´ {count}ê°œì˜ ìƒˆ í’ˆëª©ì„ 'inventory'ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
                    st.balloons()
                    safe_rerun()
        
        st.markdown("---") 

        if df_inv.empty:
            st.warning("ğŸ“¦ ë§ˆìŠ¤í„° ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. 'ë™ê¸°í™”' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”.")
            st.stop()

        # SEED_INGREDIENTS ëª©ë¡ì— ìˆëŠ” í’ˆëª©ë§Œ í‘œì‹œ/í¸ì§‘ (ìš”ì²­ì‚¬í•­)
        seed_names = set([item["ko"] for item in SEED_INGREDIENTS])
        df_inv_edit = df_inv[df_inv['ìƒí’ˆìƒì„¸'].isin(seed_names)].copy()
        df_inv_edit = df_inv_edit.sort_values('ìƒí’ˆìƒì„¸')
        
        # [ìˆ˜ì •] data_editorì— 'num_rows="dynamic"'ì„ ì¶”ê°€í•˜ì—¬ ìƒˆ í–‰ ìƒì„± í—ˆìš©
        edited_inv_df = st.data_editor(
            df_inv_edit[['ìƒí’ˆìƒì„¸', 'is_ingredient', 'uom', 'í˜„ì¬ì¬ê³ ', 'cost_unit_size', 'cost_per_unit', 'ìƒí’ˆìƒì„¸_en']],
            column_config={
                "ìƒí’ˆìƒì„¸": st.column_config.TextColumn("í’ˆëª©ëª…", disabled=False), 
                "is_ingredient": st.column_config.CheckboxColumn("ì¬ë£Œ ì—¬ë¶€ (ì²´í¬)"),
                "uom": st.column_config.TextColumn("ê¸°ë³¸ ë‹¨ìœ„", disabled=False), 
                "í˜„ì¬ì¬ê³ ": st.column_config.NumberColumn("í˜„ì¬ ì¬ê³ (ìˆ˜ê¸°)", min_value=0.0, format="%.2f"),
                "cost_unit_size": st.column_config.NumberColumn("ë§¤ì… ë‹¨ìœ„(g/ml/ea)", min_value=1.0, format="%.0f"),
                "cost_per_unit": st.column_config.NumberColumn("ë§¤ì…ê°€(ì›)", min_value=0, format="%dì›"),
                "ìƒí’ˆìƒì„¸_en": st.column_config.TextColumn("SKU (Eng)", disabled=True, help="ê¸°ì¡´ í’ˆëª©ì€ SKUìˆ˜ì • ë¶ˆê°€, ì‹ ê·œ í’ˆëª©ì€ ìë™ ìƒì„±ë¨"),
            },
            hide_index=True,
            num_rows="fixed",  # ğŸ‘ˆ SEED í’ˆëª©ë§Œ ìœ ì§€ (ìƒˆ í–‰ ì¶”ê°€ ë¶ˆê°€)
            use_container_width=True
        )

        if st.button("ğŸ’¾ 'ì¬ë£Œ/ì›ê°€/ì¬ê³ ' ì„¤ì • ì €ì¥í•˜ê¸°", type="primary"):
            changed = 0
            created = 0 
            batch = db.batch()
            original_map = df_inv.set_index('ìƒí’ˆìƒì„¸_en').to_dict('index')

            for _, item in edited_inv_df.iterrows():
                sku_en = item['ìƒí’ˆìƒì„¸_en']
                
                if pd.isna(sku_en) or not sku_en:
                    new_sku_kr = item['ìƒí’ˆìƒì„¸']
                    if not new_sku_kr:
                        st.warning("ìƒˆë¡œ ì¶”ê°€ëœ í–‰ì˜ 'í’ˆëª©ëª…'ì´ ë¹„ì–´ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                    new_sku_en = from_korean_detail(new_sku_kr) 
                    
                    if new_sku_en in original_map:
                        st.error(f"'{new_sku_kr}'({new_sku_en})ëŠ” ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                        
                    new_doc_ref = db.collection(INVENTORY_COLLECTION).document(safe_doc_id(new_sku_en))
                    batch.set(new_doc_ref, {
                        "ìƒí’ˆìƒì„¸_en": new_sku_en,
                        "ìƒí’ˆìƒì„¸": new_sku_kr,
                        "is_ingredient": bool(item['is_ingredient']),
                        "uom": normalize_uom(item['uom'] or 'ea'),
                        "í˜„ì¬ì¬ê³ ": safe_float(item['í˜„ì¬ì¬ê³ '], 0.0),
                        "ì´ˆê¸°ì¬ê³ ": 0.0, 
                        "cost_unit_size": safe_float(item['cost_unit_size'], 1.0),
                        "cost_per_unit": safe_float(item['cost_per_unit'], 0.0)
                    })
                    created += 1
                    
                else:
                    orig_item = original_map.get(sku_en, {})
                    patch = {}
                    
                    new_sku_kr_update = item['ìƒí’ˆìƒì„¸']
                    if orig_item.get('ìƒí’ˆìƒì„¸', '') != new_sku_kr_update and new_sku_kr_update:
                         patch['ìƒí’ˆìƒì„¸'] = new_sku_kr_update
                    
                    is_ingr_new = bool(item['is_ingredient'])
                    if orig_item.get('is_ingredient') != is_ingr_new:
                        patch['is_ingredient'] = is_ingr_new
                    cost_unit_new = safe_float(item['cost_unit_size'], 1.0)
                    if orig_item.get('cost_unit_size', 1.0) != cost_unit_new:
                        patch['cost_unit_size'] = cost_unit_new
                    cost_new = safe_float(item['cost_per_unit'], 0.0)
                    if orig_item.get('cost_per_unit', 0.0) != cost_new:
                        patch['cost_per_unit'] = cost_new
                    stock_new = safe_float(item['í˜„ì¬ì¬ê³ '], 0.0)
                    if orig_item.get('í˜„ì¬ì¬ê³ ', 0.0) != stock_new:
                        patch['í˜„ì¬ì¬ê³ '] = stock_new

                    if patch: 
                        doc_ref = db.collection(INVENTORY_COLLECTION).document(safe_doc_id(sku_en))
                        batch.update(doc_ref, patch)
                        changed += 1
            
            if changed > 0 or created > 0:
                batch.commit()
                st.success(f"âœ… {created}ê±´ ìƒì„±, {changed}ê±´ ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
                st.balloons()
                safe_rerun()
            else:
                st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ==============================================================
    # TAB 2: (ì‹ ê·œ) ë ˆì‹œí”¼ í¸ì§‘ê¸°
    # ==============================================================
    with tab2:
        st.subheader("ğŸ“œ ë©”ë‰´ë³„ ë ˆì‹œí”¼ (BOM) í¸ì§‘")
        st.info("`ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°` íƒ­ì—ì„œ 'ì¬ë£Œ ì—¬ë¶€'ë¥¼ ì²´í¬í•œ í’ˆëª©ë“¤ë¡œ ë ˆì‹œí”¼ë¥¼ ë§Œë“­ë‹ˆë‹¤.")
        
        try:
            df_ingredients = df_inv[df_inv['is_ingredient'] == True].copy()
            if df_ingredients.empty:
                st.error("ì˜¤ë¥˜: 'ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°' íƒ­ì—ì„œ ì¬ë£Œë¥¼ 1ê°œ ì´ìƒ ì²´í¬í•´ì•¼ í•©ë‹ˆë‹¤.")
                st.stop()
            ingredient_options_kr = sorted(df_ingredients['ìƒí’ˆìƒì„¸'].unique().tolist())
            ing_kr_to_en_map = dict(zip(df_ingredients['ìƒí’ˆìƒì„¸'], df_ingredients['ìƒí’ˆìƒì„¸_en']))
            ing_en_to_kr_map = dict(zip(df_ingredients['ìƒí’ˆìƒì„¸_en'], df_ingredients['ìƒí’ˆìƒì„¸']))
        except Exception as e:
            st.error(f"ì¬ë£Œ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.stop()
            
        all_menus_kr = sorted(df_inv[df_inv['is_ingredient'] == False]['ìƒí’ˆìƒì„¸'].unique().tolist())
        selected_menu_kr = st.selectbox(
            "ë ˆì‹œí”¼ë¥¼ ë“±ë¡/ìˆ˜ì •í•  ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            all_menus_kr
        )
        
        # [ìˆ˜ì •] selectboxê°€ ë¹„ì–´ìˆìœ¼ë©´(ë©”ë‰´ê°€ 0ê°œ) ì˜¤ë¥˜ë‚˜ë¯€ë¡œ ë°©ì–´
        if not selected_menu_kr:
            st.warning("ë¨¼ì € 'ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°' íƒ­ì—ì„œ 'ìµœì¢… ë©”ë‰´'ë¥¼ 1ê°œ ì´ìƒ ë“±ë¡í•´ì£¼ì„¸ìš”. ('ì¬ë£Œ ì—¬ë¶€' ì²´í¬ í•´ì œ)")
            st.stop()
            
        selected_menu_en = from_korean_detail(selected_menu_kr)
        st.caption(f"(Firebase ë¬¸ì„œ ID: `{safe_doc_id(selected_menu_en)}`)")
        st.markdown("---")
        
        current_recipe_items = load_recipe(selected_menu_en)
        recipe_df_rows = []
        if current_recipe_items:
            for item in current_recipe_items:
                sku_en = item.get("ingredient_en")
                recipe_df_rows.append({
                    "ì¬ë£Œ": ing_en_to_kr_map.get(sku_en, f"ì˜¤ë¥˜: {sku_en}?"),
                    "ìˆ˜ëŸ‰": safe_float(item.get("qty", 0.0)),
                    "ë‹¨ìœ„": normalize_uom(item.get("uom", "g")),
                    "ì†ì‹¤ë¥ (%)": safe_float(item.get("waste_pct", 0.0)),
                })
        if not recipe_df_rows:
            recipe_df_rows = [{"ì¬ë£Œ": None, "ìˆ˜ëŸ‰": 0.0, "ë‹¨ìœ„": "g", "ì†ì‹¤ë¥ (%)": 0.0}]
        df_recipe_editor = pd.DataFrame(recipe_df_rows)
        st.subheader(f"ğŸ“ `{selected_menu_kr}` ë ˆì‹œí”¼ í¸ì§‘")
        edited_df = st.data_editor(
            df_recipe_editor,
            column_config={
                "ì¬ë£Œ": st.column_config.SelectboxColumn("ì¬ë£Œ (í•„ìˆ˜)", options=ingredient_options_kr, required=True),
                "ìˆ˜ëŸ‰": st.column_config.NumberColumn("ìˆ˜ëŸ‰", min_value=0.0, format="%.2f", required=True),
                "ë‹¨ìœ„": st.column_config.SelectboxColumn("ë‹¨ìœ„", options=["g", "ml", "ea"], required=True),
                "ì†ì‹¤ë¥ (%)": st.column_config.NumberColumn("ì†ì‹¤ë¥ (%)", min_value=0.0, max_value=100.0, format="%.1f %%", required=True),
            },
            num_rows="dynamic",
            use_container_width=True
        )
        
        if st.button(f"ğŸ’¾ `{selected_menu_kr}` ë ˆì‹œí”¼ ì €ì¥í•˜ê¸°", type="primary"):
            final_ingredients = []
            valid = True
            for index, row in edited_df.iterrows():
                ì¬ë£Œ_kr = row["ì¬ë£Œ"]
                if not ì¬ë£Œ_kr: continue 
                ì¬ë£Œ_en = ing_kr_to_en_map.get(ì¬ë£Œ_kr)
                if not ì¬ë£Œ_en:
                    st.error(f"'{ì¬ë£Œ_kr}'ëŠ” ìœ íš¨í•œ ì¬ë£Œê°€ ì•„ë‹™ë‹ˆë‹¤. 'ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
                    valid = False; break
                final_ingredients.append({
                    "ingredient_en": ì¬ë£Œ_en,
                    "qty": safe_float(row["ìˆ˜ëŸ‰"]),
                    "uom": normalize_uom(row["ë‹¨ìœ„"]),
                    "waste_pct": safe_float(row["ì†ì‹¤ë¥ (%)"]),
                })
            if valid and not final_ingredients: st.warning("ì €ì¥í•  ì¬ë£Œê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  í–‰ì´ ë¹„ì–´ìˆìŒ)")
            elif valid and final_ingredients:
                try:
                    db.collection(RECIPES_COLLECTION).document(safe_doc_id(selected_menu_en)).set({"ingredients": final_ingredients})
                    load_all_core_data.clear() 
                    load_recipe.clear()        
                    st.success(f"âœ… `{selected_menu_kr}` ë ˆì‹œí”¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.balloons()
                    safe_rerun()
                except Exception as e: st.error(f"Firebase ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # [ë³µì›] 'ì˜ˆì „ ê·¸ë˜í”„' ë¡œì§ìœ¼ë¡œ ë˜ëŒë¦½ë‹ˆë‹¤.
        st.divider()
        st.subheader(f"ğŸ¤– AI ì¬ê³  ì˜í–¥ë„ ë¶„ì„ ({selected_menu_kr})")
        
        try:
            # [ë³µì›] compute_ingredient_metrics_for_menuê°€
            # ì´ì œ ì°¨íŠ¸(st.plotly_chart)ì™€ í…Œì´ë¸”(report_df)ì„ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            report_df = compute_ingredient_metrics_for_menu(
                selected_menu_en,
                df, 
                df_inv,
                df_params
            )
            
            # [ë³µì›] ì¬ê³  ë¶„ì„í‘œ(DataFrame)ëŠ” ì°¨íŠ¸ ì•„ë˜ì— í‘œì‹œ
            if report_df.empty:
                st.warning(f"'{selected_menu_kr}'ì— ëŒ€í•œ ë ˆì‹œí”¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë ˆì‹œí”¼ë¥¼ ë¨¼ì € ì €ì¥í•´ì£¼ì„¸ìš”.")
            else:
                display_cols = ['ìƒí’ˆìƒì„¸', 'ìƒíƒœ', 'í˜„ì¬ì¬ê³ ', 'uom', 'ê¶Œì¥ë°œì£¼', 'ì»¤ë²„ì¼ìˆ˜', 'ì¼í‰ê· ì†Œì§„', 'ROP']
                formatted_df = report_df[display_cols].copy()
                formatted_df['í˜„ì¬ì¬ê³ '] = formatted_df.apply(lambda r: f"{r['í˜„ì¬ì¬ê³ ']:,.1f} {r['uom']}", axis=1)
                formatted_df['ê¶Œì¥ë°œì£¼'] = formatted_df.apply(lambda r: f"{r['ê¶Œì¥ë°œì£¼']:,.1f} {r['uom']}", axis=1)
                formatted_df['ì¼í‰ê· ì†Œì§„'] = formatted_df.apply(lambda r: f"{r['ì¼í‰ê· ì†Œì§„']:,.1f} {r['uom']}", axis=1)
                formatted_df['ROP'] = formatted_df.apply(lambda r: f"{r['ROP']:,.1f} {r['uom']}", axis=1)
                formatted_df['ì»¤ë²„ì¼ìˆ˜'] = formatted_df['ì»¤ë²„ì¼ìˆ˜'].apply(lambda x: f"{x}ì¼")
                st.dataframe(formatted_df[['ìƒí’ˆìƒì„¸', 'ìƒíƒœ', 'í˜„ì¬ì¬ê³ ', 'ê¶Œì¥ë°œì£¼', 'ì»¤ë²„ì¼ìˆ˜', 'ì¼í‰ê· ì†Œì§„', 'ROP']], use_container_width=True)
        
        except Exception as e:
            st.error(f"AI ì¬ê³  ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            import traceback
            st.exception(traceback.format_exc())

    # ==============================================================
    # TAB 3: (ì‹ ê·œ) ì¬ê³  ì…ë ¥ (ì˜ìˆ˜ì¦ AI)
    # ==============================================================
    with tab3:
        st.subheader("ğŸ“¸ ì˜ìˆ˜ì¦ ê¸°ë°˜ ì¬ê³  ì…ê³ ")
        st.caption("ì›ì¬ë£Œ êµ¬ë§¤ ì˜ìˆ˜ì¦ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë‚´ì—­ì„ ì…ë ¥í•´ì¤ë‹ˆë‹¤.")

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•¨)
        if "receipt_result" not in st.session_state:
            st.session_state.receipt_result = None

        # --- [í™”ë©´ 1] ì—…ë¡œë“œ UI ---
        # ë¶„ì„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì—…ë¡œë“œ í™”ë©´ì„ ë³´ì—¬ì¤Œ
        if st.session_state.receipt_result is None:
            st.markdown("### ì˜ìˆ˜ì¦ ì‚¬ì§„ ì—…ë¡œë“œ")
            
            with st.container(border=True):
                uploaded_file = st.file_uploader(
                    "ë“œë˜ê·¸ ì•¤ ë“œë¡­ ë˜ëŠ” í´ë¦­í•˜ì—¬ íŒŒì¼ ì„ íƒ", 
                    type=["png", "jpg", "jpeg", "webp"],
                    help="AIê°€ ì˜ìˆ˜ì¦ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•´ ë“œë¦½ë‹ˆë‹¤."
                )
                
                if uploaded_file is not None:
                    # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
                    st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ì˜ìˆ˜ì¦", width=300)
                    
                    if st.button("ğŸ¤– AI ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                        with st.spinner("AIê°€ ì˜ìˆ˜ì¦ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 5~10ì´ˆ ì†Œìš”) ğŸ§ "):
                            # API í˜¸ì¶œ
                            data = analyze_receipt_image(uploaded_file)
                            
                            if data:
                                st.session_state.receipt_result = data
                                st.session_state.receipt_image = uploaded_file # ì´ë¯¸ì§€ë„ ìœ ì§€
                                safe_rerun() # í™”ë©´ ê°±ì‹ í•˜ì—¬ ê²°ê³¼ í™”ë©´ìœ¼ë¡œ ì´ë™

        # --- [í™”ë©´ 2] ë¶„ì„ ê²°ê³¼ í™•ì¸ ë° ìˆ˜ì • UI ---
        else:
            st.markdown("### ğŸ“ ë°ì´í„° ê²€í†  ë° ìˆ˜ì •")
            
            data = st.session_state.receipt_result
            
            # ìƒë‹¨: ì›ë³¸ ì´ë¯¸ì§€ì™€ í—¤ë” ì •ë³´
            col_img, col_info = st.columns([1, 2])
            
            with col_img:
                st.image(st.session_state.receipt_image, caption="ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)
                if st.button("ğŸ”„ ë‹¤ë¥¸ ì˜ìˆ˜ì¦ ì˜¬ë¦¬ê¸°"):
                    st.session_state.receipt_result = None
                    st.session_state.receipt_image = None
                    safe_rerun()

            with col_info:
                st.markdown("#### ì˜ìˆ˜ì¦ ì •ë³´")
                with st.container(border=True):
                    c1, c2, c3 = st.columns(3)
                    # AIê°€ ì¶”ì¶œí•œ ì •ë³´ë¡œ ì´ˆê¸°ê°’ ì„¤ì •
                    store_name = c1.text_input("ìƒí˜¸ëª…", value=data.get("store_name", ""))
                    date_val = c2.text_input("ê±°ë˜ ë‚ ì§œ", value=data.get("date", ""))
                    time_val = c3.text_input("ê±°ë˜ ì‹œê°„", value=data.get("time", ""))

            st.markdown("#### ğŸ“¦ ë¬¼í’ˆ ëª©ë¡")
            
            # í’ˆëª© ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            items_df = pd.DataFrame(data.get("items", []))
            
            # ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì»¬ëŸ¼ ë³´ì¥
            if items_df.empty:
                items_df = pd.DataFrame(columns=["name", "qty", "price", "total"])
            
            # Data Editorë¡œ í‘œì‹œ (ìˆ˜ì • ê°€ëŠ¥í•˜ë„ë¡)
            edited_items = st.data_editor(
                items_df,
                column_config={
                    "name": st.column_config.TextColumn("ë¬¼í’ˆëª…"),
                    "qty": st.column_config.NumberColumn("ìˆ˜ëŸ‰", min_value=1),
                    "price": st.column_config.NumberColumn("ë‹¨ê°€", format="%dì›"),
                    "total": st.column_config.NumberColumn("ì´ì•¡", format="%dì›"),
                },
                num_rows="dynamic", # í–‰ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥
                use_container_width=True,
                key="receipt_editor"
            )

            # ì´ì•¡ ê³„ì‚° ë° í‘œì‹œ
            st.markdown("---")
            
            # ê³„ì‚°ëœ ì´ì•¡ (Data Editor ìˆ˜ì •ê°’ ë°˜ì˜)
            try:
                calc_total = edited_items["total"].sum()
            except:
                calc_total = 0
                
            ai_total = data.get("total_amount", 0)

            col_sum1, col_sum2 = st.columns([3, 1])
            with col_sum2:
                st.metric("ê³„ì‚°ëœ ì´ì•¡", f"{calc_total:,.0f}ì›", delta=f"AI ì¸ì‹ ê¸ˆì•¡: {ai_total:,.0f}ì›")

            # í•˜ë‹¨ ë²„íŠ¼ ì•¡ì…˜ (DB ì €ì¥ X)
            st.markdown("---")
            btn_col1, btn_col2 = st.columns([1, 4])
            with btn_col2:
                # [ìš”ì²­ì‚¬í•­ ì¤€ìˆ˜] ë²„íŠ¼ì„ ëˆŒëŸ¬ë„ ì•„ë¬´ ì¼ë„ ì¼ì–´ë‚˜ì§€ ì•ŠìŒ (Printë§Œ í•¨)
                if st.button("ğŸ’¾ DBì— ì €ì¥ (ì¬ê³  ë°˜ì˜)", type="primary", use_container_width=True):
                    st.toast("âœ… (ì‹œë®¬ë ˆì´ì…˜) ë°ì´í„°ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤! (í˜„ì¬ DB ì €ì¥ ê¸°ëŠ¥ì€ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤)")
                    # ì—¬ê¸°ì— ë‚˜ì¤‘ì— firebase ì €ì¥ ì½”ë“œë¥¼ ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤.
    

# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [AI/ML í†µí•© ìˆ˜ì • 2] ===
# AIê°€ 'ê±°ì§“ë§'ì„ í•˜ì§€ ì•Šë„ë¡ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ì™€ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ë¦¬
# =============================================================
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [AI/ML í†µí•© ìˆ˜ì • 9] ===
# "ë ˆë²¨ 4: AI ì¬ë¬´/ìš´ì˜ ë¶„ì„ê°€"ë¡œ ì—…ê·¸ë ˆì´ë“œ
# 1. 3ëŒ€ ë¶„ì„ í•¨ìˆ˜ (ì¬ê³ ìœ„í—˜, "ë§ˆì§„ ì¸ì‚¬ì´íŠ¸", íŒë§¤íŒ¨í„´) ìë™ ì‹¤í–‰
# 2. ë¶„ì„ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ AIì—ê²Œ ì „ë‹¬ -> 'ì‹¤í–‰ ì¡°ì–¸' ìƒì„±
# =============================================================
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [UX ê°œì„ ] 'ì¼ë°©ì  ì¡°ì–¸' -> 'ì„ íƒí˜• ë¸Œë¦¬í•‘'ìœ¼ë¡œ ë³€ê²½ ===
# =============================================================
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [UX ê°œì„ ] 'ìƒˆë¡œ ë¶„ì„í•˜ê¸°' ë²„íŠ¼ ì¶”ê°€ ===
# =============================================================
elif menu == "AI ë¹„ì„œ":
    st.header("ğŸ¤– AI ë¹„ì„œ (ì„ íƒí˜• ë¸Œë¦¬í•‘)")

    # [ìˆ˜ì •] ëŒ€í™” ê¸°ë¡ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    if "messages_ai_v2" not in st.session_state:
        st.session_state.messages_ai_v2 = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”, ì‚¬ì¥ë‹˜! ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë¨¼ì € ë¸Œë¦¬í•‘í•´ ë“œë¦´ê¹Œìš”?"}]
    
    # [ìˆ˜ì •] ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "analysis_context" not in st.session_state:
        st.session_state.analysis_context = {
            "risk": None,
            "profit": None,
            "pattern": None
        }

    # [UX ê°œì„  3] 'ìƒˆë¡œ ë¶„ì„í•˜ê¸°' ë²„íŠ¼ ì¶”ê°€
    if st.button("ğŸ”„ ìµœì‹  ë°ì´í„°ë¡œ ìƒˆë¡œ ë¶„ì„í•˜ê¸°", help="ìƒˆë¡œ ì¶”ê°€ëœ ê±°ë˜ ë‚´ì—­ì„ ë°˜ì˜í•˜ì—¬ AI ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤."):
        with st.spinner("ìµœì‹  ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... â³"):
            # 1. AI ë¶„ì„ í•¨ìˆ˜ë¥¼ 'ê°•ì œë¡œ' ë‹¤ì‹œ ì‹¤í–‰
            risk_report = find_inventory_risks(df, df_inv, df_params)
            profit_report = find_profit_insights(df)
            pattern_report = find_top_correlations(df)
            
            # 2. ì„¸ì…˜ ìƒíƒœì— 'ìµœì‹ ' ë¶„ì„ ê²°ê³¼ë¥¼ ë®ì–´ì“°ê¸°
            st.session_state.analysis_context['risk'] = risk_report
            st.session_state.analysis_context['profit'] = profit_report
            st.session_state.analysis_context['pattern'] = pattern_report
            
            # 3. ëŒ€í™” ê¸°ë¡ë„ ë¦¬ì…‹
            st.session_state.messages_ai_v2 = [{"role": "assistant", "content": "âœ… ìµœì‹  ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ë¬´ì—‡ì„ ë¸Œë¦¬í•‘í•´ ë“œë¦´ê¹Œìš”?"}]
            
            st.success("ìƒˆë¡œ ë¶„ì„ ì™„ë£Œ!")
            safe_rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨

    st.markdown("ë°ì´í„° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¦¬í•‘ì„ ìš”ì²­í•˜ì„¸ìš”.")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸš¨ ì¬ê³  ìœ„í—˜ ë³´ê¸°", use_container_width=True):
            # [ìˆ˜ì •] ë²„íŠ¼ í´ë¦­ ì‹œì ì— 'ì•„ì§ ë¶„ì„ ì•ˆ í•œ' ê²½ìš°ì—ë§Œ ë¶„ì„ ì‹¤í–‰
            if st.session_state.analysis_context.get('risk') is None:
                st.session_state.analysis_context['risk'] = find_inventory_risks(df, df_inv, df_params)
                
            st.session_state.messages_ai_v2.append({"role": "user", "content": "ì¬ê³  ìœ„í—˜ ë¸Œë¦¬í•‘í•´ì¤˜."})
            st.session_state.messages_ai_v2.append({"role": "assistant", "content": f"**[AI ì‚¬ì‹¤ ë¦¬í¬íŠ¸: ì¬ê³  ìœ„í—˜]**\n\n{st.session_state.analysis_context['risk']}"})
            safe_rerun()

    with col2:
        if st.button("ğŸ’° ë§ˆì§„ ë¶„ì„ ë³´ê¸°", use_container_width=True):
            if st.session_state.analysis_context.get('profit') is None:
                st.session_state.analysis_context['profit'] = find_profit_insights(df)
                
            st.session_state.messages_ai_v2.append({"role": "user", "content": "ë§ˆì§„ ë¶„ì„ ë¸Œë¦¬í•‘í•´ì¤˜."})
            st.session_state.messages_ai_v2.append({"role": "assistant", "content": f"**[AI ì‚¬ì‹¤ ë¦¬í¬íŠ¸: ë§ˆì§„ ë¶„ì„]**\n\n{st.session_state.analysis_context['profit']}"})
            safe_rerun()

    with col3:
        if st.button("ğŸ“ˆ íŒë§¤ íŒ¨í„´ ë³´ê¸°", use_container_width=True):
            if st.session_state.analysis_context.get('pattern') is None:
                st.session_state.analysis_context['pattern'] = find_top_correlations(df)
                
            st.session_state.messages_ai_v2.append({"role": "user", "content": "íŒë§¤ íŒ¨í„´ ë¸Œë¦¬í•‘í•´ì¤˜."})
            st.session_state.messages_ai_v2.append({"role": "assistant", "content": f"**[AI ì‚¬ì‹¤ ë¦¬í¬íŠ¸: íŒë§¤ íŒ¨í„´]**\n\n{st.session_state.analysis_context['pattern']}"})
            safe_rerun()
            
    st.divider()

    # --- 2. ëŒ€í™”ì°½ UI (ê¸°ì¡´ê³¼ ë™ì¼) ---
    
    # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.messages_ai_v2:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # [ìˆ˜ì •] st.chat_input ì‚¬ìš©
    if prompt := st.chat_input("ìœ„ ë¶„ì„ ë‚´ìš©ì— ëŒ€í•´ ë” ë¬¼ì–´ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê²ƒì„ ìš”ì²­í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages_ai_v2.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("AIê°€ ë¶„ì„ ë‚´ìš©ê³¼ ì‚¬ì¥ë‹˜ì˜ ì§ˆë¬¸ì„ í•¨ê»˜ ìƒê° ì¤‘ì…ë‹ˆë‹¤... ğŸ§ "):
                
                # [ìˆ˜ì •] AIê°€ í˜„ì¬ê¹Œì§€ì˜ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ 'ì‚¬ì‹¤'ë¡œ ì¸ì§€í•˜ë„ë¡ ì»¨í…ìŠ¤íŠ¸ ì¡°í•©
                full_context = f"""
                [AI ë¶„ì„ ë¦¬í¬íŠ¸ 1: ì¬ê³  ìœ„í—˜]
                {st.session_state.analysis_context.get('risk', 'ì•„ì§ ë¶„ì„ ì•ˆ í•¨')}
                
                [AI ë¶„ì„ ë¦¬í¬íŠ¸ 2: ë§ˆì§„ ë¶„ì„]
                {st.session_state.analysis_context.get('profit', 'ì•„ì§ ë¶„ì„ ì•ˆ í•¨')}
                
                [AI ë¶„ì„ ë¦¬í¬íŠ¸ 3: í•µì‹¬ íŒë§¤ íŒ¨í„´]
                {st.session_state.analysis_context.get('pattern', 'ì•„ì§ ë¶„ì„ ì•ˆ í•¨')}
                """
                
                result_text = call_openai_api(
                    user_prompt=prompt,
                    data_context=full_context
                )
                
                if result_text:
                    st.markdown(result_text)
                    st.session_state.messages_ai_v2.append({"role": "assistant", "content": result_text})
                else:
                    st.error("AI ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# === [ë¹ˆí‹ˆ ìˆ˜ì •] 'ê°€ê²Œìœ„ì¹˜' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°(ì•± ì¶”ê°€ 0ê±´)ì—ë„ ì˜¤ë¥˜ ì—†ë„ë¡ ìˆ˜ì • ===
# ==============================================================
# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# === [UX ê°œì„ ] tab2(ê¸°ëŠ¥ ì¤‘ë³µ) ì‚­ì œ, 'ìˆ˜ìµ' ìë™ê³„ì‚°, ì‚­ì œ UI ê°„ì†Œí™” ===
# ==============================================================
elif menu == "ë°ì´í„° í¸ì§‘":
    # [ìˆ˜ì •] í—¤ë”ë¥¼ 'ê±°ë˜ ìˆ˜ì •/ì‚­ì œ'ë¡œ ëª…í™•íˆ í•¨
    st.header("âœï¸ ê±°ë˜ ìˆ˜ì •/ì‚­ì œ")
    
    # [ìˆ˜ì •] tab1, tab2 êµ¬ë¶„ ì‚­ì œ
    
    df_raw, df_view = load_sales_with_id()
    if df_view.empty:
        st.info("ìˆ˜ì •í•  Firebase ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (CSVëŠ” ì½ê¸° ì „ìš©)")
    else:
        st.caption("ğŸ’¡ Firebaseì— ì €ì¥ëœ ê±°ë˜ ë‚´ì—­ë§Œ ìˆ˜ì •/ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê°€ê²Œìœ„ì¹˜=Firebase)")
        
        if 'ê°€ê²Œìœ„ì¹˜' in df_view.columns:
            df_view_fb = df_view[df_view['ê°€ê²Œìœ„ì¹˜'] == 'Firebase'].copy()
        else:
            df_view_fb = pd.DataFrame(columns=df_view.columns) 
        
        if df_view_fb.empty:
            st.info("ì•„ì§ ì•±ì„ í†µí•´ ì¶”ê°€ëœ(ìˆ˜ì • ê°€ëŠ¥í•œ) ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            
            # [ìˆ˜ì •] 'ìˆ˜ìµ' ì»¬ëŸ¼ì„ ìˆ˜ì • ë¶ˆê°€ëŠ¥(disabled)í•˜ê²Œ ë³€ê²½
            edited_df = st.data_editor(
                df_view_fb[['_id','ë‚ ì§œ','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ']],
                column_config={
                    "_id": st.column_config.TextColumn("ë¬¸ì„œID", disabled=True),
                    "ë‚ ì§œ": st.column_config.DateColumn("ë‚ ì§œ", format="YYYY-MM-DD"),
                    "ìˆ˜ëŸ‰": st.column_config.NumberColumn("ìˆ˜ëŸ‰", min_value=0), # 0ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥
                    "ë‹¨ê°€": st.column_config.NumberColumn("ë‹¨ê°€(ì›)", format="%dì›"),
                    "ìˆ˜ìµ": st.column_config.NumberColumn(
                        "ìˆ˜ìµ (ìë™ê³„ì‚°)", 
                        disabled=True, # ğŸ‘ˆ [í•µì‹¬ ìˆ˜ì •] ì‚¬ìš©ìê°€ ì§ì ‘ ìˆ˜ì • ë¶ˆê°€
                        format="%dì›"
                    )
                },
                hide_index=True,
                num_rows="dynamic" # ğŸ‘ˆ [í•µì‹¬] ì—¬ê¸°ì„œ í–‰ ì‚­ì œ ê°€ëŠ¥
            )
            
            # [ìœ ì§€] ì´ ì²´í¬ë°•ìŠ¤ëŠ” ë””ìì´ë„ˆë‹˜ ìš”ì²­ëŒ€ë¡œ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
            reflect_inv = st.checkbox("ì €ì¥ ì‹œ ì¬ê³ ì— ë°˜ì˜(ì°¨ê°/ë³µì›)", value=True)
            
            if st.button("ë³€ê²½ëœ ë‚´ìš© ì €ì¥í•˜ê¸° ğŸ’¾"):
                changed = 0 # ìˆ˜ì •ëœ í–‰
                deleted = 0 # ì‚­ì œëœ í–‰
                
                # [ìˆ˜ì •] data_editorì—ì„œ ì‚­ì œëœ í–‰ì„ ë¨¼ì € ê°ì§€
                orig_ids = set(df_view_fb['_id'])
                edited_ids = set(edited_df['_id'])
                deleted_ids = list(orig_ids - edited_ids)

                if deleted_ids:
                    for doc_id in deleted_ids:
                        if reflect_inv: # ì‚­ì œ ì‹œ ì¬ê³  ë³µì›
                            try:
                                orig = df_raw[df_raw['_id'] == doc_id].iloc[0]
                                qty_to_restore = -int(orig.get('ìˆ˜ëŸ‰', 0)) # ìˆ˜ëŸ‰ì„ ìŒìˆ˜ë¡œ
                                detail_en = orig.get('ìƒí’ˆìƒì„¸')
                                if qty_to_restore != 0 and detail_en:
                                    adjust_inventory_by_recipe(detail_en, qty_to_restore, move_type="delete_restore", note=f"Deleted: {doc_id}")
                            except Exception as e:
                                st.warning(f"{doc_id} ì¬ê³  ë³µì› ì‹¤íŒ¨: {e}")
                        
                        db.collection(SALES_COLLECTION).document(doc_id).delete()
                        deleted += 1

                # [ìˆ˜ì •] ìˆ˜ì •ëœ í–‰ ì²˜ë¦¬
                for i, new in edited_df.iterrows():
                    doc_id = new['_id']
                    if pd.isna(doc_id): # ìƒˆë¡œ ì¶”ê°€ëœ í–‰ì€ ë¬´ì‹œ (ì´ íƒ­ì€ 'ìˆ˜ì •/ì‚­ì œ' ì „ìš©)
                        continue
                        
                    orig = df_raw[df_raw['_id'] == doc_id].iloc[0]
                    patch = {}
                    
                    try:
                        new_date_str = str(pd.to_datetime(new['ë‚ ì§œ']).date())
                    except Exception:
                        new_date_str = str(orig.get('ë‚ ì§œ'))
                    if new_date_str != str(orig.get('ë‚ ì§œ')):
                        patch['ë‚ ì§œ'] = new_date_str
                    
                    detail_en = from_korean_detail(new['ìƒí’ˆìƒì„¸'])
                    if detail_en != orig.get('ìƒí’ˆìƒì„¸'):
                        patch['ìƒí’ˆìƒì„¸'] = detail_en
                    
                    # [í•µì‹¬ ìˆ˜ì •] 'ìˆ˜ìµ' ìë™ ê³„ì‚° ë¡œì§
                    qty_new = int(new['ìˆ˜ëŸ‰'])
                    unit_new = float(new['ë‹¨ê°€'])
                    rev_new_calculated = qty_new * unit_new # ğŸ‘ˆ 'ìˆ˜ìµ' ìë™ ê³„ì‚°

                    qty_changed = qty_new != int(orig.get('ìˆ˜ëŸ‰', 0))
                    unit_changed = unit_new != float(orig.get('ë‹¨ê°€', 0))
                    
                    if qty_changed:
                        patch['ìˆ˜ëŸ‰'] = qty_new
                    if unit_changed:
                        patch['ë‹¨ê°€'] = unit_new

                    # ìˆ˜ëŸ‰/ë‹¨ê°€ê°€ ë°”ë€Œì—ˆê±°ë‚˜, ì›ë˜ ìˆ˜ìµì´ ì˜ëª» ê³„ì‚°ëì—ˆë‹¤ë©´ 'ìˆ˜ìµ' ì—…ë°ì´íŠ¸
                    if (qty_changed or unit_changed) or (rev_new_calculated != float(orig.get('ìˆ˜ìµ', 0))):
                        patch['ìˆ˜ìµ'] = rev_new_calculated
                    
                    if patch:
                        if reflect_inv and 'ìˆ˜ëŸ‰' in patch: # ì¬ê³  ë°˜ì˜
                            diff = qty_new - int(orig.get('ìˆ˜ëŸ‰', 0))
                            adjust_inventory_by_recipe(detail_en, diff, move_type="edit_adjust", note=str(doc_id))
                        
                        db.collection(SALES_COLLECTION).document(doc_id).update(patch)
                        changed += 1
                
                if changed > 0 or deleted > 0:
                    st.success(f"âœ… {changed}ê±´ ìˆ˜ì •, {deleted}ê±´ ì‚­ì œ ì™„ë£Œ")
                    safe_rerun()
                else:
                    st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

            # [ìˆ˜ì •] ID ê¸°ë°˜ì˜ multiselect ì‚­ì œ ê¸°ëŠ¥ (st.markdown("---") ì´í•˜) ëª¨ë‘ ì‚­ì œ
    
    # [ìˆ˜ì •] `with tab2:` ë¸”ë¡ ì „ì²´ ì‚­ì œ

# ==============================================================

# ğŸ“‹ ê±°ë˜ ë‚´ì—­
# ==============================================================
elif menu == "ê±°ë˜ ë‚´ì—­":
    st.header("ğŸ“‹ ì „ì²´ ê±°ë˜ ë‚´ì—­")
    if df.empty:
        st.info("í‘œì‹œí•  ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        
        # --- [UX ê°œì„  1] í•„í„° ë° ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€ ---
        max_date = df['ë‚ ì§œ'].max().date()
        min_date = df['ë‚ ì§œ'].min().date()

        # 1. ë‚ ì§œ í•„í„° (ìµœì‹  ë‚ ì§œë¶€í„° 30ì¼ ì´ì „ê¹Œì§€ ê¸°ë³¸ê°’)
        default_start_date = max_date - pd.Timedelta(days=30)
        default_start_date = max(min_date, default_start_date) # ë°ì´í„° ì‹œì‘ì¼ë³´ë‹¤ ë¹ ë¥¼ ìˆ˜ ì—†ìŒ
        
        col_date1, col_date2 = st.columns(2)
        with col_date1:
            start_date = st.date_input("ì¡°íšŒ ì‹œì‘ì¼", value=default_start_date, max_value=max_date)
        with col_date2:
            end_date = st.date_input("ì¡°íšŒ ì¢…ë£Œì¼", value=max_date, min_value=start_date, max_value=max_date)
        
        # 2. í…ìŠ¤íŠ¸ ê²€ìƒ‰ í•„í„°
        search_query = st.text_input("ìƒí’ˆ ê²€ìƒ‰ (ìƒí’ˆìƒì„¸ ë˜ëŠ” ì¹´í…Œê³ ë¦¬)", "")

        # 3. ë°ì´í„° í•„í„°ë§ ì ìš© (ë‚ ì§œ í•„í„°)
        filtered_df = df[
            (df['ë‚ ì§œ'].dt.date >= start_date) & 
            (df['ë‚ ì§œ'].dt.date <= end_date)
        ]
        
        # 4. í…ìŠ¤íŠ¸ ê²€ìƒ‰ í•„í„° ì ìš©
        if search_query:
            # ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ ìƒí’ˆ ìƒì„¸ ë˜ëŠ” ì¹´í…Œê³ ë¦¬ì—ì„œ í•„í„°ë§
            filtered_df = filtered_df[
                filtered_df['ìƒí’ˆìƒì„¸'].str.contains(search_query, case=False) |
                filtered_df['ìƒí’ˆì¹´í…Œê³ ë¦¬'].str.contains(search_query, case=False)
            ]

        # --- [UX ê°œì„  2] ìš”ì•½ ì •ë³´ í‘œì‹œ ---
        st.markdown(f"---")
        total_filtered_rows = len(filtered_df)
        total_filtered_revenue = filtered_df['ìˆ˜ìµ'].sum()
        
        c_metric1, c_metric2 = st.columns(2)
        c_metric1.metric("í‘œì‹œëœ ê±°ë˜ ê±´ìˆ˜", f"{total_filtered_rows:,} ê±´")
        c_metric2.metric("í‘œì‹œëœ ë§¤ì¶œ ì´í•©", format_krw(total_filtered_revenue))
        
        st.caption(f"ì´ {len(df)}ê±´ì˜ ê±°ë˜ ë‚´ì—­ ì¤‘, í•„í„°ë§ëœ **{total_filtered_rows}ê±´**ì„ í‘œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # 5. í•„í„°ë§ëœ ë°ì´í„° ì¶œë ¥
        cols = ['ë‚ ì§œ','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ','ìƒí’ˆì¹´í…Œê³ ë¦¬','ìš”ì¼','ì‹œ']
        cols = [c for c in cols if c in filtered_df.columns]
        
        st.dataframe(
            filtered_df[cols].sort_values('ë‚ ì§œ', ascending=False), 
            width=None, 
            use_container_width=True
        )

elif menu == "ì—°êµ¬ ê²€ì¦":
    st.header("ğŸ“ ì—°êµ¬ ê²€ì¦ ë° ê¸°ìˆ  ì‹¤ì¦ (Validation)")
    st.markdown("""
    ë³¸ ì—°êµ¬ëŠ” **ì‹œìŠ¤í…œ ì„±ëŠ¥**, **AI ëª¨ë¸ ì‹ ë¢°ë„**, **ë¹„ìš© ëª¨ë¸**ì˜ ì„¸ ê°€ì§€ í•µì‹¬ ì„±ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    """)
    st.divider()

    # --- 1. ì‹œìŠ¤í…œ ì„±ëŠ¥ (Speed) ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 1: ì‹œìŠ¤í…œ ì„±ëŠ¥ (ë°ì´í„° ì²˜ë¦¬ ì†ë„) ğŸš€")
    st.metric(f"ì£¼ ë°ì´í„°ì…‹ (ì´ {row_count:,}ê±´) ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œê°„", f"{load_time:.4f} ì´ˆ")
    st.caption("ì¦ê°•/í˜„ì¥ CSVë¥¼ ìˆ˜ ì´ˆ ë‚´ë¡œ ë¡œë”©í•´ ëŒ€ì‹œë³´ë“œì— ë°˜ì˜í•©ë‹ˆë‹¤.")
    
    st.divider()

    # --- 2. AI ëª¨ë¸ ì„±ëŠ¥ (MAPE) - ìë™ ì‹¤í–‰ ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 2: AI ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì‹ ë¢°ë„ (ë°±í…ŒìŠ¤íŒ…) ğŸ§ ")
    st.markdown("""
    Prophet ëª¨ë¸ì„ **ì´ˆê¸° 5ê°œì›” ë°ì´í„°ë¡œ í›ˆë ¨**í•˜ê³ , ì´í›„ ê¸°ê°„ì˜ ì‹¤ì œ íŒë§¤ëŸ‰ê³¼ ë¹„êµí•©ë‹ˆë‹¤.
    """)

    unique_days = df_csv['ë‚ ì§œ'].nunique() if not df_csv.empty else 0
    max_test_days = max(1, min(60, unique_days - 10)) if unique_days else 0

    if max_test_days < 3:
        st.warning("ê²€ì¦í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ìµœì†Œ 10ì¼ í›ˆë ¨ + 3ì¼ ê²€ì¦ í•„ìš”)")
    else:
        default_test_days = min(30, max_test_days)
        test_days_input = st.number_input(
            "ê²€ì¦ ê¸°ê°„(ì¼) ì„ íƒ", 
            min_value=1, max_value=int(max_test_days), value=int(default_test_days),
            help="ë°ì´í„°ì…‹ì˜ ë§ˆì§€ë§‰ Nì¼ì„ 'ê²€ì¦ìš©(ì‹¤ì œê°’)'ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
        )

        with st.spinner(f"ëª¨ë¸ì„ ê²€ì¦í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... (í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_days_input}ì¼) â³"):
            mape, fig, msg = run_prophet_backtesting(df_csv, test_days=test_days_input)
        
        if mape is not None:
            st.metric("ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ í‰ê·  ì˜¤ì°¨ìœ¨ (MAPE)", f"{mape:.2f} %")
            st.caption(f"**(ì—°êµ¬ ê²°ê³¼ í•´ì„)** ëª¨ë¸ì€ í–¥í›„ {test_days_input}ì¼ì„ ì˜ˆì¸¡í•  ë•Œ **í‰ê·  ì•½ {mape:.2f}%ì˜ ì˜¤ì°¨**ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.")
            st.pyplot(fig) 
        else:
            st.error(f"ê²€ì¦ ì‹¤íŒ¨: {msg}")
            
    st.divider()

    # --- 2-1. ì „ë‹¬ë°›ì€ ë³„ë„ CSV ë·°ì–´ (êµ­ë¬¸ ë¦¬í¬íŠ¸) ---
    st.subheader("í˜„ì¥ CSV ìŠ¤ëƒ…ìƒ· (ë³„ë„ ì œê³µ íŒŒì¼) ğŸ“‚")
    tab_aug, tab_prod, tab_hour, tab_top = st.tabs([
        "ë°ì´í„° ì¦ê°•", "ìƒí’ˆë§¤ì¶œí˜„í™©", "ì‹œê°„ëŒ€ë³„ ë§¤ì¶œë¶„ì„", "ì¹´í”¼ì—”ë“œ Top5"
    ])

    with tab_aug:
        df_aug = load_augmented_sales()
        if df_aug is None or df_aug.empty:
            st.info("data/ë°ì´í„° ì¦ê°•.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            c1, c2, c3 = st.columns(3)
            c1.metric("ê±°ë˜ ê±´ìˆ˜", f"{len(df_aug):,} ê±´")
            c2.metric("ì´ ë§¤ì¶œ", format_krw(df_aug['price'].sum()))
            latest_ts = df_aug['timestamp'].max()
            latest_txt = latest_ts.strftime("%Y-%m-%d %H:%M") if pd.notna(latest_ts) else "-"
            c3.metric("ë§ˆì§€ë§‰ ê±°ë˜ì‹œê°", latest_txt)

            hourly = df_aug.groupby('hour')['price'].sum().reset_index()
            fig_aug = px.bar(hourly, x='hour', y='price', title="ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ (ì¦ê°• ë°ì´í„°)")
            st.plotly_chart(fig_aug, use_container_width=True)
            st.dataframe(df_aug.head(200), use_container_width=True)
            with st.expander("ì»¬ëŸ¼ êµ¬ì¡°"):
                st.markdown("""
                - timestamp: ê±°ë˜ ë°œìƒ ì‹œê° (datetime)
                - menu_item: ë©”ë‰´ëª…
                - price: íŒë§¤ ê¸ˆì•¡
                - day_of_week: ìš”ì¼ ë¬¸ìì—´ (e.g., MONDAY)
                - hour: ì‹œ(hour) ìˆ«ì
                - day_type: WEEKDAY / WEEKEND êµ¬ë¶„
                """)

    with tab_prod:
        df_prod = load_product_status()
        if df_prod is None or df_prod.empty:
            st.info("data/ìƒí’ˆë§¤ì¶œí˜„í™©.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            c1, c2 = st.columns(2)
            if 'íŒë§¤ê¸ˆì•¡' in df_prod.columns:
                c1.metric("ì´ íŒë§¤ê¸ˆì•¡", format_krw(df_prod['íŒë§¤ê¸ˆì•¡'].sum()))
            if 'ìˆ˜ëŸ‰' in df_prod.columns:
                c2.metric("ì´ íŒë§¤ìˆ˜ëŸ‰", f"{int(df_prod['ìˆ˜ëŸ‰'].sum()):,} ê°œ")

            if 'íŒë§¤ê¸ˆì•¡' in df_prod.columns:
                top5 = df_prod.sort_values('íŒë§¤ê¸ˆì•¡', ascending=False).head(5)
                fig_prod = px.bar(top5, x='ìƒí’ˆëª…', y='íŒë§¤ê¸ˆì•¡', title="ìƒí’ˆë§¤ì¶œ Top 5", text='íŒë§¤ê¸ˆì•¡')
                st.plotly_chart(fig_prod, use_container_width=True)
            st.dataframe(df_prod, use_container_width=True)
            with st.expander("ì»¬ëŸ¼ êµ¬ì¡°"):
                st.markdown("""
                - ìƒí’ˆëª…: ë©”ë‰´ ì´ë¦„
                - ìƒí’ˆì½”ë“œ: ë‚´ë¶€ ì½”ë“œ
                - ìˆ˜ëŸ‰: íŒë§¤ ìˆ˜ëŸ‰
                - ì ìœ ìœ¨(ìˆ˜ëŸ‰): ìˆ˜ëŸ‰ ê¸°ì¤€ ë¹„ì¤‘ (%)
                - íŒë§¤ê¸ˆì•¡: ì´ ë§¤ì¶œì•¡
                - ì ìœ ìœ¨(ê¸ˆì•¡): ë§¤ì¶œì•¡ ê¸°ì¤€ ë¹„ì¤‘ (%)
                """)

    with tab_hour:
        df_hour = load_hourly_sales()
        if df_hour is None or df_hour.empty:
            st.info("data/ì‹œê°„ëŒ€ë³„ ë§¤ì¶œë¶„ì„.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if {'hour', 'ì´ì•¡'}.issubset(df_hour.columns):
                fig_hour = px.bar(df_hour, x='hour', y='ì´ì•¡', title="ì‹œê°„ëŒ€ë³„ ì´ì•¡", labels={'hour': 'ì‹œê°„'})
                st.plotly_chart(fig_hour, use_container_width=True)
            st.dataframe(df_hour, use_container_width=True)
            with st.expander("ì»¬ëŸ¼ êµ¬ì¡°"):
                st.markdown("""
                - hour: 0~23ì‹œ
                - ì´ì•¡: í•´ë‹¹ ì‹œê°„ëŒ€ ì´ ë§¤ì¶œ
                - í˜„ê¸ˆ / ì¹´ë“œ / í˜„ê¸ˆì˜ìˆ˜ì¦: ê²°ì œ ìˆ˜ë‹¨ë³„ ë§¤ì¶œ
                - í• ì¸: í• ì¸ ì ìš© ê¸ˆì•¡
                - ê±°ë˜ê±´ìˆ˜: íŠ¸ëœì­ì…˜ ìˆ˜
                """)

    with tab_top:
        df_top = load_top5_recipe()
        if df_top is None or df_top.empty:
            st.info("data/ì¹´í”¼ì—”ë“œ_ì»¤í”¼_Top5.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.caption("Top5 ë©”ë‰´ì˜ ë ˆì‹œí”¼/ì›ê°€ í…Œì´ë¸”ì…ë‹ˆë‹¤. (ì›ë³¸ ê·¸ëŒ€ë¡œ í‘œì‹œ)")
            st.dataframe(df_top, use_container_width=True)
            with st.expander("ì»¬ëŸ¼ êµ¬ì¡°"):
                st.markdown("""
                - ë©” ë‰´: ë©”ë‰´ëª…
                - í’ˆ ëª©: ì¬ë£Œëª…
                - ë‹¨ê°€(ì›), ë‹¨ìœ„, ìˆ˜ëŸ‰, ê°œë³„ê°€: ì¬ë£Œ ë‹¨ê°€/ê·œê²©
                - ì‚¬ìš©ëŸ‰, ì‚¬ìš© ë‹¨ê°€, ì‚¬ìš©ë‹¨ê°€ í•©ê³„: ë ˆì‹œí”¼ ì†Œìš”ëŸ‰ ë° ì›ê°€
                - íŒë§¤ê°€ê²©: ë©”ë‰´ íŒë§¤ê°€
                - ì›ê°€ìœ¨: ì›ê°€/íŒë§¤ê°€ ë¹„ìœ¨
                """)

    st.divider()

    # --- 3. ì‹¤ìš©ì  ë¹„ìš© ëª¨ë¸ ì„¤ê³„ (Cost Model) ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 3: ì‹¤ìš©ì  ë¹„ìš© ëª¨ë¸ ì„¤ê³„ (Trade-off ë¶„ì„) ğŸ’°")
    st.markdown("""
    ì¸í„°ë·° ê²°ê³¼(ë¹„ìš© ë¯¼ê°ë„)ì™€ ê¸°ìˆ ì  ì‹¤ì¦(AI ë¹„ìš©)ì„ í† ëŒ€ë¡œ, ë³¸ ì—°êµ¬ëŠ” 2ê°€ì§€ ìƒìš©í™” ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    """)
    col1, col2 = st.columns(2)
    with col1:
        st.info("**A. ê¸°ë³¸í˜• (ì›” $35-50 ê³ ì •ë¹„)**")
        st.markdown("""
        * **í¬í•¨:** ì¬ê³  ê´€ë¦¬, ë°ì´í„° ì§‘ê³„, BOM/ROP ê³„ì‚°
        * **ëŒ€ìƒ:** ë¹„ìš©ì— ê·¹ë„ë¡œ ë¯¼ê°í•˜ë©°, ìš´ì˜ ìë™í™”ê°€ ìµœìš°ì„ ì¸ ì¹´í˜
        """)
    with col2:
        st.warning("**B. AI í™•ì¥í˜• (ì›” $50 + ë³€ë™ë¹„)**")
        st.markdown("""
        * **í¬í•¨:** ê¸°ë³¸í˜• + AI ë¹„ì„œ (OpenAI), ìˆ˜ìš” ì˜ˆì¸¡ (Prophet)
        * **ëŒ€ìƒ:** ë§ˆì¼€íŒ…, ì‹ ë©”ë‰´ ê°œë°œ ë“± ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•œ ì¹´í˜
        """)
    st.caption("ì´ëŠ” ì†Œìƒê³µì¸ì´ ìì‹ ì˜ ì˜ˆì‚°ê³¼ í•„ìš”ì— ë§ì¶° í•©ë¦¬ì ì¸ DX(ë””ì§€í„¸ ì „í™˜)ë¥¼ ì„ íƒí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì‹¤ìš©ì ì¸ ì„¤ê³„ì•ˆì…ë‹ˆë‹¤.")
# ==============================================================
# â“ ë„ì›€ë§
# ==============================================================
# ==============================================================
# â“ ë„ì›€ë§
# ==============================================================
elif menu == "ë„ì›€ë§":
    st.header("â˜•ï¸ ì»¤í”¼ ì›ë‘ ì¬ê³ ê´€ë¦¬ íŒŒì´í”„ë¼ì¸ ì‰½ê²Œ ì´í•´í•˜ê¸°")
    
    st.markdown("""
> **â€œì»¤í”¼ ì›ë‘ê°€ ì–´ë–»ê²Œ ë“¤ì–´ì˜¤ê³ , ì–¼ë§ˆë‚˜ ì“°ì´ê³ , ì–¸ì œ ë‹¤ì‹œ ì£¼ë¬¸ë¼ì•¼ í•˜ëŠ”ì§€ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ì!â€** ì—‘ì…€ ëŒ€ì‹  ERPê°€ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì¤ë‹ˆë‹¤.
""")

    # ------------------------------------------------------------------
    # âœ… (ì¶”ê°€ë¨) ì›¹ì‚¬ì´íŠ¸ ì‚¬ìš©ë²• ì„¹ì…˜
    # ------------------------------------------------------------------
    st.subheader("ğŸ“š ì›¹ì‚¬ì´íŠ¸ ì‚¬ìš©ë²• ê°€ì´ë“œ: ë©”ë‰´ë³„ í•µì‹¬ ê¸°ëŠ¥")
    st.markdown("---")
    
    st.markdown("""
    ë³¸ ëŒ€ì‹œë³´ë“œëŠ” **ë°ì´í„° í™•ì¸**, **ì¬ê³ /ì›ê°€ ê´€ë¦¬**, **ê±°ë˜ ì…ë ¥/ìˆ˜ì •**, **AI ë¶„ì„**ì˜ ë„¤ ê°€ì§€ ì˜ì—­ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.
    
    ### 1. ğŸ“Š ë°ì´í„° í™•ì¸ ë° ë¶„ì„
    
    | ë©”ë‰´ | ëª©ì  | ì£¼ìš” í‘œì‹œ í•­ëª© |
    | :--- | :--- | :--- |
    | **ê²½ì˜ í˜„í™©** | ì „ì²´ ì´ê´„ ìš”ì•½ (ë§¤ì¶œì•¡, íŒë§¤ ê±´ìˆ˜) | ì´ ë§¤ì¶œ, ê±´ë‹¹ í‰ê·  ë§¤ì¶œ, ì¹´í…Œê³ ë¦¬ë³„/ì¼ìë³„ ë§¤ì¶œ ì¶”ì´ |
    | **ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ** | ì£¼ìš” ë§¤ì¶œ ì¶”ì„¸ íŒŒì•… | ì›”ë³„/ì¹´í…Œê³ ë¦¬ë³„ ëˆ„ì  ë§¤ì¶œ, ìƒí’ˆ êµ¬ì¡°ë³„ (íŠ¸ë¦¬ë§µ) ë§¤ì¶œ ê¸°ì—¬ë„ |
    | **ê¸°ê°„ë³„ ë¶„ì„** | íŠ¹ì • ê¸°ê°„ì˜ íŒë§¤ íŠ¹ì„± ë¶„ì„ | ìš”ì¼ë³„ ë§¤ì¶œ (ë°” ì°¨íŠ¸), ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ ì¶”ì´ (ë¼ì¸ ì°¨íŠ¸) |
    | **ê±°ë˜ ë‚´ì—­** | ì›ì²œ ë°ì´í„° ì¡°íšŒ | í•„í„°ë§/ê²€ìƒ‰ ê¸°ëŠ¥ìœ¼ë¡œ íŠ¹ì • ê¸°ê°„, ìƒí’ˆì˜ ê±°ë˜ ë‚´ì—­ í™•ì¸ |
    
    ---
    
    ### 2. âš™ï¸ ê´€ë¦¬ ë° í¸ì§‘
    
    | ë©”ë‰´ | ëª©ì  | ì£¼ìš” ì‘ì—… |
    | :--- | :--- | :--- |
    | **ê±°ë˜ ì¶”ê°€** | ì‹ ê·œ íŒë§¤ ê±°ë˜ ì…ë ¥ | ì¹´í…Œê³ ë¦¬/íƒ€ì…/ìƒì„¸ ì„ íƒ í›„ ìˆ˜ëŸ‰/ë‹¨ê°€ ì…ë ¥ â†’ **ì¬ê³  ìë™ ì°¨ê°** |
    | **ë°ì´í„° í¸ì§‘** | ê¸°ì¡´ ê±°ë˜ ìˆ˜ì •/ì‚­ì œ | Firebase ë°ì´í„° ìˆ˜ì •/ì‚­ì œ, **ìˆ˜ëŸ‰ ë³€ê²½ ì‹œ ì¬ê³  ìë™ ì¡°ì •** |
    | **ì¬ê³  ê´€ë¦¬** | ì¬ë£Œ/ë©”ë‰´ ë§ˆìŠ¤í„° ë° ë ˆì‹œí”¼(BOM) ê´€ë¦¬ | ì¬ë£Œ/ì›ê°€/í˜„ì¬ ì¬ê³  ìˆ˜ê¸° ì…ë ¥, ë©”ë‰´ë³„ ë ˆì‹œí”¼ ë“±ë¡ ë° ìˆ˜ì • |
    
    ---
    
    ### 3. ğŸ¤– AI ê¸°ë°˜ ì˜ì‚¬ ê²°ì •
    
    | ë©”ë‰´ | ëª©ì  | ì£¼ìš” ì œê³µ ê¸°ëŠ¥ |
    | :--- | :--- | :--- |
    | **AI ë¹„ì„œ** | ë°ì´í„° ê¸°ë°˜ ì‹¤í–‰ ì¡°ì–¸ ì œê³µ | **ì¬ê³  ìœ„í—˜**, **ë§ˆì§„ ë¶„ì„**, **íŒë§¤ íŒ¨í„´** ë“± 3ëŒ€ ë¦¬í¬íŠ¸ ë° ì§ˆì˜ì‘ë‹µ |
    | **ì¬ê³  ê´€ë¦¬** (ë ˆì‹œí”¼ íƒ­) | ë©”ë‰´ ì œì¡°ì— í•„ìš”í•œ ì¬ë£Œì˜ ì ì • ë°œì£¼ëŸ‰ ê³„ì‚° | AI ì˜ˆì¸¡ ê¸°ë°˜ **ê¶Œì¥ ë°œì£¼ëŸ‰, ì»¤ë²„ ì¼ìˆ˜, ROP(ë°œì£¼ì )** ê³„ì‚° ë° ì°¨íŠ¸ ì œê³µ |
    
    """)
    # ------------------------------------------------------------------
    # ------------------------------------------------------------------
    
    st.markdown("---")
    # [AI/ML í†µí•© ìˆ˜ì •] ë„ì›€ë§ ë‚´ìš© ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ERP íŒŒì´í”„ë¼ì¸)
    st.markdown("## ğŸ“Š ERP íŒŒì´í”„ë¼ì¸ ì‘ë™ ì›ë¦¬")
    st.markdown("""
### 1. (ML) ìŠ¤ë§ˆíŠ¸ ë°œì£¼ ë¡œì§ (ì¬ê³  ê´€ë¦¬ íƒ­)
| ë‹¨ê³„ | í•˜ëŠ” ì¼ |
| --- | --- |
| **1. ìˆ˜ìš” ì˜ˆì¸¡** | Prophet (ML)ì´ "ì•„ë©”ë¦¬ì¹´ë…¸"ì˜ **ë¯¸ë˜ 21ì¼** íŒë§¤ëŸ‰ì„ [500ì”]ìœ¼ë¡œ ì˜ˆì¸¡ |
| **2. ì†Œì§„ëŸ‰ ê³„ì‚°** | [500ì”] x [ë ˆì‹œí”¼: ì”ë‹¹ 20g] = **[10,000g]** (ì˜ˆìƒ ì´ ì†Œì§„ëŸ‰) |
| **3. ê¶Œì¥ ë°œì£¼ëŸ‰** | [10,000g] - [í˜„ì¬ ì¬ê³ : 3,000g] = **[7,000g]** (ê¶Œì¥ ë°œì£¼ëŸ‰) |
| **4. ROP (ë°œì£¼ì )** | (ì¼í‰ê· ì†Œì§„ * ë¦¬ë“œíƒ€ì„) + ì•ˆì „ì¬ê³ . ì´ë³´ë‹¤ ì¬ê³ ê°€ ë‚®ìœ¼ë©´ **'ğŸš¨ ë°œì£¼ìš”ë§'** ì•Œë¦¼ |
### 2. (AI) ë§ˆì¼€íŒ… ë³´ì¡° (AI ë¹„ì„œ íƒ­)
| ê¸°ëŠ¥ | ì„¤ëª… |
| --- | --- |
| **ìš”ì²­ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±** | í˜„ì¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ì „ëµ, í™ë³´ ë¬¸êµ¬ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤. |
| **ìš´ì˜ ë³´ê³ ** | ì¼ì¼ ë§¤ì¶œ, íŒë§¤ ê±´ìˆ˜ ë“±ì„ ìš”ì•½í•˜ì—¬ ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. |
### 3. ê¸°ë³¸ ë°ì´í„° íë¦„
| ë‹¨ê³„ | í•˜ëŠ” ì¼ |
| --- | --- |
| **1. ì›ë‘ ì…ê³ ** | 'ì¬ê³  ê´€ë¦¬' > 'ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°'ì—ì„œ [+10,000g] ìˆ˜ë™ ì…ë ¥ ë° ì €ì¥ |
| **2. íŒë§¤ ë°œìƒ** | 'ê±°ë˜ ì¶”ê°€' íƒ­ ë˜ëŠ” POSì—ì„œ 'ì•„ë©”ë¦¬ì¹´ë…¸' 1ì” íŒë§¤ (Firestore 'coffee_sales'ì— ê¸°ë¡) |
| **3. ìë™ ì°¨ê°** | ì‹œìŠ¤í…œì´ 'ì•„ë©”ë¦¬ì¹´ë…¸' ë ˆì‹œí”¼(BOM)ë¥¼ ì¡°íšŒí•˜ì—¬ [ì›ë‘: 20g] ì‚¬ìš© í™•ì¸ |
| **4. ì¬ê³  ë°˜ì˜** | 'inventory' DBì˜ 'ì›ë‘' ì¬ê³ ë¥¼ [-20g] ìë™ ì°¨ê° (ì¬ê³  ì´ë™ ë¡œê·¸ ê¸°ë¡) |
""")
