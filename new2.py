# ==============================================================
# â˜• Coffee ERP Dashboard â€” Company Showcase Edition (Tone-Down Blue)
# (ê¸°ì¡´ ì£¼ì„ ìƒëµ)
# ==============================================================

import os
import json
import re
import warnings
from math import ceil
from pathlib import Path
from datetime import datetime
import time # #[AI/ML í†µí•© ì¶”ê°€] (Mock ì‘ë‹µìš©)

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.io as pio

import firebase_admin
from firebase_admin import credentials, firestore

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1 (AI ë¹„ì„œ) ë° SPRINT 2 (ìˆ˜ìš” ì˜ˆì¸¡) ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import openai
    import time
    from prophet import Prophet
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_absolute_percentage_error
except ImportError:
    st.error("""
    AI/ML ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.
    í„°ë¯¸ë„ì—ì„œ 'pip install openai prophet scikit-learn'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
    """)
    st.stop()
# === [AI/ML í†µí•© ì¶”ê°€] ===
# === [ë¹ˆí‹ˆ ìˆ˜ì •] ëˆ„ë½ëœ í•µì‹¬ ë„ìš°ë¯¸ í•¨ìˆ˜ (format_krw, safe_rerun) ===
def format_krw(x: float) -> str:
    """ìˆ«ìë¥¼ ì›í™” í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        return f"{x:,.0f} ì›"
    except Exception:
        return "-"

def safe_rerun():
    """Streamlit ë²„ì „ì— ë§ì¶° ì•±ì„ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤."""
    try:
        if hasattr(st, "rerun"):
            st.rerun()
        elif hasattr(st, "experimental_rerun"):
            st.experimental_rerun()
    except Exception as e:
        # (ìƒˆë¡œê³ ì¹¨ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ)
        pass
# ===================================================================


st.set_page_config(page_title="â˜• Coffee ERP Dashboard", layout="wide")


# (init_firebase í•¨ìˆ˜ ì›ë³¸)
def init_firebase():
    try:
        if "GOOGLE_APPLICATION_CREDENTIALS_JSON" in os.environ:
            cred_info = json.loads(os.environ["GOOGLE_APPLICATION_CREDENTIALS_JSON"])
            cred = credentials.Certificate(cred_info)
            if not firebase_admin._apps:
                firebase_admin.initialize_app(cred)
            return firestore.client(), "success"
        else:
            return None, "no_env"
    except Exception as e:
        return None, f"error: {e}"

# âœ… í•¨ìˆ˜ í˜¸ì¶œ í›„ UI í‘œì‹œ ë¶„ë¦¬
db, fb_status = init_firebase()

# --- Pylance/static analyzer guards (no runtime effect) ---
items = []  # type: ignore
sold_qty = 0  # type: ignore
summary = []  # type: ignore

# ----------------------
# 0ï¸âƒ£ ê²½ë¡œ/ìƒìˆ˜ (íŒ€ì›ì´ ì–´ë””ì„œ ë°›ì•„ë„ ë™ì‘)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
BASE_DIR = Path(__file__).resolve().parent

try:
    SECRETS = dict(st.secrets)
except Exception:
    SECRETS = {}

def _resolve_path(val, default: Path) -> Path:
    if not val:
        return default
    p = Path(str(val))
    return p if p.is_absolute() else (BASE_DIR / p)

DATA_DIR   = _resolve_path(SECRETS.get("DATA_DIR")   or os.environ.get("ERP_DATA_DIR"),   BASE_DIR / "data")
ASSETS_DIR = _resolve_path(SECRETS.get("ASSETS_DIR") or os.environ.get("ERP_ASSETS_DIR"), BASE_DIR / "assets")
KEYS_DIR   = _resolve_path(SECRETS.get("KEYS_DIR")   or os.environ.get("ERP_KEYS_DIR"),   BASE_DIR / "keys")

CSV_PATH     = DATA_DIR / "Coffee Shop Sales.csv"
PIPELINE_IMG = ASSETS_DIR / "pipeline_diagram.png"
SA_FILE_PATH = KEYS_DIR / "serviceAccount.json"

SALES_COLLECTION      = "coffee_sales"
INVENTORY_COLLECTION  = "inventory"
ORDERS_COLLECTION     = "orders"
SKU_PARAMS_COLLECTION = "sku_params"

RECIPES_COLLECTION      = "recipes"
STOCK_COUNTS_COLLECTION = "stock_counts"
STOCK_MOVES_COLLECTION  = "stock_moves"

USE_KRW_CONVERSION = True
KRW_PER_USD = 1350
DEFAULT_INITIAL_STOCK   = 10000
REORDER_THRESHOLD_RATIO = 0.15


for p in (DATA_DIR, ASSETS_DIR, KEYS_DIR):
    p.mkdir(parents=True, exist_ok=True)


# ----------------------
# 0-1ï¸âƒ£ Firebase ì´ˆê¸°í™” (Secrets â†’ keys/ â†’ GOOGLE_APPLICATION_CREDENTIALS)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_resource
def init_firestore():
    """Firebase ì¸ì¦ ë° Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€ + ìºì‹œ ì ìš©)"""
    if firebase_admin._apps:
        return firestore.client()
    svc_dict = SECRETS.get("firebase_service_account")
    if isinstance(svc_dict, dict) and svc_dict:
        cred = credentials.Certificate(svc_dict)
        firebase_admin.initialize_app(cred)
        return firestore.client()
    if SA_FILE_PATH.exists():
        cred = credentials.Certificate(str(SA_FILE_PATH))
        firebase_admin.initialize_app(cred)
        return firestore.client()
    gac = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if gac and Path(gac).expanduser().exists():
        firebase_admin.initialize_app()
        return firestore.client()
    st.error(
        "Firebase ìê²©ì¦ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:\n"
        "â€¢ st.secrets['firebase_service_account'] ë”•ì…”ë„ˆë¦¬\n"
        "â€¢ keys/serviceAccount.json íŒŒì¼\n"
        "â€¢ í™˜ê²½ë³€ìˆ˜ GOOGLE_APPLICATION_CREDENTIALS=ìê²©ì¦ëª…íŒŒì¼ê²½ë¡œ"
    )
    st.stop()


db = init_firestore()

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í‚¤ ì„¤ì •
try:
    openai.api_key = st.secrets["openai"]["api_key"]
except (KeyError, AttributeError):
    st.warning("""
    OpenAI API í‚¤ê°€ 'secrets.toml'ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 
    AI ë¹„ì„œ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šê±°ë‚˜ Mock ë°ì´í„°ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
    [.streamlit/secrets.toml] íŒŒì¼ì— [openai] api_key = "sk-..."ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
    """)
    openai.api_key = None # í‚¤ê°€ ì—†ì–´ë„ ì•±ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡
# === [AI/ML í†µí•© ì¶”ê°€] ===

# ----------------------
# 0-2ï¸âƒ£ UI/ìŠ¤íƒ€ì¼
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
pio.templates.default = "plotly_white"
px.defaults.template = "plotly_white"
px.defaults.color_continuous_scale = "Blues"

st.markdown("""
    <style>
    /* ... (ê¸°ì¡´ ìŠ¤íƒ€ì¼ ì •ì˜) ... */
    </style>
""", unsafe_allow_html=True)


st.markdown("""
<div class="dashboard-header">
  <h1>â˜• Coffee ERP Dashboard</h1>
</div>
""", unsafe_allow_html=True)

# ----------------------
# 0-3ï¸âƒ£ í•œê¸€ ë§¤í•‘ í…Œì´ë¸”
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
category_map = {
    "Coffee": "ì»¤í”¼", "Tea": "ì°¨", "Bakery": "ë² ì´ì»¤ë¦¬",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Packaged Chocolate": "í¬ì¥ ì´ˆì½œë¦¿",
}
rev_category_map = {v: k for k, v in category_map.items()}
rev_category_map.update({
    "ë² ì´ì»¤ë¦¬": "Bakery",
    # ... (ê¸°ì¡´ ì—­ ë§¤í•‘) ...
    "ì»¤í”¼": "Coffee",
})

type_map = {
    "Barista Espresso": "ë°”ë¦¬ìŠ¤íƒ€ ì—ìŠ¤í”„ë ˆì†Œ",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Premium Brewed Coffee": "í”„ë¦¬ë¯¸ì—„ ë¸Œë£¨ë“œ ì»¤í”¼",
}
rev_type_map = {v: k for k, v in type_map.items()}

SIZE_SUFFIX_MAP = {"Lg": "ë¼ì§€", "Rg": "ë ˆê·¤ëŸ¬", "Sm": "ìŠ¤ëª°"}
REV_SIZE_SUFFIX_MAP = {"ë¼ì§€": "Lg", "ë ˆê·¤ëŸ¬": "Rg", "ìŠ¤ëª°": "Sm"}

detail_base_map = {
    "Almond Croissant": "ì•„ëª¬ë“œ í¬ë£¨ì•„ìƒ",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Traditional Blend Chai": "íŠ¸ë˜ë””ì…”ë„ ë¸”ë Œë“œ ì°¨ì´",
}
rev_detail_base_map = {v: k for k, v in detail_base_map.items()}

def to_korean_detail(name: str) -> str:
    s = str(name).strip()
    if re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s):
        return s
    m = re.search(r"\s+(Lg|Rg|Sm)$", s)
    size_en = m.group(1) if m else None
    base_en = s[: -len(size_en) - 1] if size_en else s
    base_ko = detail_base_map.get(base_en, base_en)
    if size_en:
        return f"{base_ko} ({SIZE_SUFFIX_MAP[size_en]})"
    return base_ko

def from_korean_detail(display: str) -> str:
    s = str(display).strip()
    if re.search(r"\s+(Lg|Rg|Sm)$", s):
        return s
    m = re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s)
    size_ko = m.group(1) if m else None
    base_ko = re.sub(r"\s*\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", "", s)
    base_en = rev_detail_base_map.get(base_ko, base_ko)
    if size_ko:
        return f"{base_en} {REV_SIZE_SUFFIX_MAP[size_ko]}"
    return base_en

weekday_map = {"Monday": "ì›”", "Tuesday": "í™”", "Wednesday": "ìˆ˜",
               "Thursday": "ëª©", "Friday": "ê¸ˆ", "Saturday": "í† ", "Sunday": "ì¼"}
weekday_order_kr = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]

def map_series(s: pd.Series, mapping: dict) -> pd.Series:
    return s.apply(lambda x: mapping.get(x, x))

# ----------------------
# âœ… UoM(ë‹¨ìœ„) ìœ í‹¸
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def normalize_uom(u: str | None) -> str:
    u = (u or "ea").strip().lower()
    if u in {"g", "gram", "grams", "ê·¸ë¨", "kg", "í‚¬ë¡œê·¸ë¨"}:
        return "g"
    if u in {"ml", "ë°€ë¦¬ë¦¬í„°", "l", "ë¦¬í„°"}:
        return "ml"
    return "ea"

def convert_qty(qty: float, from_uom: str, to_uom: str) -> float:
    fu = normalize_uom(from_uom)
    tu = normalize_uom(to_uom)
    if fu == tu:
        return float(qty)
    return float(qty)

def safe_float(x, default=0.0):
    if x is None:
        return default
    try:
        if isinstance(x, (int, float)):
            try:
                if pd.isna(x):
                    return default
            except Exception:
                pass
            return float(x)
        if isinstance(x, str):
            s = x.strip()
            if s == "" or s.lower() in {"nan", "none"}:
                return default
            s = s.replace(",", "")
            return float(s)
        return float(x)
    except Exception:
        return default

# ----------------------
# âœ… ë‚ ì§œ íŒŒì„œ: ëª…ì‹œ í˜•ì‹ ìš°ì„  + ê²½ê³ ì—†ëŠ” í´ë°±
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def parse_mixed_dates(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip()
    out = pd.Series(pd.NaT, index=s.index, dtype="datetime64[ns]")
    patterns = [
        (r'^\d{4}-\d{2}-\d{2}$', '%Y-%m-%d'),
        (r'^\d{4}/\d{2}/\d{2}$', '%Y/%m/%d'),
        (r'^\d{2}/\d{2}/\d{4}$', '%m/%d/%Y'),
        (r'^\d{2}-\d{2}-\d{4}$', '%m-%d-%Y'),
        (r'^\d{4}\.\d{2}\.\d{2}$', '%Y.%m.%d'),
        (r'^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}$', '%Y-%m-%d %H:%M:%S'),
        (r'^\d{2}/\d{2}/\d{4}\s+\d{2}:\d{2}:\d{2}$', '%m/%d/%Y %H:%M:%S'),
    ]
    for pat, fmt in patterns:
        mask = s.str.match(pat)
        if mask.any():
            out.loc[mask] = pd.to_datetime(s.loc[mask], format=fmt, errors='coerce')
    remain = out.isna()
    if remain.any():
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", UserWarning)
            out.loc[remain] = pd.to_datetime(s.loc[remain], errors='coerce')
    return out

# ----------------------
# 1ï¸âƒ£ CSV ë¡œë“œ (ìƒ˜í”Œ ìƒì„± ì—†ìŒ)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_data(ttl=3600) 
def load_csv_FINAL(path: Path): # [Pylance ì˜¤ë¥˜] íƒ€ì… íŒíŠ¸ ì œê±°
    """
    Kaggle CSVë¥¼ ë¡œë“œí•˜ê³ , 'ì²˜ë¦¬ ì†ë„'ë¥¼ ì¸¡ì •í•˜ë©°,
    'ìˆ˜ìµ' ì»¬ëŸ¼ì„ 'ìˆ˜ëŸ‰ * ë‹¨ê°€'ë¡œ *ì§ì ‘ ê³„ì‚°*í•©ë‹ˆë‹¤.
    """
    if not path.exists():
        st.error(f"CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {path})")
        st.stop()
    
    #st.write(f"Kaggle ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œì‘... (ê²½ë¡œ: {path})")
    start_time = time.time() # [ì²˜ë°© 2] ì‹œê°„ ì¸¡ì • ì‹œì‘
    
    df = pd.read_csv(path)
    
    # 1. ì›ë³¸ ì»¬ëŸ¼ëª… -> í•œê¸€ ì»¬ëŸ¼ëª… ë³€í™˜
    # [!!!] 'Revenue': 'ìˆ˜ìµ' -> ì˜¤ë¥˜ì˜ ì›ì¸ì´ë¯€ë¡œ *ì œê±°*
    df = df.rename(columns={
        'transaction_id': 'ê±°ë˜ë²ˆí˜¸', 'transaction_date': 'ë‚ ì§œ', 'transaction_time': 'ì‹œê°„',
        'transaction_qty': 'ìˆ˜ëŸ‰', 'store_id': 'ê°€ê²ŒID', 'store_location': 'ê°€ê²Œìœ„ì¹˜',
        'product_id': 'ìƒí’ˆID', 'unit_price': 'ë‹¨ê°€', 'product_category': 'ìƒí’ˆì¹´í…Œê³ ë¦¬',
        'product_type': 'ìƒí’ˆíƒ€ì…', 'product_detail': 'ìƒí’ˆìƒì„¸'
    })
    
    # 2. 'ë‹¨ê°€'ì™€ 'ìˆ˜ëŸ‰' ì •ë¦¬
    try:
        df['ë‹¨ê°€'] = df['ë‹¨ê°€'].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
        df['ìˆ˜ëŸ‰'] = pd.to_numeric(df['ìˆ˜ëŸ‰'], errors='coerce')
    except KeyError:
        st.error("ì˜¤ë¥˜: ì›ë³¸ CSVì— 'unit_price'(ë‹¨ê°€) ë˜ëŠ” 'transaction_qty'(ìˆ˜ëŸ‰)ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # 3. [!!! í•µì‹¬ ìˆ˜ì • !!!] 'ìˆ˜ìµ' ì»¬ëŸ¼ì„ *ì§ì ‘ ê³„ì‚°*
    if 'ìˆ˜ëŸ‰' in df.columns and 'ë‹¨ê°€' in df.columns:
        df['ìˆ˜ìµ'] = df['ìˆ˜ëŸ‰'] * df['ë‹¨ê°€']
    else:
        st.error("ì˜¤ë¥˜: 'ìˆ˜ëŸ‰' ë˜ëŠ” 'ë‹¨ê°€' ì»¬ëŸ¼ì´ ì—†ì–´ 'ìˆ˜ìµ'ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # 4. KRW ë³€í™˜ (ê¸°ì¡´ ë¡œì§ ì¡´ì¤‘, 'ìˆ˜ìµ' ê³„ì‚° *ì´í›„*ì— ì‹¤í–‰)
    try:
        # (USE_KRW_CONVERSION, KRW_PER_USD ë³€ìˆ˜ëŠ” ì´ í•¨ìˆ˜ *ë°–ì—* ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨)
        if 'USE_KRW_CONVERSION' in globals() and USE_KRW_CONVERSION:
            if 'KRW_PER_USD' in globals():
                df['ìˆ˜ìµ'] *= KRW_PER_USD
                df['ë‹¨ê°€'] *= KRW_PER_USD
    except Exception:
        pass 

    # 5. ë‚ ì§œ ë° ì‹œê°„ ì²˜ë¦¬ (Kaggle ì›ë³¸ í˜•ì‹: %m/%d/%Y)
    try:
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], format='%m/%d/%Y')
    except ValueError:
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce') # ì‹¤íŒ¨ ì‹œ, ì¬ì‹œë„
        
    if 'ì‹œê°„' in df.columns:
        df['ì‹œ'] = pd.to_datetime(df['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df['ì‹œ'] = None
    
    df['ìš”ì¼'] = df['ë‚ ì§œ'].dt.day_name()
    df['ì›”'] = df['ë‚ ì§œ'].dt.month
    
    # 6. ë¶ˆí•„ìš” ë°ì´í„° ì œê±°
    df = df.dropna(subset=['ë‚ ì§œ', 'ìˆ˜ìµ']) 
    
    end_time = time.time()
    load_time = end_time - start_time
    row_count_final = len(df)
    
    #st.success(f"ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì™„ë£Œ. ({row_count_final}ê±´, {load_time:.4f} ì´ˆ)")
    
    return df, load_time, row_count_final

df_csv, load_time, row_count = load_csv_FINAL(CSV_PATH)

@st.cache_data(ttl=3600)
def run_prophet_backtesting(df_input, test_days=30): # [Pylance ì˜¤ë¥˜] íƒ€ì… íŒíŠ¸ ì œê±°
    """
    'ì˜ˆì¸¡'ì´ ì•„ë‹Œ 'ì—°êµ¬ ê²€ì¦'ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    if df_input is None or df_input.empty:
        return None, None, "ì˜¤ë¥˜: ì…ë ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
    # 1. ë°ì´í„° ì „ì²˜ë¦¬ (Prophet í˜•ì‹: ds, y)
    if 'ìˆ˜ìµ' not in df_input.columns or 'ë‚ ì§œ' not in df_input.columns:
        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: ë°±í…ŒìŠ¤íŒ…ì— í•„ìš”í•œ 'ë‚ ì§œ' ë˜ëŠ” 'ìˆ˜ìµ' ì»¬ëŸ¼ì´ dfì— ì—†ìŠµë‹ˆë‹¤.")
        return None, None, "ë°ì´í„° ì»¬ëŸ¼ëª… ì˜¤ë¥˜"
        
    df_prophet = df_input[['ë‚ ì§œ', 'ìˆ˜ìµ']].copy()
    
    df_prophet = df_prophet.rename(columns={'ë‚ ì§œ': 'ds', 'ìˆ˜ìµ': 'y'})
    df_prophet = df_prophet.groupby('ds').sum().reset_index()

    if len(df_prophet) < test_days + 10: 
        return None, None, f"ì˜¤ë¥˜: ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤."

    # 2. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    split_date = df_prophet['ds'].max() - pd.to_timedelta(test_days, 'D')
    train_data = df_prophet[df_prophet['ds'] <= split_date]
    test_data = df_prophet[df_prophet['ds'] > split_date]

    if len(train_data) < 10:
        return None, None, "ì˜¤ë¥˜: í›ˆë ¨ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤."

    # 3. ëª¨ë¸ í›ˆë ¨ (Kaggle ë°ì´í„°ëŠ” 6ê°œì›”ì´ë¯€ë¡œ yearly_seasonality=False)
    m = Prophet(daily_seasonality=True, yearly_seasonality=False, weekly_seasonality=True)
    m.fit(train_data)

    # 4. ì˜ˆì¸¡
    future_frame = m.make_future_dataframe(periods=test_days, freq='D')
    forecast = m.predict(future_frame)
    
    # 5. ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³‘í•©
    comparison_df = pd.merge(test_data[['ds', 'y']], forecast[['ds', 'yhat']], on='ds')

    # 6. MAPE ê³„ì‚°
    comparison_df = comparison_df[comparison_df['y'] > 0] # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    if comparison_df.empty:
        return None, None, "ì˜¤ë¥˜: MAPE ê³„ì‚°ì„ ìœ„í•œ ìœ íš¨í•œ ë¹„êµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ('ìˆ˜ìµ' ì»¬ëŸ¼ì´ 0 ë˜ëŠ” NaNì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"
        
    mape = mean_absolute_percentage_error(comparison_df['y'], comparison_df['yhat']) * 100
    
    # 7. ì‹œê°í™”
    fig = m.plot(forecast)
    ax = fig.gca()
    ax.plot(test_data['ds'], test_data['y'], 'r.', label='Actual Test Data (ì‹¤ì œê°’)')
    ax.legend()

    return mape, fig, f"ëª¨ë¸ ê²€ì¦ ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_days}ì¼)"


# ----------------------
# 2ï¸âƒ£ Firestore(íŒë§¤) ë¡œë“œ
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def load_sales_from_firestore() -> pd.DataFrame:
    docs = db.collection(SALES_COLLECTION).stream()
    data = [d.to_dict() for d in docs]
    df_fb = pd.DataFrame(data)
    if df_fb.empty:
        return df_fb
    if 'ë‚ ì§œ' in df_fb.columns:
        df_fb['ë‚ ì§œ'] = parse_mixed_dates(df_fb['ë‚ ì§œ'])
    if 'ìˆ˜ìµ' in df_fb.columns:
        df_fb['ìˆ˜ìµ'] = pd.to_numeric(df_fb['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_fb.columns:
        df_fb['ë‹¨ê°€'] = pd.to_numeric(df_fb['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_fb.columns:
        df_fb['ìˆ˜ëŸ‰'] = pd.to_numeric(df_fb['ìˆ˜ëŸ‰'], errors='coerce')
    if 'ì‹œê°„' in df_fb.columns:
        df_fb['ì‹œ'] = pd.to_datetime(df_fb['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df_fb['ì‹œ'] = None
    df_fb['ìš”ì¼'] = df_fb['ë‚ ì§œ'].dt.day_name()
    df_fb['ì›”'] = df_fb['ë‚ ì§œ'].dt.month
    return df_fb

df_fb = load_sales_from_firestore()

def load_sales_with_id():
    docs = db.collection(SALES_COLLECTION).stream()
    rows = []
    for d in docs:
        rec = d.to_dict()
        rec["_id"] = d.id
        rows.append(rec)
    df_raw = pd.DataFrame(rows)
    if df_raw.empty:
        return df_raw, df_raw
    if 'ë‚ ì§œ' in df_raw.columns:
        df_raw['ë‚ ì§œ'] = parse_mixed_dates(df_raw['ë‚ ì§œ'])
    if 'ìˆ˜ìµ' in df_raw: df_raw['ìˆ˜ìµ'] = pd.to_numeric(df_raw['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_raw: df_raw['ë‹¨ê°€'] = pd.to_numeric(df_raw['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_raw: df_raw['ìˆ˜ëŸ‰'] = pd.to_numeric(df_raw['ìˆ˜ëŸ‰'], errors='coerce')
    df_view = df_raw.copy()
    if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df_view: df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
    if 'ìƒí’ˆíƒ€ì…' in df_view: df_view['ìƒí’ˆíƒ€ì…'] = map_series(df_view['ìƒí’ˆíƒ€ì…'], type_map)
    if 'ìƒí’ˆìƒì„¸' in df_view: df_view['ìƒí’ˆìƒì„¸'] = df_view['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)
    return df_raw, df_view

# ==============================================================
# === [L4 ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë”© ë¸”ë¡] ===
# (ìˆœì„œ ë¬¸ì œ í•´ê²°: 'ì •ì˜'ë¥¼ 'í˜¸ì¶œ'ë³´ë‹¤ ì•ìœ¼ë¡œ ì´ë™)
# ==============================================================

# --- 1. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 1: Inventory) ---
@st.cache_data(ttl=60)
def load_inventory_df() -> pd.DataFrame:
    inv_docs = db.collection(INVENTORY_COLLECTION).stream()
    rows = []
    for d in inv_docs:
        doc = d.to_dict() or {}
        en = doc.get("ìƒí’ˆìƒì„¸_en", d.id)
        ko = to_korean_detail(en)
        
        # [L4] ì›ê°€ ì •ë³´ ë¡œë“œ
        cost_unit_size = safe_float(doc.get("cost_unit_size", 1.0), 1.0)
        cost_per_unit = safe_float(doc.get("cost_per_unit", 0.0), 0.0)
        
        # 1g/1ml/1eaë‹¹ ì›ê°€ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        unit_cost = cost_per_unit / cost_unit_size if cost_unit_size > 0 else 0.0
        
        rows.append({
            "ìƒí’ˆìƒì„¸_en": en,
            "ìƒí’ˆìƒì„¸": ko,
            "ì´ˆê¸°ì¬ê³ ": doc.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "í˜„ì¬ì¬ê³ ": doc.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "uom": normalize_uom(doc.get("uom", "ea")),
            "is_ingredient": bool(doc.get("is_ingredient", False)),
            
            # [L4] ì›ê°€ ì»¬ëŸ¼ ì¶”ê°€
            "cost_unit_size": cost_unit_size, # ë§¤ì… ë‹¨ìœ„ (e.g., 1000)
            "cost_per_unit": cost_per_unit,  # ë§¤ì…ê°€ (e.g., 30000)
            "unit_cost": unit_cost           # 1g/ml/eaë‹¹ ì›ê°€ (e.g., 30)
        })
    
    # === [ë¹ˆí‹ˆ ìˆ˜ì •] inventoryê°€ ë¹„ì–´ìˆì–´ë„ ì»¬ëŸ¼ì€ ìœ ì§€ ===
    df = pd.DataFrame(rows, columns=[
        "ìƒí’ˆìƒì„¸_en", "ìƒí’ˆìƒì„¸", "ì´ˆê¸°ì¬ê³ ", "í˜„ì¬ì¬ê³ ", "uom", "is_ingredient",
        "cost_unit_size", "cost_per_unit", "unit_cost" # [L4]
    ])
    return df

# --- 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 2: SKU Params) ---
@st.cache_data(ttl=60)
def load_sku_params() -> pd.DataFrame:
    try:
        docs = db.collection(SKU_PARAMS_COLLECTION).stream()
    except Exception:
        docs = []
    rows = []
    for d in docs:
        item = d.to_dict() or {}
        try:
            item["_id"] = d.id
        except Exception:
            item["_id"] = item.get("_id", "")
        rows.append(item)
    dfp = pd.DataFrame(rows)
    if dfp.empty:
        dfp = pd.DataFrame(columns=[
            "_id","sku_en","lead_time_days","safety_stock_units","target_days","grams_per_cup","expiry_days"
        ])
    defaults = {
        "lead_time_days": 3,
        "safety_stock_units": 10,
        "target_days": 21,
        "grams_per_cup": 18.0,
        "expiry_days": 28,
    }
    for col, default in defaults.items():
        if col not in dfp.columns:
            dfp[col] = default
        else:
            dfp[col] = pd.to_numeric(dfp[col], errors="coerce").fillna(default)
    return dfp

# --- 3. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 3: Ensure Inventory Doc) ---
def ensure_inventory_doc(product_detail_en: str, uom: str = "ea", is_ingredient: bool = False):
    ref = db.collection(INVENTORY_COLLECTION).document(product_detail_en)
    snap = ref.get()
    if snap.exists:
        data = snap.to_dict() or {}
        patch = {}
        if normalize_uom(data.get("uom")) != normalize_uom(uom):
            patch["uom"] = normalize_uom(uom)
        if bool(data.get("is_ingredient", False)) != bool(is_ingredient):
            patch["is_ingredient"] = bool(is_ingredient)
        if patch:
            ref.update(patch)
        return ref
    else:
        ref.set({
            "ìƒí’ˆìƒì„¸_en": product_detail_en,
            "ì´ˆê¸°ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "í˜„ì¬ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "uom": normalize_uom(uom),
            "is_ingredient": bool(is_ingredient),
            # [L4] ì›ê°€ ê¸°ë³¸ê°’
            "cost_unit_size": 1.0,
            "cost_per_unit": 0.0,
            "unit_cost": 0.0,
        })
        return ref

def ensure_ingredient_sku(ingredient_en: str, uom: str = "ea"):
    return ensure_inventory_doc(ingredient_en, uom=uom, is_ingredient=True)


# --- 4. ë©”ì¸ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (í˜¸ì¶œ 1) ---
@st.cache_data(ttl=60)
def load_all_core_data():
    """
    [L4 ìˆ˜ì •] ì•± ì‹¤í–‰ ì‹œ ëª¨ë“  í•µì‹¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    (ì´ì œ ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ì–´ë„, í•„ìš”í•œ í•¨ìˆ˜ë“¤ì´ 'ìœ„ì—' ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.)
    """
    # 1. Sales (df)
    df = pd.concat([df_csv, df_fb], ignore_index=True)
    if 'ìš”ì¼' in df.columns:
        df['ìš”ì¼'] = map_series(df['ìš”ì¼'], weekday_map)
    if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df.columns:
        df['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
    if 'ìƒí’ˆíƒ€ì…' in df.columns:
        df['ìƒí’ˆíƒ€ì…'] = map_series(df['ìƒí’ˆíƒ€ì…'], type_map)
    if 'ìƒí’ˆìƒì„¸' in df.columns:
        df['ìƒí’ˆìƒì„¸'] = df['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)
    
    # 2. Inventory (df_inv) - [L4] ì›ê°€ ê³„ì‚°ì´ í¬í•¨ëœ í•¨ìˆ˜ë¡œ í˜¸ì¶œ
    df_inv = load_inventory_df() 
    
    # 3. Recipes (recipes)
    recipes = {}
    try:
        recipe_docs = db.collection(RECIPES_COLLECTION).stream()
        for d in recipe_docs:
            data = d.to_dict()
            if data and "ingredients" in data:
                recipes[d.id] = data["ingredients"]
    except Exception as e:
        st.error(f"ë ˆì‹œí”¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
    # 4. Params (df_params)
    df_params = load_sku_params()
    
    return df, df_inv, recipes, df_params

# --- 5. ë©”ì¸ ë°ì´í„° ë¡œë“œ 'ì‹¤í–‰' ---
try:
    #data_load_state = st.info("ëª¨ë“  í•µì‹¬ ë°ì´í„°(íŒë§¤, ì¬ê³ , ë ˆì‹œí”¼) ë¡œë“œ ì¤‘... â³")
    df, df_inv, RECIPES, df_params = load_all_core_data()
    #data_load_state.success("âœ… ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
except Exception as e:
    #data_load_state.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()
    

# --- 6. ì›ê°€(COGS) ê³„ì‚° í•¨ìˆ˜ (ì •ì˜ 4) ---
@st.cache_data(ttl=600)
def calculate_menu_cogs(df_inv: pd.DataFrame, recipes: dict) -> dict:
    """
    (L4) 'df_inv'ì˜ 'unit_cost'ì™€ 'recipes'ë¥¼ ì‚¬ìš©í•´
    ëª¨ë“  ë©”ë‰´ì˜ COGS(ë§¤ì¶œ ì›ê°€)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    if 'unit_cost' not in df_inv.columns:
        st.error("calculate_menu_cogs: df_invì— 'unit_cost' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {}
        
    # 1. ì¬ë£Œ ì›ê°€ ë§µ ìƒì„± (sku_en -> unit_cost)
    ingredient_costs = df_inv[df_inv['is_ingredient'] == True].set_index('ìƒí’ˆìƒì„¸_en')['unit_cost'].to_dict()
    
    menu_cogs = {}
    
    # 2. ëª¨ë“  ë ˆì‹œí”¼ë¥¼ ìˆœíšŒí•˜ë©° ì›ê°€ ê³„ì‚°
    for menu_sku_en, ingredients in recipes.items():
        total_cogs = 0.0
        for item in ingredients:
            ing_sku_en = item["ingredient_en"]
            qty = safe_float(item.get("qty", 0.0))
            waste_pct = safe_float(item.get("waste_pct", 0.0))
            
            # 3. ì¬ë£Œ ì›ê°€ ê°€ì ¸ì˜¤ê¸°
            unit_cost = safe_float(ingredient_costs.get(ing_sku_en, 0.0))
            
            # 4. ì†ì‹¤ë¥ (waste_pct)ì„ ì›ê°€ì— ë°˜ì˜
            cost_with_waste = unit_cost * (1 + (waste_pct / 100.0))
            
            # 5. ì´ ì¬ë£Œì˜ ì´ ì›ê°€ = (ì›ê°€ * ìˆ˜ëŸ‰)
            total_cogs += (cost_with_waste * qty)
        
        menu_cogs[menu_sku_en] = total_cogs
        
    return menu_cogs

# --- 7. ì›ê°€(COGS) 'ì‹¤í–‰' ë° 'df'ì— í†µí•© ---
try:
    #cogs_load_state = st.info("ë©”ë‰´ë³„ ì›ê°€(COGS) ë° ë§ˆì§„ ê³„ì‚° ì¤‘... ğŸ’°")
    
    # 1. ë©”ë‰´ë³„ COGS ë”•ì…”ë„ˆë¦¬ ìƒì„± (e.g., {'Americano': 600.0})
    menu_cogs_map = calculate_menu_cogs(df_inv, RECIPES)
    
    # 2. 'ìƒí’ˆìƒì„¸'(í•œê¸€) <-> 'menu_sku_en' ë§µ ìƒì„±
    cogs_map_kr = {to_korean_detail(sku_en): cogs for sku_en, cogs in menu_cogs_map.items()}

    # 3. 'df'ì— 'ì›ê°€' ì»¬ëŸ¼ ì¶”ê°€
    df['ì›ê°€'] = df['ìƒí’ˆìƒì„¸'].map(cogs_map_kr).fillna(0.0)
    
    # 4. 'ìˆœì´ìµ' ë° 'ë§ˆì§„ìœ¨' ê³„ì‚°
    df['ìˆ˜ìµ'] = pd.to_numeric(df['ìˆ˜ìµ'], errors='coerce').fillna(0)
    df['ìˆœì´ìµ'] = df['ìˆ˜ìµ'] - df['ì›ê°€']
    df['ë§ˆì§„ìœ¨(%)'] = (df['ìˆœì´ìµ'] / df['ìˆ˜ìµ']).replace([pd.NA, float('inf'), float('-inf')], 0).fillna(0) * 100
    
    #cogs_load_state.success("âœ… ì›ê°€ ë° ë§ˆì§„ ê³„ì‚° ì™„ë£Œ!")

except Exception as e:
    #cogs_load_state.error(f"ì›ê°€ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
    # ì›ê°€ ì—†ì´ë„ ì•±ì€ ê³„ì† ì‘ë™í•´ì•¼ í•¨
    df['ì›ê°€'] = 0.0
    df['ìˆ˜ìµ'] = pd.to_numeric(df['ìˆ˜ìµ'], errors='coerce').fillna(0)
    df['ìˆœì´ìµ'] = df['ìˆ˜ìµ']
    df['ë§ˆì§„ìœ¨(%)'] = 0.0

# --- 8. 'load_recipe' (L4) í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---
@st.cache_data(ttl=60)
def load_recipe(menu_sku_en: str) -> list[dict]:
    """[L4 ìˆ˜ì •] DBë¥¼ ë§¤ë²ˆ ì¡°íšŒí•˜ëŠ” ëŒ€ì‹ , ì „ì—­ 'RECIPES' ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©"""
    global RECIPES
    return RECIPES.get(menu_sku_en, [])

# --- 9. (ê¸°ì¡´ í•¨ìˆ˜) ì¬ê³  ì°¨ê° í•¨ìˆ˜ë“¤ (ìˆœì„œ ë³€ê²½) ---
def deduct_stock(product_detail_en: str, qty: int):
    ref = ensure_inventory_doc(product_detail_en)
    snap = ref.get()
    data = snap.to_dict() if snap.exists else {}
    init_stock = int(data.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    cur_stock = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    new_stock = max(cur_stock - int(qty), 0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return init_stock, new_stock

def get_all_recipe_ingredients() -> set:
    ingredients = set()
    try:
        docs = db.collection(RECIPES_COLLECTION).stream()
        for d in docs:
            items = (d.to_dict() or {}).get("ingredients", [])
            for it in items:
                ingredients.add(it["ingredient_en"])
    except Exception:
        pass
    return ingredients

def deduct_inventory(ingredient_en: str, qty: float, uom: str):
    ref = ensure_inventory_doc(ingredient_en, uom=uom)
    snap = ref.get()
    data = snap.to_dict() or {}
    cur = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    inv_uom = normalize_uom(data.get("uom", "ea"))
    use_qty = convert_qty(qty, from_uom=uom, to_uom=inv_uom)
    new_stock = max(cur - use_qty, 0.0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return cur, new_stock, inv_uom

def apply_recipe_deduction(menu_sku_en: str, sold_qty: int, commit: bool = True) -> list[dict]:
    items = load_recipe(menu_sku_en)
    summary: list[dict] = []
    if not items:
        ref = ensure_inventory_doc(menu_sku_en, uom="ea")
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used = float(sold_qty)
        after = max(before - used, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": menu_sku_en, "used": used, "uom": inv_uom, "before": before, "after": after})
        return summary
    for it in items:
        ing = it["ingredient_en"]
        uom = normalize_uom(it["uom"])
        qty_per_unit = safe_float(it["qty"])
        waste_pct = safe_float(it["waste_pct"], 0)
        total_used = (qty_per_unit * sold_qty) * (1 + (waste_pct / 100.0))
        ref = ensure_inventory_doc(ing, uom=uom, is_ingredient=True)
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used_converted = convert_qty(total_used, from_uom=uom, to_uom=inv_uom)
        after = max(before - used_converted, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": ing, "used": used_converted, "uom": inv_uom, "before": before, "after": after})
    return summary

def adjust_inventory_by_recipe(menu_sku_en: str,
                               qty_diff: int,
                               move_type: str = "manual_adjust",
                               note: str = ""):
    if qty_diff == 0:
        return
    details = apply_recipe_deduction(menu_sku_en, qty_diff, commit=True)
    log_doc = {
        "ts": datetime.now().isoformat(),
        "type": move_type,
        "menu_sku_en": menu_sku_en,
        "qty": qty_diff,
        "note": note,
        "details": details,
    }
    db.collection(STOCK_MOVES_COLLECTION).add(log_doc)

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í˜¸ì¶œ í—¬í¼
def call_openai_api(user_prompt: str, data_context: str, model="gpt-3.5-turbo"):
    """
    [AI ìˆ˜ì • 2] data_context(ì‚¬ì‹¤)ì™€ user_prompt(ìš”ì²­)ë¥¼ ë¶„ë¦¬í•˜ì—¬ AIê°€ 'ê±°ì§“ë§'ì„ í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì •.
    data_contextëŠ” 'system' ë©”ì‹œì§€ë¡œ, user_promptëŠ” 'user' ë©”ì‹œì§€ë¡œ ì „ë‹¬.
    """
    
    # 1. API í‚¤ê°€ ì—†ëŠ” ê²½ìš°
    if not openai.api_key:
        time.sleep(1.5) 
        st.error("OpenAI API í‚¤ê°€ 'secrets.toml'ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return (f"âš ï¸ **[AI ì‘ë‹µ ì‹¤íŒ¨ (API í‚¤ ì—†ìŒ)]**\n\n"
                f"'secrets.toml'ì— OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
                f"--- (ë°ì´í„° ì»¨í…ìŠ¤íŠ¸) ---\n{data_context}\n\n"
                f"--- (ì‚¬ìš©ì ìš”ì²­) ---\n{user_prompt}")

    # 2. API í˜¸ì¶œ ì‹œë„
    try:
        # [ìˆ˜ì •] ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëª…í™•íˆ ë¶„ë¦¬
        response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": (
                    "ë‹¹ì‹ ì€ ì¹´í˜ ìš´ì˜ ë° ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                    "ë‹¤ìŒì€ í˜„ì¬ ì¹´í˜ì˜ ì‹¤ì œ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ 'ì‚¬ì‹¤'ë¡œ ê°„ì£¼í•˜ê³ , "
                    "ì´ 'ì‚¬ì‹¤'ì— ê¸°ë°˜í•´ì„œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì ˆëŒ€ ë°ì´í„°ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.\n\n"
                    f"--- [ì¹´í˜ ì‹¤ì œ ë°ì´í„°] ---\n{data_context}\n--- [ë°ì´í„° ë] ---"
                )},
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.choices[0].message.content
        
    # 3. [ìˆ˜ì •] ì”ì•¡ ë¶€ì¡± ë˜ëŠ” API ì˜¤ë¥˜ ë°œìƒ ì‹œ
    except openai.InsufficientQuotaError as e:
        # "ê°€ì§œ ì‘ë‹µ"ì´ ì•„ë‹Œ, ëª…í™•í•œ 'ì˜¤ë¥˜'ì™€ 'ì‹œë„í–ˆë˜ ë‚´ìš©'ì„ ë°˜í™˜
        st.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: ì”ì•¡(Quota)ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì˜¤ë¥˜: {e.message})")
        return (f"âš ï¸ **[AI ì‘ë‹µ ì‹¤íŒ¨ (ì”ì•¡ ë¶€ì¡±)]**\n\n"
                f"OpenAI ê³„ì •ì˜ ì”ì•¡ì´ ë¶€ì¡±í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"--- (AIê°€ ì „ë‹¬ë°›ì€ ë°ì´í„°) ---\n{data_context}\n\n"
                f"--- (AIê°€ ìš”ì²­ë°›ì€ ì‘ì—…) ---\n{user_prompt}")
        
    except openai.AuthenticationError as e:
        st.error("âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: API í‚¤ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. 'secrets.toml'ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# SPRINT 2: Prophet ìˆ˜ìš” ì˜ˆì¸¡ í—¬í¼
@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
# SPRINT 2: Prophet ìˆ˜ìš” ì˜ˆì¸¡ í—¬í¼
@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
def get_item_forecast(df_all_sales: pd.DataFrame, menu_sku_en: str, days_to_forecast: int):
    """Prophetì„ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ë©”ë‰´ì˜ ë¯¸ë˜ íŒë§¤ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    
    try:
        # === [ìˆ˜ì •] ë‚ ì§œ ë°ì´í„° ì•ˆì •í™” ===
        df_all_sales = df_all_sales.copy()
        df_all_sales['ë‚ ì§œ'] = pd.to_datetime(df_all_sales['ë‚ ì§œ'], errors='coerce')
        df_all_sales = df_all_sales.dropna(subset=['ë‚ ì§œ'])
        # === [ìˆ˜ì • ë] ===

        # === [ë²„ê·¸ ìˆ˜ì •] ì´ë¦„ ë¶ˆì¼ì¹˜ í•´ê²° ===
        base_sku_en = re.sub(r"\s+(Lg|Rg|Sm)$", "", menu_sku_en.strip())
        menu_name_kr_base = to_korean_detail(base_sku_en) # This should now be 'ì•„ë©”ë¦¬ì¹´ë…¸'
        
        original_menu_name_kr = to_korean_detail(menu_sku_en)
        if original_menu_name_kr != menu_name_kr_base:
            st.info(f"AI ì˜ˆì¸¡: '{original_menu_name_kr}' ë©”ë‰´ì˜ ì˜ˆì¸¡ì„ ìœ„í•´, íŒë§¤ ë°ì´í„°ì—ì„œ '{menu_name_kr_base}'(ìœ¼)ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.")
        # === [ë²„ê·¸ ìˆ˜ì • ë] ===

        df_item = df_all_sales[
            df_all_sales['ìƒí’ˆìƒì„¸'] == menu_name_kr_base
        ].copy()
        
        if df_item.empty:
            st.warning(f"íŒë§¤ ë°ì´í„°(df)ì—ì„œ '{menu_name_kr_base}' ì´ë¦„ì˜ íŒë§¤ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„° 0ê±´)")
            return None, None # íŒë§¤ ë°ì´í„° ì—†ìŒ

        # Prophetì´ ë‚ ì§œ ë°ì´í„°ë¥¼ ì‹ ë¢°í•˜ë„ë¡ ì „ì²˜ë¦¬
        df_agg = df_item.groupby('ë‚ ì§œ')['ìˆ˜ëŸ‰'].sum().reset_index()
        df_agg['ë‚ ì§œ'] = pd.to_datetime(df_agg['ë‚ ì§œ'])
        
        if not df_agg.empty:
            date_range = pd.date_range(start=df_agg['ë‚ ì§œ'].min(), end=df_agg['ë‚ ì§œ'].max())
            df_agg = df_agg.set_index('ë‚ ì§œ').reindex(date_range, fill_value=0).reset_index()
            df_agg.rename(columns={'index': 'ë‚ ì§œ'}, inplace=True)
        
        df_prophet = df_agg[['ë‚ ì§œ', 'ìˆ˜ëŸ‰']].rename(columns={"ë‚ ì§œ": "ds", "ìˆ˜ëŸ‰": "y"})

        if len(df_prophet) < 7: # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜ˆì¸¡ ë¶ˆê°€
            return None, None

        m = Prophet(weekly_seasonality=True, yearly_seasonality=False, daily_seasonality=False)
        m.fit(df_prophet)
        
        # [ìˆ˜ì •] freq='D'ë¥¼ ì¶”ê°€í•˜ì—¬ 'ì¼(Daily)' ë‹¨ìœ„ ì˜ˆì¸¡ì„ì„ ëª…ì‹œ
        future = m.make_future_dataframe(periods=days_to_forecast, freq='D')
        forecast = m.predict(future)
        
        # === [ë¹ˆí‹ˆ ìˆ˜ì •] 'y' ì»¬ëŸ¼ì´ ë¹ ì§€ëŠ” ì˜¤ë¥˜ ìˆ˜ì • ===
        forecast_chart_data = forecast.merge(df_prophet, on='ds', how='left')
        
        # ìŒìˆ˜ ì˜ˆì¸¡ì€ 0ìœ¼ë¡œ
        forecast_chart_data['yhat'] = forecast_chart_data['yhat'].clip(lower=0) 
        
        # ì˜ˆì¸¡ëœ ê¸°ê°„(target_days)ì˜ ì´ ì†Œì§„ëŸ‰ í•©ê³„ ë°˜í™˜
        predicted_sum = forecast_chart_data.iloc[-days_to_forecast:]['yhat'].sum()
        
        return max(predicted_sum, 0), forecast_chart_data 

    except Exception as e:
        st.warning(f"Prophet ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None
# === [AI/ML í†µí•© ì¶”ê°€] ===

# ----------
# [AI/ML í†µí•© ìˆ˜ì • 6] 
# ( compute_ingredient_metrics_for_menu )
# SPRINT 2: ML ìˆ˜ìš” ì˜ˆì¸¡ ë¡œì§ ìˆ˜ì •
# - [ë¹ˆí‹ˆ ìˆ˜ì •] "ì „ì²´ ê±°ë˜ ë‚´ì—­"ì´ ê·¸ë˜í”„ì— ë°˜ì˜ë˜ë„ë¡ .iloc[-90:] ì‚­ì œ
# - [ê¸°ëŠ¥ ì¶”ê°€] 'ì‹¤ì œ íŒë§¤ëŸ‰(y)'ê³¼ 'AI ì˜ˆì¸¡(yhat)'ì„ ê·¸ë˜í”„ì— ë™ì‹œ í‘œì‹œ
# ----------
def compute_ingredient_metrics_for_menu(
    menu_sku_en: str,
    df_all_sales: pd.DataFrame, # ì „ì²´ íŒë§¤ ë°ì´í„°(df)
    df_inv: pd.DataFrame,
    df_params: pd.DataFrame,
    window_days: int = 28 # [ìˆ˜ì •] ì´ ê°’ì€ ì´ì œ AI ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©ë¨
) -> pd.DataFrame:
    """
    [AI ìˆ˜ì •ë¨] íŠ¹ì • ë©”ë‰´ì˜ ë ˆì‹œí”¼ì™€ *ë¯¸ë˜ ì˜ˆì¸¡ íŒë§¤ëŸ‰* ê¸°ë°˜ìœ¼ë¡œ ì¬ë£Œë³„ ì§€í‘œ ê³„ì‚°.
    ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ ê³¼ê±° ìœˆë„ìš°(window_days) í‰ê· ìœ¼ë¡œ ëŒ€ì²´.
    """
    items = load_recipe(menu_sku_en)
    if not items:
        return pd.DataFrame()

    # === [ë²„ê·¸ ìˆ˜ì •] ì´ë¦„ ë¶ˆì¼ì¹˜ í•´ê²° (Historical) ===
    base_sku_en = re.sub(r"\s+(Lg|Rg|Sm)$", "", menu_sku_en.strip())
    menu_name_kr_base = to_korean_detail(base_sku_en) # 'ì•„ë©”ë¦¬ì¹´ë…¸'
    # === [ë²„ê·¸ ìˆ˜ì • ë] ===

    # === [ìˆ˜ì •] ì˜ˆì¸¡ ê¸°ê°„ì„ 21ì¼ë¡œ ê³ ì •í•˜ì—¬ ë²„ê·¸ í•´ê²° ===
    target_days_forecast = 21
    window_days_fallback = 21 # AI ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„ë„ 21ì¼ë¡œ í†µì¼
    st.info(f"ğŸ¤– AI ìˆ˜ìš” ì˜ˆì¸¡ì„ í–¥í›„ **{target_days_forecast}ì¼** ê¸°ì¤€ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    # === [ìˆ˜ì • ë] ===

    # 1. (Fallbackìš©) ê³¼ê±° ìœˆë„ìš° íŒë§¤ëŸ‰ ì§‘ê³„
    sold_sum_historical = 0.0
    if "ë‚ ì§œ" in df_all_sales.columns and pd.api.types.is_datetime64_any_dtype(df_all_sales["ë‚ ì§œ"]):
        max_day = df_all_sales["ë‚ ì§œ"].max()
        min_day = max_day - pd.Timedelta(days=window_days_fallback - 1)
        df_win = df_all_sales[(df_all_sales["ë‚ ì§œ"] >= min_day) & (df_all_sales["ë‚ ì§œ"] <= max_day)]
        sold_sum_historical = df_win[df_win['ìƒí’ˆìƒì„¸'] == menu_name_kr_base]['ìˆ˜ëŸ‰'].sum()
    
    # 2. [AI/ML] ë¯¸ë˜ ìˆ˜ìš” ì˜ˆì¸¡
    predicted_menu_sales, forecast_chart_data = get_item_forecast(
        df_all_sales, menu_sku_en, days_to_forecast=target_days_forecast
    )

    # 3. ì‚¬ìš©í•  íŒë§¤ëŸ‰(sold_sum) ë° ê¸°ì¤€ì¼(days) ê²°ì •
    use_historical_fallback = False
    
    if predicted_menu_sales is None or predicted_menu_sales == 0:
        st.warning(f"ğŸ¤– AI ì˜ˆì¸¡: '{to_korean_detail(menu_sku_en)}'ì˜ íŒë§¤ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ê³¼ê±° {window_days_fallback}ì¼ íŒë§¤ëŸ‰: {sold_sum_historical}ê°œ)ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        sold_sum = sold_sum_historical # ê³¼ê±° ë°ì´í„° ì‚¬ìš©
        days = window_days_fallback
        use_historical_fallback = True
    else:
        st.success(f"ğŸ¤– **AI ì˜ˆì¸¡**: '{to_korean_detail(menu_sku_en)}'ì˜ í–¥í›„ **{target_days_forecast}ì¼ê°„** ì˜ˆìƒ íŒë§¤ëŸ‰ì„ **{predicted_menu_sales:,.0f}ê°œ**ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.")
        sold_sum = predicted_menu_sales # ì˜ˆì¸¡ê°’ìœ¼ë¡œ ëŒ€ì²´
        days = target_days_forecast # ê¸°ì¤€ì¼ë„ ì˜ˆì¸¡ ê¸°ê°„ìœ¼ë¡œ ë³€ê²½
        
        # [ë³µì›] 'ì˜ˆì „ ê·¸ë˜í”„' ë¡œì§ì„ ì—¬ê¸°ì— ë‹¤ì‹œ ì¶”ê°€í•©ë‹ˆë‹¤.
        if forecast_chart_data is not None:
            try:
                fig = px.line(forecast_chart_data, x='ds', y='yhat', 
                                title=f"'{to_korean_detail(menu_sku_en)}' ì „ì²´ ê¸°ê°„ ìˆ˜ìš” ì˜ˆì¸¡", 
                                labels={'ds':'ë‚ ì§œ', 'yhat':'ì˜ˆì¸¡ íŒë§¤ëŸ‰'})
                
                actual_data = forecast_chart_data.dropna(subset=['y'])
                fig.add_scatter(x=actual_data['ds'], y=actual_data['y'], 
                                mode='markers', 
                                name='ì‹¤ì œ íŒë§¤ëŸ‰', 
                                marker=dict(color='rgba(0,0,255,0.5)', size=5))
                
                fig.add_scatter(x=forecast_chart_data['ds'], y=forecast_chart_data['yhat_lower'], fill='tozeroy', mode='lines', line=dict(color='rgba(0,0,0,0)'), name='ë¶ˆí™•ì‹¤ì„±(í•˜í•œ)')
                fig.add_scatter(x=forecast_chart_data['ds'], y=forecast_chart_data['yhat_upper'], fill='tonexty', mode='lines', line=dict(color='rgba(0,0,0,0)'), fillcolor='rgba(231, 234, 241, 0.5)', name='ë¶ˆí™•ì‹¤ì„±(ìƒí•œ)')
                
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

    # 4. ë ˆì‹œí”¼ ê¸°ë°˜ ì›ì¬ë£Œ ì†Œì§„ëŸ‰ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ í™œìš©)
    rows = []
    for item in items:
        # ... (ì´í•˜ ëª¨ë“  ê³„ì‚° ë¡œì§ì€ ì›ë³¸ê³¼ ë™ì¼) ...
        sku_en = item["ingredient_en"]
        qty_per_unit = safe_float(item.get("qty", 0.0))
        uom = normalize_uom(item.get("uom", "ea"))
        waste_pct = safe_float(item.get("waste_pct", 0.0))
        
        total_used = (qty_per_unit * sold_sum) * (1 + (waste_pct / 100.0))
        
        rows.append({
            "sku_en": sku_en,
            "uom_recipe": uom,
            "total_consumption": total_used
        })

    if not rows:
        return pd.DataFrame()
    
    use_df = pd.DataFrame(rows).groupby("sku_en").agg({
        "total_consumption": "sum",
        "uom_recipe": "first" 
    }).reset_index()
    
    base = use_df.rename(columns={"total_consumption": "ìµœê·¼ì†Œì§„í•©"})

    # 5. ì¬ê³  ì§€í‘œ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ í™œìš©)
    base["ì¼í‰ê· ì†Œì§„"] = (base["ìµœê·¼ì†Œì§„í•©"] / max(days, 1)).round(3)
    base.loc[base["ì¼í‰ê· ì†Œì§„"].eq(0), "ì¼í‰ê· ì†Œì§„"] = 0.01

    base = base.merge(df_inv[['ìƒí’ˆìƒì„¸_en', 'í˜„ì¬ì¬ê³ ', 'ì´ˆê¸°ì¬ê³ ', 'uom']], left_on='sku_en', right_on='ìƒí’ˆìƒì„¸_en', how='left')
    base['í˜„ì¬ì¬ê³ '] = base['í˜„ì¬ì¬ê³ '].fillna(0)
    base['ì´ˆê¸°ì¬ê³ '] = base['ì´ˆê¸°ì¬ê³ '].fillna(DEFAULT_INITIAL_STOCK)
    base['uom'] = base['uom'].fillna('ea').apply(normalize_uom)

    base["ì»¤ë²„ì¼ìˆ˜"] = (base["í˜„ì¬ì¬ê³ "] / base["ì¼í‰ê· ì†Œì§„"]).round(1)

    # 6. ROP ë° ê¶Œì¥ ë°œì£¼ëŸ‰ ê³„ì‚°
    base = base.merge(df_params, on="sku_en", how="left")
    
    base['lead_time_days'] = base['lead_time_days'].fillna(3)
    base['safety_stock_units'] = base['safety_stock_units'].fillna(0)
    base['target_days'] = base['target_days'].fillna(21)

    base["ROP"] = (base["ì¼í‰ê· ì†Œì§„"] * base["lead_time_days"] + base["safety_stock_units"]).round(0).astype(int)
    base["ê¶Œì¥ë°œì£¼"] = (base["ìµœê·¼ì†Œì§„í•©"] - base["í˜„ì¬ì¬ê³ "]).apply(lambda x: max(int(ceil(x)), 0))
    base["ìƒíƒœ"] = base.apply(lambda r: "ğŸš¨ ë°œì£¼ìš”ë§" if r["í˜„ì¬ì¬ê³ "] <= r["ROP"] else "âœ… ì •ìƒ", axis=1)

    base["ìƒí’ˆìƒì„¸"] = base["sku_en"].apply(to_korean_detail)
    cols = ["ìƒí’ˆìƒì„¸","sku_en","í˜„ì¬ì¬ê³ ","ì´ˆê¸°ì¬ê³ ","uom","ìµœê·¼ì†Œì§„í•©","ì¼í‰ê· ì†Œì§„","ì»¤ë²„ì¼ìˆ˜",
            "lead_time_days","safety_stock_units","target_days","ROP","ê¶Œì¥ë°œì£¼","ìƒíƒœ"]
    for c in cols:
        if c not in base.columns:
            base[c] = None
            
    return base[cols].sort_values(["ìƒíƒœ","ì»¤ë²„ì¼ìˆ˜"])

# =============================================================
# === [AI/ML ì—…ê·¸ë ˆì´ë“œ] í”„ë¡œì•¡í‹°ë¸Œ ë¶„ì„ í•¨ìˆ˜ (L3 + L4) ===
# =============================================================

@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
def find_inventory_risks(df, df_inv, df_params):
    """(AI ë ˆë²¨ 3) AI ì˜ˆì¸¡ ê¸°ë°˜, ì¬ê³  ìœ„í—˜ í’ˆëª© ìƒìœ„ 3ê°œ ì°¾ê¸°"""
    try:
        # 1. ë ˆì‹œí”¼ê°€ ìˆëŠ” ë©”ë‰´ë§Œ
        # [L4] ì „ì—­ RECIPES ì‚¬ìš©
        menu_list_en = list(RECIPES.keys())
        if not menu_list_en:
            return "ë ˆì‹œí”¼ê°€ ë“±ë¡ë˜ì§€ ì•Šì•„ ì¬ê³  ìœ„í—˜ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        all_risks = []
        
        for menu_sku_en in menu_list_en:
            # 2. ëª¨ë“  ë©”ë‰´ì— ëŒ€í•´ 'AI ì˜ˆì¸¡' ë° 'ì¬ê³  ê³„ì‚°' ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
            report_df = compute_ingredient_metrics_for_menu(
                menu_sku_en, df, df_inv, df_params, window_days=21
            )
            
            # 3. 'ë°œì£¼ìš”ë§' ìƒíƒœì¸ ì¬ë£Œ í•„í„°ë§
            risk_items = report_df[report_df['ìƒíƒœ'] == 'ğŸš¨ ë°œì£¼ìš”ë§']
            
            if not risk_items.empty:
                for _, row in risk_items.iterrows():
                    all_risks.append(
                        f"- '{row['ìƒí’ˆìƒì„¸']}' (ë©”ë‰´ '{to_korean_detail(menu_sku_en)}'ìš©): "
                        f"í˜„ì¬ ì¬ê³  {row['í˜„ì¬ì¬ê³ ']}{row['uom']}, "
                        f"AI ì˜ˆì¸¡ ê¸°ë°˜ ê¶Œì¥ ë°œì£¼ëŸ‰ {row['ê¶Œì¥ë°œì£¼']}{row['uom']}. (ì»¤ë²„ì¼ìˆ˜: {row['ì»¤ë²„ì¼ìˆ˜']}ì¼)"
                    )
                    
        if not all_risks:
            return "AI ì˜ˆì¸¡ ê²°ê³¼, í˜„ì¬ ì¬ê³ ê°€ ì¶©ë¶„í•©ë‹ˆë‹¤. (ìœ„í—˜ 0ê±´)"
        
        # ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
        return "\n".join(list(set(all_risks))[:3])

    except Exception as e:
        return f"ì¬ê³  ìœ„í—˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_slow_moving_items(df, df_inv):
    """(AI ë ˆë²¨ 3) ì•…ì„± ì¬ê³  (30ì¼ê°„ 5ê°œ ì´í•˜ íŒë§¤) ì°¾ê¸°"""
    try:
        # 1. 30ì¼ê°„ ë©”ë‰´ë³„ íŒë§¤ëŸ‰ ì§‘ê³„
        min_day = df["ë‚ ì§œ"].max() - pd.Timedelta(days=29)
        df_30d = df[df["ë‚ ì§œ"] >= min_day]
        sales_counts = df_30d.groupby('ìƒí’ˆìƒì„¸')['ìˆ˜ëŸ‰'].sum()
        
        # 2. 30ì¼ê°„ 5ê°œ ì´í•˜ë¡œ íŒ”ë¦° 'ë¹„ì¸ê¸° ë©”ë‰´'
        slow_menus_kr = sales_counts[sales_counts <= 5].index.tolist()
        if not slow_menus_kr:
            return "ì§€ë‚œ 30ì¼ê°„ íŒë§¤ê°€ ë¶€ì§„í•œ ë©”ë‰´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # 3. ë¹„ì¸ê¸° ë©”ë‰´ì˜ ë ˆì‹œí”¼ -> ì¬ë£Œ ì°¾ê¸°
        slow_ingredients = set()
        for menu_kr in slow_menus_kr:
            menu_en = from_korean_detail(menu_kr)
            items = load_recipe(menu_en) # [L4] ì „ì—­ RECIPES ì‚¬ìš©
            for item in items:
                slow_ingredients.add(item['ingredient_en'])
        
        if not slow_ingredients:
            return "ì§€ë‚œ 30ì¼ê°„ íŒë§¤ê°€ ë¶€ì§„í•œ ë©”ë‰´ê°€ ìˆìœ¼ë‚˜, ë ˆì‹œí”¼ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
        # 4. í•´ë‹¹ ì¬ë£Œë“¤ì˜ í˜„ì¬ ì¬ê³  í™•ì¸
        df_ing_stock = df_inv[df_inv['ìƒí’ˆìƒì„¸_en'].isin(list(slow_ingredients))]
        df_ing_stock = df_ing_stock.sort_values('í˜„ì¬ì¬ê³ ', ascending=False)
        
        if df_ing_stock.empty:
            return "íŒë§¤ ë¶€ì§„ ë©”ë‰´ì™€ ì—°ê²°ëœ ì¬ë£Œ ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
            
        report = []
        for _, row in df_ing_stock.head(3).iterrows(): # ì¬ê³  ë§ì€ ìƒìœ„ 3ê°œ
            report.append(
                f"- '{row['ìƒí’ˆìƒì„¸']}' (ë¹„ì¸ê¸° ë©”ë‰´ìš© ì¬ë£Œ): "
                f"í˜„ì¬ ì¬ê³  {row['í˜„ì¬ì¬ê³ ']}{row['uom']}"
            )
        return "\n".join(report)

    except Exception as e:
        return f"ì•…ì„± ì¬ê³  ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_top_correlations(df):
    """(AI ë ˆë²¨ 3) í•¨ê»˜ ì˜ íŒ”ë¦¬ëŠ” ë©”ë‰´ (ìƒê´€ê´€ê³„) ì°¾ê¸°"""
    try:
        # 1. ë‚ ì§œ-ìƒí’ˆë³„ íŒë§¤ëŸ‰ í”¼ë²— í…Œì´ë¸” ìƒì„±
        df_pivot = df.pivot_table(
            index='ë‚ ì§œ', 
            columns='ìƒí’ˆìƒì„¸', 
            values='ìˆ˜ëŸ‰', 
            aggfunc='sum'
        ).fillna(0)
        
        # (ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 20ê°œë§Œ)
        top_20_items = df_pivot.sum().nlargest(20).index
        df_pivot = df_pivot[top_20_items]
        
        # 2. ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        corr_matrix = df_pivot.corr()
        
        # 3. ìê¸° ìì‹ (1.0)ì„ ì œì™¸í•œ ìƒìœ„ 3ê°œ íŒ¨í„´ ì°¾ê¸°
        corr_pairs = corr_matrix.unstack()
        corr_pairs = corr_pairs[corr_pairs < 1].sort_values(ascending=False)
        
        top_3 = corr_pairs.head(3)
        if top_3.empty:
            return "ìœ ì˜ë¯¸í•œ ë™ì‹œ íŒë§¤ íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        report = []
        for (item1, item2), corr_val in top_3.items():
            report.append(f"- '{item1}' + '{item2}' (ìƒê´€ê´€ê³„: {corr_val:.2f})")
        return "\n".join(report)
        
    except Exception as e:
        return f"íŒë§¤ íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_profit_insights(df_with_margin: pd.DataFrame):
    """(AI ë ˆë²¨ 4) 'ìˆœì´ìµ'ê³¼ 'ë§ˆì§„ìœ¨' ê¸°ë°˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
    
    if 'ìˆœì´ìµ' not in df_with_margin.columns or df_with_margin['ì›ê°€'].sum() == 0:
        return ("'ì›ê°€' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ì›ê°€ & ë ˆì‹œí”¼ í—ˆë¸Œ' íƒ­ì—ì„œ "
                "ë¨¼ì € 'ì¬ë£Œ ì›ê°€'ì™€ 'ë ˆì‹œí”¼'ë¥¼ ë“±ë¡í•´ì•¼ 'ìˆœì´ìµ' ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    try:
        # 1. ë©”ë‰´ë³„ ì§‘ê³„
        df_agg = df_with_margin.groupby('ìƒí’ˆìƒì„¸').agg(
            ì´íŒë§¤ìˆ˜ëŸ‰=('ìˆ˜ëŸ‰', 'sum'),
            ì´ë§¤ì¶œ=('ìˆ˜ìµ', 'sum'),
            ì´ìˆœì´ìµ=('ìˆœì´ìµ', 'sum')
        ).reset_index()
        
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] = (df_agg['ì´ìˆœì´ìµ'] / df_agg['ì´ë§¤ì¶œ']).replace([pd.NA, float('inf'), float('-inf')], 0).fillna(0) * 100
        
        # 2. íš¨ì ìƒí’ˆ (ìˆœì´ìµ ê¸°ì—¬ë„ Top 3)
        stars = df_agg.sort_values('ì´ìˆœì´ìµ', ascending=False).head(3)
        star_report = "\n".join([
            f"- '{row['ìƒí’ˆìƒì„¸']}' (ì´ ìˆœì´ìµ: {format_krw(row['ì´ìˆœì´ìµ'])}, ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
            for _, row in stars.iterrows()
        ])
        
        # 3. ìˆ˜ìµì„± í•¨ì • (ë§ˆì§„ìœ¨ í•˜ìœ„ 3ê°œ - ë‹¨, ì›ê°€ê°€ 0ì´ ì•„ë‹Œ ë©”ë‰´ ì¤‘)
        traps = df_agg[df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] > 0].sort_values('í‰ê· ë§ˆì§„ìœ¨(%)', ascending=True).head(3)
        trap_report = "\n".join([
            f"- '{row['ìƒí’ˆìƒì„¸']}' (ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
            for _, row in traps.iterrows()
        ])

        # 4. ì†ì‹¤ ìƒí’ˆ (ë§ˆì§„ìœ¨ì´ 0 ë˜ëŠ” ë§ˆì´ë„ˆìŠ¤)
        loss = df_agg[df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] <= 0]
        loss_report = "ì†ì‹¤ ë°œìƒ ë©”ë‰´ ì—†ìŒ."
        if not loss.empty:
            loss_report = "\n".join([
                f"- '{row['ìƒí’ˆìƒì„¸']}' (ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
                for _, row in loss.iterrows()
            ])

        return f"""
[íš¨ì ìƒí’ˆ (ìˆœì´ìµ Top 3)]
{star_report}

[ìˆ˜ìµì„± í•¨ì • (ë§ˆì§„ìœ¨ í•˜ìœ„ 3)]
{trap_report}

[ì†ì‹¤ ë°œìƒ ë©”ë‰´ (ë§ˆì§„ìœ¨ <= 0)]
{loss_report}
"""
    except Exception as e:
        return f"ë§ˆì§„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"


# ----------------------
# 5ï¸âƒ£ ì‚¬ì´ë“œë°” ë©”ë‰´
# ----------------------
# 1. ëª¨ë“  ë©”ë‰´ ì˜µì…˜ ì •ì˜
# 1. ëª¨ë“  ë©”ë‰´ ì˜µì…˜ ì •ì˜
MENU_OPTIONS = [
    "í™ˆ", "ê²½ì˜ í˜„í™©", "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ", "ê¸°ê°„ë³„ ë¶„ì„", "ê±°ë˜ ì¶”ê°€", 
    "ì¬ê³  ê´€ë¦¬", "AI ë¹„ì„œ", "ë°ì´í„° í¸ì§‘", "ê±°ë˜ ë‚´ì—­", "ì—°êµ¬ ê²€ì¦", "ë„ì›€ë§"
]

# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•± ì‹¤í–‰ ì‹œ 'í™ˆ'ìœ¼ë¡œ ì„¤ì •)
if "current_page" not in st.session_state:
    st.session_state.current_page = "í™ˆ"

# 3. í˜ì´ì§€ ë³€ê²½ í—¬í¼ í•¨ìˆ˜ (ë²„íŠ¼ í´ë¦­ ì‹œ ì‚¬ìš©)
def set_page(page_name):
    st.session_state.current_page = page_name

# 4. ì‚¬ì´ë“œë°” ì œê±°ë¨
# st.sidebar.radio(...) ê´€ë ¨ ì½”ë“œê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.

# 5. í˜„ì¬ í˜ì´ì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´
menu = st.session_state.current_page


# ==============================================================
# ğŸ  í™ˆ (ë©”ì¸ í™”ë©´)
# ==============================================================
if menu == "í™ˆ":
    st.header("ğŸ  ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë¦¬ ì‹œìŠ¤í…œ")
    st.write("ì›í•˜ì‹œëŠ” ë©”ë‰´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    # CSS ìŠ¤íƒ€ì¼ (ë²„íŠ¼ ë†’ì´ ë° í…ìŠ¤íŠ¸) - (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    st.markdown("""
    <style>
    /* 'border=True' ì»¨í…Œì´ë„ˆì˜ íŒ¨ë”©ì„ ì¡°ì ˆ */
    div[data-testid="stVerticalBlock"] > [data-testid="stVerticalBlockBorderWrapper"] {
        padding-top: 10px;
    }
    /* ë²„íŠ¼ ë†’ì´, í°íŠ¸ í¬ê¸° ì¡°ì ˆ */
    div[data-testid="stButton"] > button {
        height: 70px;
        font-size: 1.1rem;
        font-weight: 600;
    }
    .stButton p { /* ë²„íŠ¼ ë‚´ì˜ í…ìŠ¤íŠ¸(ì´ëª¨ì§€ í¬í•¨) */
        font-size: 1.1rem;
        font-weight: 600;
    }
    /* ë¶€ì œëª© í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ */
    .home-desc {
        text-align: center; 
        font-size: 0.9rem; 
        color: #555;
        margin-top: -10px; 
        padding-bottom: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

    # ë©”ë‰´ ì•„ì´í…œ ì •ì˜ (ì•„ì´ì½˜, ì´ë¦„, ì„¤ëª…)
    menu_items = {
        "ê²½ì˜ í˜„í™©": ("ğŸ“ˆ", "ì „ì²´ ê²½ì˜ í˜„í™© í™•ì¸"),
        "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ": ("ğŸ“Š", "ë§¤ì¶œ ë°ì´í„° ë¶„ì„"),
        "ê¸°ê°„ë³„ ë¶„ì„": ("ğŸ“…", "ê¸°ê°„ë³„ ë°ì´í„° ë¶„ì„"),
        "ê±°ë˜ ì¶”ê°€": ("â•", "ìƒˆë¡œìš´ ê±°ë˜ ë“±ë¡"),
        "ì¬ê³  ê´€ë¦¬": ("ğŸ“¦", "ì¬ê³  í˜„í™© ê´€ë¦¬"),
        "AI ë¹„ì„œ": ("ğŸ¤–", "AI ê¸°ë°˜ ì—…ë¬´ ì§€ì›"),
        "ë°ì´í„° í¸ì§‘": ("âœï¸", "ë°ì´í„° ìˆ˜ì • ë° ê´€ë¦¬"),
        "ê±°ë˜ ë‚´ì—­": ("ğŸ§¾", "ê±°ë˜ ì´ë ¥ ì¡°íšŒ"),
        "ì—°êµ¬ ê²€ì¦": ("ğŸ”¬", "ë°ì´í„° ê²€ì¦ ë° ì—°êµ¬"),
        "ë„ì›€ë§": ("â“", "ì‚¬ìš© ê°€ì´ë“œ ë° ì§€ì›"),
    }
    
    menu_keys = list(menu_items.keys())
    
    # 5x2 ê·¸ë¦¬ë“œ ìƒì„±
    for i in range(0, len(menu_keys), 5):
        cols = st.columns(5)
        current_row_keys = menu_keys[i:i+5]
        
        for col_index, key in enumerate(current_row_keys):
            icon, desc = menu_items[key]
            
            with cols[col_index].container(border=True):
                # [í•µì‹¬] ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ set_page í•¨ìˆ˜ê°€ í˜¸ì¶œë¨
                st.button(
                    label=f"{icon} {key}",
                    on_click=set_page,
                    args=(key,), # ğŸ‘ˆ This is the page name to pass to set_page
                    use_container_width=True,
                )
                # ë²„íŠ¼ ì•„ë˜ì— ì„¤ëª… ì¶”ê°€
                st.markdown(f"<div class='home-desc'>{desc}</div>", unsafe_allow_html=True)

# ==============================================================
# ğŸ§¾ ê±°ë˜ ì¶”ê°€ (ë²„íŠ¼ ê°€ì‹œì„± í–¥ìƒì„ ìœ„í•´ ìˆ˜ì •ëœ ì˜ˆì‹œ)
# ==============================================================

elif menu == "ê²½ì˜ í˜„í™©":
    # 1. st.columns()ì˜ ë°˜í™˜ê°’ì„ ì–¸íŒ¨í‚¹í•©ë‹ˆë‹¤. (í—¤ë”ê°€ í•„ìš” ì—†ìœ¼ë¯€ë¡œ, ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ë¬´ì‹œí•˜ê¸° ìœ„í•´ _ ì‚¬ìš©)
    _, col_button = st.columns([0.8, 0.2])
    
    # 2. ì´ì œ col_buttonì€ ë‘ ë²ˆì§¸ ì»¬ëŸ¼ ê°ì²´ì´ë¯€ë¡œ with êµ¬ë¬¸ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")
elif menu == "ê±°ë˜ ì¶”ê°€":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        # âœ¨ ì´ ì½”ë“œê°€ ë²„íŠ¼ì´ í—¤ë” ì˜†ì— ì˜ ë³´ì´ë„ë¡ ìˆ˜ì§ ì •ë ¬ì„ ë•ìŠµë‹ˆë‹¤.
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    
    st.markdown("---")

elif menu == "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
        
    st.markdown("---")

elif menu == "ê¸°ê°„ë³„ ë¶„ì„":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "ì¬ê³  ê´€ë¦¬":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "AI ë¹„ì„œ":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "ë°ì´í„° í¸ì§‘":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "ê±°ë˜ ë‚´ì—­":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")
    # try:
    #     df_raw, df_view = load_sales_with_id()

elif menu == "ì—°êµ¬ ê²€ì¦":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

elif menu == "ë„ì›€ë§":
    _, col_button = st.columns([0.8, 0.2])
    with col_button:
        st.write("") 
        st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_page, args=("í™ˆ",), use_container_width=True)
    st.markdown("---")

# ==============================================================
# ğŸ§¾ ê±°ë˜ ì¶”ê°€
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
if menu == "ê±°ë˜ ì¶”ê°€":
    st.header(" ê±°ë˜ ë°ì´í„° ì¶”ê°€")
    
    # [ìˆ˜ì •] st.formì„ ì œê±°í•˜ê³ , ì¢…ì†í˜• ë©”ë‰´ë¥¼ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜í•©ë‹ˆë‹¤.
    
    category_options = sorted(pd.Series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬']).dropna().unique().tolist())
    
    # --- 1. ì¹´í…Œê³ ë¦¬ ì„ íƒ ---
    ìƒí’ˆì¹´í…Œê³ ë¦¬_ko = st.selectbox("1. ìƒí’ˆì¹´í…Œê³ ë¦¬ ì„ íƒ", category_options, index=None, placeholder="ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”...")

    # --- 2. íƒ€ì… ì„ íƒ (ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ í•„í„°ë§) ---
    if ìƒí’ˆì¹´í…Œê³ ë¦¬_ko:
        df_filtered_type = df[df['ìƒí’ˆì¹´í…Œê³ ë¦¬'] == ìƒí’ˆì¹´í…Œê³ ë¦¬_ko]
        type_options = sorted(pd.Series(df_filtered_type['ìƒí’ˆíƒ€ì…']).dropna().unique().tolist())
        
        ìƒí’ˆíƒ€ì…_ko = st.selectbox("2. ìƒí’ˆíƒ€ì… ì„ íƒ", type_options, index=None, placeholder="ìƒí’ˆíƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”...")

        # --- 3. ìƒì„¸ ë©”ë‰´ ì„ íƒ (íƒ€ì…ì— ë”°ë¼ í•„í„°ë§) ---
        if ìƒí’ˆíƒ€ì…_ko:
            df_filtered_detail = df_filtered_type[df_filtered_type['ìƒí’ˆíƒ€ì…'] == ìƒí’ˆíƒ€ì…_ko]
            detail_options = sorted(pd.Series(df_filtered_detail['ìƒí’ˆìƒì„¸']).dropna().unique().tolist())
            
            ìƒí’ˆìƒì„¸_ko = st.selectbox("3. ìƒí’ˆìƒì„¸ ì„ íƒ", detail_options, index=None, placeholder="ìƒì„¸ ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”...")

            # --- 4. ìˆ˜ëŸ‰ ë° ë‹¨ê°€ ì…ë ¥ (ë©”ë‰´ê°€ í™•ì •ëœ í›„) ---
            if ìƒí’ˆìƒì„¸_ko:
                
                # [UX ê°œì„  2] ì„ íƒí•œ ë©”ë‰´ì˜ 'ìµœê·¼ ë‹¨ê°€'ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
                try:
                    # dfì—ì„œ ì´ ë©”ë‰´ì˜ ê°€ì¥ ë§ˆì§€ë§‰(ìµœê·¼) 'ë‹¨ê°€'ë¥¼ ì°¾ì•„ ì œì•ˆ
                    last_price = df[df['ìƒí’ˆìƒì„¸'] == ìƒí’ˆìƒì„¸_ko]['ë‹¨ê°€'].iloc[-1]
                    last_price = float(last_price)
                except Exception:
                    last_price = 1000.0 # ëª»ì°¾ìœ¼ë©´ ê¸°ë³¸ê°’

                st.markdown("---")
                
                col1, col2 = st.columns(2)
                with col1:
                    ìˆ˜ëŸ‰ = st.number_input("ìˆ˜ëŸ‰", min_value=1, value=1)
                with col2:
                    ë‹¨ê°€ = st.number_input(
                        "ë‹¨ê°€(ì›)", 
                        min_value=0.0, 
                        value=last_price, # ğŸ‘ˆ ìë™ìœ¼ë¡œ ì°¾ì€ ìµœê·¼ ë‹¨ê°€ë¥¼ ì œì•ˆ
                        step=100.0
                    )
                
                ë‚ ì§œ = st.date_input("ë‚ ì§œ", value=datetime.now().date())
                
                ìˆ˜ìµ = ìˆ˜ëŸ‰ * ë‹¨ê°€
                st.markdown(f"### ğŸ’° ê³„ì‚°ëœ ìˆ˜ìµ: **{format_krw(ìˆ˜ìµ)}**")
                
                # [ìˆ˜ì •] st.form_submit_button ëŒ€ì‹  st.button ì‚¬ìš©
                submitted = st.button("ë°ì´í„° ì¶”ê°€")
                
                if submitted:
                    # ... (ì´í•˜ ë°ì´í„° ì €ì¥ ë¡œì§ì€ ë™ì¼) ...
                    ìƒí’ˆì¹´í…Œê³ ë¦¬_en = rev_category_map.get(ìƒí’ˆì¹´í…Œê³ ë¦¬_ko, ìƒí’ˆì¹´í…Œê³ ë¦¬_ko)
                    ìƒí’ˆíƒ€ì…_en = rev_type_map.get(ìƒí’ˆíƒ€ì…_ko, ìƒí’ˆíƒ€ì…_ko)
                    ìƒí’ˆìƒì„¸_en = from_korean_detail(ìƒí’ˆìƒì„¸_ko)
                    
                    new_doc = {
                        "ë‚ ì§œ": str(ë‚ ì§œ),
                        # ... (ì´í•˜ ë™ì¼) ...
                    }
                    try:
                        db.collection(SALES_COLLECTION).add(new_doc)
                        st.success(f"âœ… '{ìƒí’ˆìƒì„¸_ko}' {ìˆ˜ëŸ‰}ê±´ ì¶”ê°€ ì™„ë£Œ!")
                        
                        with st.spinner("ì¬ê³  ìë™ ì°¨ê° ì ìš© ì¤‘..."):
                            adjust_inventory_by_recipe(
                                ìƒí’ˆìƒì„¸_en,
                                ìˆ˜ëŸ‰,
                                move_type="sale",
                                note=f"ê±°ë˜ ì¶”ê°€: {ìƒí’ˆìƒì„¸_ko} x{ìˆ˜ëŸ‰}"
                            )
                        st.success("âœ… ì¬ê³  ì°¨ê° ì™„ë£Œ!")
                        safe_rerun()
                    except Exception as e:
                        st.error(f"ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {e}")

# ==============================================================
# ğŸ“Š ê²½ì˜ í˜„í™©
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê²½ì˜ í˜„í™©":
    st.header("ğŸ“Š ê²½ì˜ í˜„í™©")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        total_revenue = df['ìˆ˜ìµ'].sum()
        total_sales_count = df.shape[0]
        avg_revenue_per_sale = total_revenue / total_sales_count if total_sales_count > 0 else 0
        
        st.markdown(
            f"""
            <div style="display:grid; grid-template-columns:1fr 1fr 1fr; gap:16px; margin-bottom:20px;">
                <div class="metric-card">
                    <div class="metric-title">ì´ ë§¤ì¶œ</div>
                    <div class="metric-value">{format_krw(total_revenue)}</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">ì´ íŒë§¤ ê±´ìˆ˜</div>
                    <div class="metric-value">{total_sales_count:,} ê±´</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">ê±´ë‹¹ í‰ê·  ë§¤ì¶œ</div>
                    <div class="metric-value">{format_krw(avg_revenue_per_sale)}</div>
                </div>
            </div>
            """, unsafe_allow_html=True
        )

        if not df.empty:
            try:
                top_cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
                top_prod = df.groupby('ìƒí’ˆíƒ€ì…')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
                st.info(f"ğŸ† ê°€ì¥ ë§¤ì¶œ ë†’ì€ ì¹´í…Œê³ ë¦¬: **{top_cat.index[0]}** ({format_krw(top_cat.iloc[0])}) / ìƒí’ˆ: **{top_prod.index[0]}**")
            except Exception:
                st.info("ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ìƒìœ„ í•­ëª©ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        col4, col5 = st.columns(2)
        with col4:
            # ì—¬ê¸°ëŠ” 'ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ' ë§‰ëŒ€ ì°¨íŠ¸
            cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().reset_index()
            
            # [ìˆ˜ì • 1] í´ ìˆ˜ë¡ ì˜¤ë¥¸ìª½ì— ìˆë„ë¡ 'ì˜¤ë¦„ì°¨ìˆœ(ascending=True)'ìœ¼ë¡œ ì •ë ¬
            cat = cat.sort_values('ìˆ˜ìµ', ascending=True) 
            
            fig_cat = px.bar(cat, x='ìƒí’ˆì¹´í…Œê³ ë¦¬', y='ìˆ˜ìµ', title="ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ")
            
            # [ìˆ˜ì • 2] í•˜ì´ë¸Œë¦¬ë“œ UX ì ìš©
            fig_cat.update_layout(
                yaxis_tickformat=None # Yì¶•: M/k ì¶•ì•½í˜•
            )
            fig_cat.update_traces(
                hovertemplate="ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>" # íˆ´íŒ: ì „ì²´ ìˆ«ì
            )
            
            st.plotly_chart(fig_cat, use_container_width=True)
        with col5:
            # [ë³µêµ¬] ì—¬ê¸°ê°€ 'ì¼ìë³„ ë§¤ì¶œ ì¶”ì´' ì›ë³¸ì…ë‹ˆë‹¤.
            daily = df.groupby('ë‚ ì§œ')['ìˆ˜ìµ'].sum().reset_index()
            
            # [ìˆ˜ì • 1] ìˆ˜ìµì´ 0ì¸ ë‚ ì§œ(ê·¸ë˜í”„ê°€ 0ìœ¼ë¡œ ë‚´ë ¤ê°€ëŠ” ì§€ì )ë¥¼ ì œì™¸í•©ë‹ˆë‹¤.
            daily_filtered = daily[daily['ìˆ˜ìµ'] > 0]
            
            fig_trend = px.line(
                daily_filtered,  # ğŸ‘ˆ 0ì›ì¸ ë‚ ì§œê°€ ì œì™¸ëœ ë°ì´í„° ì‚¬ìš©
                x='ë‚ ì§œ', 
                y='ìˆ˜ìµ', 
                title="ì¼ìë³„ ë§¤ì¶œ ì¶”ì´"
            )

            # [ìˆ˜ì • 2] í•˜ì´ë¸Œë¦¬ë“œ UX ì ìš©
            fig_trend.update_layout(
                yaxis_tickformat=None # Yì¶•: M/k ì¶•ì•½í˜•
            )
            fig_trend.update_traces(
                # íˆ´íŒ: "2025-01-15<br>ë§¤ì¶œ: 4,500,000ì›" í˜•ì‹
                hovertemplate="<b>%{x|%Y-%m-%d}</b><br>ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>" 
            )

            st.plotly_chart(fig_trend, use_container_width=True)

# ==============================================================
# ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ":
    st.header("ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        
        # [ìˆ˜ì •] 1. ì§‘ê³„ ì „, 'ë‚ ì§œ'ì™€ 'ìƒí’ˆì¹´í…Œê³ ë¦¬'ê°€ ë¹„ì–´ìˆëŠ”(NaN) ë°ì´í„°ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        df_clean = df.dropna(subset=['ë‚ ì§œ', 'ìƒí’ˆì¹´í…Œê³ ë¦¬'])

        if df_clean.empty:
            st.warning("ğŸ“ˆ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë‚ ì§œ ë˜ëŠ” ì¹´í…Œê³ ë¦¬ ì •ë³´ê°€ ë¹„ì–´ìˆìŒ)")
        else:
            # [ìˆ˜ì •] 2. 'ì›”'ê³¼ 'ìƒí’ˆì¹´í…Œê³ ë¦¬'ë³„ë¡œ ìˆ˜ìµì„ ì§‘ê³„í•©ë‹ˆë‹¤.
            try:
                monthly_stacked_df = df_clean.groupby([
                    df_clean['ë‚ ì§œ'].dt.to_period("M"), 
                    'ìƒí’ˆì¹´í…Œê³ ë¦¬'
                ])['ìˆ˜ìµ'].sum().reset_index()
                
                # [ìˆ˜ì •] 3. Plotlyë¥¼ ìœ„í•´ Period(ê¸°ê°„) ê°ì²´ë¥¼ Timestamp(ë‚ ì§œ)ë¡œ ë³€ê²½
                monthly_stacked_df['ë‚ ì§œ'] = monthly_stacked_df['ë‚ ì§œ'].dt.to_timestamp()

            except Exception as e:
                st.error(f"ë°ì´í„° ì§‘ê³„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.dataframe(df_clean[['ë‚ ì§œ', 'ìƒí’ˆì¹´í…Œê³ ë¦¬']]) # ì˜¤ë¥˜ íŒŒì•…ì„ ìœ„í•´ ì›ë³¸ ë°ì´í„° í‘œì‹œ
                monthly_stacked_df = pd.DataFrame() # ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì´ˆê¸°í™”

            # [ìˆ˜ì •] 4. ì§‘ê³„ëœ ë°ì´í„°ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸
            if monthly_stacked_df.empty:
                st.warning("ğŸ“ˆ ì›”ë³„/ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì§‘ê³„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                
                # [ìˆ˜ì • 1] Xì¶•ì„ í•œê¸€ë¡œ ë§Œë“¤ê¸° ìœ„í•´ 'ë‚ ì§œ' ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ê°€ê³µ
                # ì˜ˆ: '2025-01-01' -> '2025ë…„ 01ì›”'
                monthly_stacked_df['ì›”(í•œê¸€)'] = monthly_stacked_df['ë‚ ì§œ'].dt.strftime('%Yë…„ %mì›”')

                # [ìˆ˜ì • 2] 'px.bar'ë¥¼ ì‚¬ìš©í•´ ëˆ„ì  ë§‰ëŒ€ ê·¸ë˜í”„(Stacked Bar Chart) ìƒì„±
                fig_stacked_bar = px.bar(
                    monthly_stacked_df, 
                    x='ì›”(í•œê¸€)',      # ğŸ‘ˆ Xì¶•ì„ ìƒˆë¡œ ë§Œë“  í•œê¸€ ë¬¸ìì—´ ì»¬ëŸ¼ìœ¼ë¡œ ë³€ê²½
                    y='ìˆ˜ìµ',          
                    color='ìƒí’ˆì¹´í…Œê³ ë¦¬', 
                    title="ì›”ë³„/ì¹´í…Œê³ ë¦¬ë³„ ëˆ„ì  ë§¤ì¶œ",
                )
                
                # [ìˆ˜ì • 3] Yì¶•ì˜ 'M' ë‹¨ìœ„ë¥¼ ì‰¼í‘œ(,)ê°€ ìˆëŠ” ì „ì²´ ìˆ«ìë¡œ ë³€ê²½
                fig_stacked_bar.update_layout(
                    # [ì œê±°] 'yaxis_tickformat'ì„ ì œê±°í•˜ë©´
                    # Plotlyê°€ ìë™ìœ¼ë¡œ '100M'ì²˜ëŸ¼ ì¶•ì•½í•´ ì¤ë‹ˆë‹¤.
                    # yaxis_tickformat=',.0f', ğŸ‘ˆ ì´ ì¤„ì„ ì‚­ì œí•˜ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬
                    
                    xaxis_title="ì›”",        # Xì¶• ì œëª©
                    legend_itemclick=False # ë²”ë¡€ í´ë¦­ ë¹„í™œì„±í™”
                )
                
                # [ìˆ˜ì • 4] ë§ˆìš°ìŠ¤ ì˜¤ë²„(íˆ´íŒ)ì—ë„ 'M' ëŒ€ì‹  ì „ì²´ ìˆ«ìê°€ ë‚˜ì˜¤ë„ë¡ ìˆ˜ì •
                fig_stacked_bar.update_traces(
                    hovertemplate="<b>%{data.name}</b><br>ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>"
                )
                
                # ì°¨íŠ¸ê°€ ê°€ìš´ë°(ì „ì²´ ë„ˆë¹„)ì— ì˜¤ë„ë¡ ë°”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
                st.plotly_chart(fig_stacked_bar, use_container_width=True)

        
        # [ìˆ˜ì •] Sunburst ì°¨íŠ¸ë¥¼ Treemapìœ¼ë¡œ ë³€ê²½
        # [ìˆ˜ì •] Sunburst ì°¨íŠ¸ë¥¼ Treemapìœ¼ë¡œ ë³€ê²½
        prod_sales = df.groupby(['ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸'])['ìˆ˜ìµ'].sum().reset_index()
        
        # [ì¶”ê°€] ì§‘ê³„ëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not prod_sales.empty:
            fig_treemap = px.treemap(
                prod_sales, 
                path=['ìƒí’ˆíƒ€ì…', 'ìƒí’ˆìƒì„¸'], # ê³„ì¸µ êµ¬ì¡°: íƒ€ì… > ìƒì„¸
                values='ìˆ˜ìµ',               # íƒ€ì¼ í¬ê¸°
                title="ìƒí’ˆ êµ¬ì¡°ë³„ ë§¤ì¶œ (íŠ¸ë¦¬ë§µ)",
                
                # color='ìˆ˜ìµ',
                # color_continuous_scale=px.colors.sequential.Blues
            )
            
            # [UX ê°œì„ ] ìš”ì²­í•˜ì‹  3ê°€ì§€(íˆ´íŒ, ê°€ë…ì„±, í…ìŠ¤íŠ¸)ë¥¼ ì—¬ê¸°ì„œ ìˆ˜ì •í•©ë‹ˆë‹¤.
            fig_treemap.update_traces(
                
                # 1. íˆ´íŒ (ë§ˆìš°ìŠ¤ ì˜¬ë ¸ì„ ë•Œ) - "ì •í™•í•œ ì „ì²´ ìˆ«ì"
                # "k", "M" ì—†ì´ 1,234,567ì› í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                hovertemplate=(
                    "<b>%{label}</b><br>" +     
                    "ë§¤ì¶œ: %{value:,.0f}ì›" +   
                    "<extra></extra>"         
                ),
                
                # 2. íƒ€ì¼ ìœ„ í…ìŠ¤íŠ¸ (ë²„ê·¸ ìˆ˜ì • ë° UX ê°œì„ )
                # 'texttemplate' ëŒ€ì‹  'textinfo="label+value"'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                # íƒ€ì¼ ìœ„ì— "ì•„ë©”ë¦¬ì¹´ë…¸"ì™€ "150M"ì²˜ëŸ¼
                # ë ˆì´ë¸”ê³¼ 'ì¶•ì•½í˜•' ê°’ì´ í•¨ê»˜ í‘œì‹œë©ë‹ˆë‹¤.
                # (ì´ ë°©ì‹ì€ 'ë°”ê¹¥ íƒ­' ë²„ê·¸ë„ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)
                textinfo="label+value",
                textposition='middle center', 
                textfont_size=14
            )
            
            st.plotly_chart(fig_treemap, use_container_width=True) # ğŸ‘ˆ ê°œì„ ëœ ì°¨íŠ¸ë¥¼ í‘œì‹œ
        else:
            st.info("íŠ¸ë¦¬ë§µì„ í‘œì‹œí•  ìƒí’ˆ êµ¬ì¡° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
# ==============================================================
# ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê¸°ê°„ë³„ ë¶„ì„":
    st.header("ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        min_date = df['ë‚ ì§œ'].min().date()
        max_date = df['ë‚ ì§œ'].max().date()
        
        # [UX ê°œì„  1] st.sliderë¥¼ st.date_input 2ê°œë¡œ ë³€ê²½
        c_filter1, c_filter2 = st.columns(2)
        with c_filter1:
            start_date = st.date_input(
                "ì¡°íšŒ ì‹œì‘ì¼",
                value=min_date,
                min_value=min_date, max_value=max_date,
                format="YYYY/MM/DD"
            )
        with c_filter2:
            # ì‹œì‘ì¼ë³´ë‹¤ ì¢…ë£Œì¼ì´ ë¹ ë¥¼ ìˆ˜ ì—†ë„ë¡ min_value ì„¤ì •
            end_date = st.date_input(
                "ì¡°íšŒ ì¢…ë£Œì¼",
                value=max_date,
                min_value=start_date, max_value=max_date,
                format="YYYY/MM/DD"
            )
        
        # í•„í„° ë¡œì§ì„ start_date, end_dateë¡œ ë³€ê²½
        filtered_df = df[
            (df['ë‚ ì§œ'].dt.date >= start_date) & 
            (df['ë‚ ì§œ'].dt.date <= end_date)
        ]
        
        if filtered_df.empty:
            st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            c1, c2 = st.columns(2)
            
            # --- ì°¨íŠ¸ 1: ìš”ì¼ë³„ ë§¤ì¶œ ---
            with c1:
                week_sales = filtered_df.groupby('ìš”ì¼')['ìˆ˜ìµ'].sum().reindex(weekday_order_kr)
                
                # [UX ê°œì„  2] ìƒ‰ìƒ ë° í¬ë§· í†µì¼
                fig_week = px.bar(
                    week_sales, 
                    x=week_sales.index, 
                    y='ìˆ˜ìµ', 
                    title="ìš”ì¼ë³„ ë§¤ì¶œ",
                    color='ìˆ˜ìµ', # ë§¤ì¶œì•¡ ê¸°ì¤€ìœ¼ë¡œ ìƒ‰ìƒ ì ìš©
                    color_continuous_scale=px.colors.sequential.Blues # í†¤ë‹¤ìš´ ë¸”ë£¨
                )
                fig_week.update_layout(
                    yaxis_tickformat=None, # Yì¶•: M/k ì¶•ì•½í˜•
                    
                    # [ì¶”ê°€] í”Œë¡¯ ì˜ì—­ì— ì—°í•œ íšŒìƒ‰ ë°°ê²½ì„ ì¶”ê°€í•´ ê²½ê³„ë¥¼ ë§Œë“­ë‹ˆë‹¤.
                    plot_bgcolor='rgba(0,0,0,0.03)' 
                )
                fig_week.update_traces(hovertemplate="ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>")
                                
                st.plotly_chart(fig_week, use_container_width=True)
                
            # --- ì°¨íŠ¸ 2: ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ ---
            with c2:
                hour_sales = filtered_df.groupby('ì‹œ')['ìˆ˜ìµ'].sum().reset_index()
                
                # [UX ê°œì„  3] ì‹œê°„ëŒ€ë³„: Bar -> Line (ì¶”ì„¸ íŒŒì•…) + ìƒ‰ìƒ/í¬ë§· í†µì¼
                fig_hour = px.line( # ğŸ‘ˆ Barë¥¼ Lineìœ¼ë¡œ ë³€ê²½
                    hour_sales, 
                    x='ì‹œ', 
                    y='ìˆ˜ìµ', 
                    title="ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ ì¶”ì´",
                    markers=True # ì‹œê°„ëŒ€ë³„ë¡œ ì  í‘œì‹œ
                )
                # ë¼ì¸ ì°¨íŠ¸ëŠ” í†¤ë‹¤ìš´ ë¸”ë£¨ ê³„ì—´ì˜ ë‹¨ìƒ‰ìœ¼ë¡œ ì§€ì •
                fig_hour.update_traces(line_color='#08519c') 
                fig_hour.update_layout(
                    yaxis_tickformat=None, # Yì¶•: M/k ì¶•ì•½í˜•
                    xaxis_title="ì‹œê°„ (0-23ì‹œ)" # Xì¶• ì œëª© ì¶”ê°€
                )
                fig_hour.update_traces(hovertemplate="<b>%{x}ì‹œ</b><br>ë§¤ì¶œ: %{y:,.0f}ì›<extra></extra>") # íˆ´íŒ ê°œì„ 
                
                st.plotly_chart(fig_hour, use_container_width=True)
# ==============================================================
# ğŸ“¦ ì¬ê³  ê´€ë¦¬
# (ì›ë³¸ ì½”ë“œ ìƒëµ, [AI/ML í†µí•© ìˆ˜ì •]ì´ ì ìš©ëœ í•¨ìˆ˜ë¥¼ ì‚¬ìš©)
# ==============================================================
# ==============================================================
# ğŸ“¦ ì¬ê³  ê´€ë¦¬
# ==============================================================
elif menu == "ì¬ê³  ê´€ë¦¬":
    st.header("ğŸ“¦ ì¬ê³  ê´€ë¦¬")
    
    # [ìˆ˜ì •] ëª¨ë“  ë¡œì§ ì „ì— ì¬ê³ /íŒŒë¼ë¯¸í„°ë¥¼ ë¨¼ì € ë¡œë“œ
    df_inv = load_inventory_df()
    df_params = load_sku_params()
    
    # [UX ê°œì„ ] 3ì¤‘ íƒ­ì„ 2ê°œì˜ ëª…í™•í•œ íƒ­ìœ¼ë¡œ ì¬êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸ“Š ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°", "ğŸ“œ ë ˆì‹œí”¼ í¸ì§‘ê¸° (BOM)"])

    # ==============================================================
    # TAB 1: (ì‹ ê·œ) ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°
    # ==============================================================
    with tab1:
        st.subheader("ğŸ“Š ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„° ê´€ë¦¬")
        st.info("ì´ê³³ì—ì„œ ëª¨ë“  í’ˆëª©ì˜ **ì¬ê³ , ì›ê°€, ì¬ë£Œ ì—¬ë¶€**ë¥¼ í•œëˆˆì— ê´€ë¦¬í•©ë‹ˆë‹¤.")

        with st.expander("ğŸš€ (ì¬ë™ê¸°í™”) íŒë§¤ ë°ì´í„°ì—ì„œ í’ˆëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"):
            st.markdown("'ì•„ë©”ë¦¬ì¹´ë…¸'ì²˜ëŸ¼ íŒë§¤ ëª©ë¡ì—ëŠ” ìˆì§€ë§Œ, ì•„ë˜ ë§ˆìŠ¤í„° ëª©ë¡ì— ì—†ëŠ” í’ˆëª©ì„ ë™ê¸°í™”í•©ë‹ˆë‹¤.")
            
            if st.button("íŒë§¤ ëª©ë¡ê³¼ 'ì¬ë£Œ ë§ˆìŠ¤í„°' ë™ê¸°í™”í•˜ê¸°"):
                current_master_items_en = set(df_inv['ìƒí’ˆìƒì„¸_en'].unique())
                all_sales_items_kr = df['ìƒí’ˆìƒì„¸'].unique()
                all_sales_items_en = {from_korean_detail(name_kr) for name_kr in all_sales_items_kr if name_kr}
                new_items_to_add = list(all_sales_items_en - current_master_items_en)
                
                if not new_items_to_add:
                    st.success("âœ… ëª¨ë“  íŒë§¤ í’ˆëª©ì´ ì´ë¯¸ ë§ˆìŠ¤í„° ëª©ë¡ì— ìˆìŠµë‹ˆë‹¤. (ìƒˆ í•­ëª© 0ê±´)")
                else:
                    with st.spinner(f"{len(new_items_to_add)}ê°œì˜ ìƒˆ í’ˆëª©ì„ 'inventory'ë¡œ ì˜®ê¸°ëŠ” ì¤‘..."):
                        count = 0
                        for sku_en in new_items_to_add:
                            if sku_en:
                                ensure_inventory_doc(sku_en, uom="ea", is_ingredient=False)
                                count += 1
                    
                    st.success(f"âœ… ì´ {count}ê°œì˜ ìƒˆ í’ˆëª©ì„ 'inventory'ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
                    st.balloons()
                    safe_rerun()
        
        st.markdown("---") 

        if df_inv.empty:
            st.warning("ğŸ“¦ ë§ˆìŠ¤í„° ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. 'ë™ê¸°í™”' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”.")
            st.stop()
        
        df_inv_edit = df_inv.copy()
        df_inv_edit = df_inv_edit.sort_values('ìƒí’ˆìƒì„¸')
        
        # [ìˆ˜ì •] data_editorì— 'num_rows="dynamic"'ì„ ì¶”ê°€í•˜ì—¬ ìƒˆ í–‰ ìƒì„± í—ˆìš©
        edited_inv_df = st.data_editor(
            df_inv_edit[['ìƒí’ˆìƒì„¸', 'is_ingredient', 'uom', 'í˜„ì¬ì¬ê³ ', 'cost_unit_size', 'cost_per_unit', 'ìƒí’ˆìƒì„¸_en']],
            column_config={
                "ìƒí’ˆìƒì„¸": st.column_config.TextColumn("í’ˆëª©ëª…", disabled=False), 
                "is_ingredient": st.column_config.CheckboxColumn("ì¬ë£Œ ì—¬ë¶€ (ì²´í¬)"),
                "uom": st.column_config.TextColumn("ê¸°ë³¸ ë‹¨ìœ„", disabled=False), 
                "í˜„ì¬ì¬ê³ ": st.column_config.NumberColumn("í˜„ì¬ ì¬ê³ (ìˆ˜ê¸°)", min_value=0.0, format="%.2f"),
                "cost_unit_size": st.column_config.NumberColumn("ë§¤ì… ë‹¨ìœ„(g/ml/ea)", min_value=1.0, format="%.0f"),
                "cost_per_unit": st.column_config.NumberColumn("ë§¤ì…ê°€(ì›)", min_value=0, format="%dì›"),
                "ìƒí’ˆìƒì„¸_en": st.column_config.TextColumn("SKU (Eng)", disabled=True, help="ê¸°ì¡´ í’ˆëª©ì€ SKUìˆ˜ì • ë¶ˆê°€, ì‹ ê·œ í’ˆëª©ì€ ìë™ ìƒì„±ë¨"),
            },
            hide_index=True,
            num_rows="dynamic", # ğŸ‘ˆ [í•µì‹¬ ìˆ˜ì •] ìƒˆ í–‰ì„ ì¶”ê°€í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
            use_container_width=True
        )

        if st.button("ğŸ’¾ 'ì¬ë£Œ/ì›ê°€/ì¬ê³ ' ì„¤ì • ì €ì¥í•˜ê¸°", type="primary"):
            changed = 0
            created = 0 
            batch = db.batch()
            original_map = df_inv.set_index('ìƒí’ˆìƒì„¸_en').to_dict('index')

            for _, item in edited_inv_df.iterrows():
                sku_en = item['ìƒí’ˆìƒì„¸_en']
                
                if pd.isna(sku_en) or not sku_en:
                    new_sku_kr = item['ìƒí’ˆìƒì„¸']
                    if not new_sku_kr:
                        st.warning("ìƒˆë¡œ ì¶”ê°€ëœ í–‰ì˜ 'í’ˆëª©ëª…'ì´ ë¹„ì–´ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                    new_sku_en = from_korean_detail(new_sku_kr) 
                    
                    if new_sku_en in original_map:
                        st.error(f"'{new_sku_kr}'({new_sku_en})ëŠ” ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                        
                    new_doc_ref = db.collection(INVENTORY_COLLECTION).document(new_sku_en)
                    batch.set(new_doc_ref, {
                        "ìƒí’ˆìƒì„¸_en": new_sku_en,
                        "ìƒí’ˆìƒì„¸": new_sku_kr,
                        "is_ingredient": bool(item['is_ingredient']),
                        "uom": normalize_uom(item['uom'] or 'ea'),
                        "í˜„ì¬ì¬ê³ ": safe_float(item['í˜„ì¬ì¬ê³ '], 0.0),
                        "ì´ˆê¸°ì¬ê³ ": 0.0, 
                        "cost_unit_size": safe_float(item['cost_unit_size'], 1.0),
                        "cost_per_unit": safe_float(item['cost_per_unit'], 0.0)
                    })
                    created += 1
                    
                else:
                    orig_item = original_map.get(sku_en, {})
                    patch = {}
                    
                    new_sku_kr_update = item['ìƒí’ˆìƒì„¸']
                    if orig_item.get('ìƒí’ˆìƒì„¸', '') != new_sku_kr_update and new_sku_kr_update:
                         patch['ìƒí’ˆìƒì„¸'] = new_sku_kr_update
                    
                    is_ingr_new = bool(item['is_ingredient'])
                    if orig_item.get('is_ingredient') != is_ingr_new:
                        patch['is_ingredient'] = is_ingr_new
                    cost_unit_new = safe_float(item['cost_unit_size'], 1.0)
                    if orig_item.get('cost_unit_size', 1.0) != cost_unit_new:
                        patch['cost_unit_size'] = cost_unit_new
                    cost_new = safe_float(item['cost_per_unit'], 0.0)
                    if orig_item.get('cost_per_unit', 0.0) != cost_new:
                        patch['cost_per_unit'] = cost_new
                    stock_new = safe_float(item['í˜„ì¬ì¬ê³ '], 0.0)
                    if orig_item.get('í˜„ì¬ì¬ê³ ', 0.0) != stock_new:
                        patch['í˜„ì¬ì¬ê³ '] = stock_new

                    if patch: 
                        doc_ref = db.collection(INVENTORY_COLLECTION).document(sku_en)
                        batch.update(doc_ref, patch)
                        changed += 1
            
            if changed > 0 or created > 0:
                batch.commit()
                st.success(f"âœ… {created}ê±´ ìƒì„±, {changed}ê±´ ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
                st.balloons()
                safe_rerun()
            else:
                st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ==============================================================
    # TAB 2: (ì‹ ê·œ) ë ˆì‹œí”¼ í¸ì§‘ê¸°
    # ==============================================================
    with tab2:
        st.subheader("ğŸ“œ ë©”ë‰´ë³„ ë ˆì‹œí”¼ (BOM) í¸ì§‘")
        st.info("`ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°` íƒ­ì—ì„œ 'ì¬ë£Œ ì—¬ë¶€'ë¥¼ ì²´í¬í•œ í’ˆëª©ë“¤ë¡œ ë ˆì‹œí”¼ë¥¼ ë§Œë“­ë‹ˆë‹¤.")
        
        try:
            df_ingredients = df_inv[df_inv['is_ingredient'] == True].copy()
            if df_ingredients.empty:
                st.error("ì˜¤ë¥˜: 'ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°' íƒ­ì—ì„œ ì¬ë£Œë¥¼ 1ê°œ ì´ìƒ ì²´í¬í•´ì•¼ í•©ë‹ˆë‹¤.")
                st.stop()
            ingredient_options_kr = sorted(df_ingredients['ìƒí’ˆìƒì„¸'].unique().tolist())
            ing_kr_to_en_map = dict(zip(df_ingredients['ìƒí’ˆìƒì„¸'], df_ingredients['ìƒí’ˆìƒì„¸_en']))
            ing_en_to_kr_map = dict(zip(df_ingredients['ìƒí’ˆìƒì„¸_en'], df_ingredients['ìƒí’ˆìƒì„¸']))
        except Exception as e:
            st.error(f"ì¬ë£Œ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.stop()
            
        all_menus_kr = sorted(df_inv[df_inv['is_ingredient'] == False]['ìƒí’ˆìƒì„¸'].unique().tolist())
        selected_menu_kr = st.selectbox(
            "ë ˆì‹œí”¼ë¥¼ ë“±ë¡/ìˆ˜ì •í•  ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            all_menus_kr
        )
        
        # [ìˆ˜ì •] selectboxê°€ ë¹„ì–´ìˆìœ¼ë©´(ë©”ë‰´ê°€ 0ê°œ) ì˜¤ë¥˜ë‚˜ë¯€ë¡œ ë°©ì–´
        if not selected_menu_kr:
            st.warning("ë¨¼ì € 'ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°' íƒ­ì—ì„œ 'ìµœì¢… ë©”ë‰´'ë¥¼ 1ê°œ ì´ìƒ ë“±ë¡í•´ì£¼ì„¸ìš”. ('ì¬ë£Œ ì—¬ë¶€' ì²´í¬ í•´ì œ)")
            st.stop()
            
        selected_menu_en = from_korean_detail(selected_menu_kr)
        st.caption(f"(Firebase ë¬¸ì„œ ID: `{selected_menu_en}`)")
        st.markdown("---")
        
        current_recipe_items = load_recipe(selected_menu_en)
        recipe_df_rows = []
        if current_recipe_items:
            for item in current_recipe_items:
                sku_en = item.get("ingredient_en")
                recipe_df_rows.append({
                    "ì¬ë£Œ": ing_en_to_kr_map.get(sku_en, f"ì˜¤ë¥˜: {sku_en}?"),
                    "ìˆ˜ëŸ‰": safe_float(item.get("qty", 0.0)),
                    "ë‹¨ìœ„": normalize_uom(item.get("uom", "g")),
                    "ì†ì‹¤ë¥ (%)": safe_float(item.get("waste_pct", 0.0)),
                })
        if not recipe_df_rows:
            recipe_df_rows = [{"ì¬ë£Œ": None, "ìˆ˜ëŸ‰": 0.0, "ë‹¨ìœ„": "g", "ì†ì‹¤ë¥ (%)": 0.0}]
        df_recipe_editor = pd.DataFrame(recipe_df_rows)
        st.subheader(f"ğŸ“ `{selected_menu_kr}` ë ˆì‹œí”¼ í¸ì§‘")
        edited_df = st.data_editor(
            df_recipe_editor,
            column_config={
                "ì¬ë£Œ": st.column_config.SelectboxColumn("ì¬ë£Œ (í•„ìˆ˜)", options=ingredient_options_kr, required=True),
                "ìˆ˜ëŸ‰": st.column_config.NumberColumn("ìˆ˜ëŸ‰", min_value=0.0, format="%.2f", required=True),
                "ë‹¨ìœ„": st.column_config.SelectboxColumn("ë‹¨ìœ„", options=["g", "ml", "ea"], required=True),
                "ì†ì‹¤ë¥ (%)": st.column_config.NumberColumn("ì†ì‹¤ë¥ (%)", min_value=0.0, max_value=100.0, format="%.1f %%", required=True),
            },
            num_rows="dynamic",
            use_container_width=True
        )
        
        if st.button(f"ğŸ’¾ `{selected_menu_kr}` ë ˆì‹œí”¼ ì €ì¥í•˜ê¸°", type="primary"):
            final_ingredients = []
            valid = True
            for index, row in edited_df.iterrows():
                ì¬ë£Œ_kr = row["ì¬ë£Œ"]
                if not ì¬ë£Œ_kr: continue 
                ì¬ë£Œ_en = ing_kr_to_en_map.get(ì¬ë£Œ_kr)
                if not ì¬ë£Œ_en:
                    st.error(f"'{ì¬ë£Œ_kr}'ëŠ” ìœ íš¨í•œ ì¬ë£Œê°€ ì•„ë‹™ë‹ˆë‹¤. 'ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
                    valid = False; break
                final_ingredients.append({
                    "ingredient_en": ì¬ë£Œ_en,
                    "qty": safe_float(row["ìˆ˜ëŸ‰"]),
                    "uom": normalize_uom(row["ë‹¨ìœ„"]),
                    "waste_pct": safe_float(row["ì†ì‹¤ë¥ (%)"]),
                })
            if valid and not final_ingredients: st.warning("ì €ì¥í•  ì¬ë£Œê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  í–‰ì´ ë¹„ì–´ìˆìŒ)")
            elif valid and final_ingredients:
                try:
                    db.collection(RECIPES_COLLECTION).document(selected_menu_en).set({"ingredients": final_ingredients})
                    load_all_core_data.clear() 
                    load_recipe.clear()        
                    st.success(f"âœ… `{selected_menu_kr}` ë ˆì‹œí”¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.balloons()
                    safe_rerun()
                except Exception as e: st.error(f"Firebase ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # [ë³µì›] 'ì˜ˆì „ ê·¸ë˜í”„' ë¡œì§ìœ¼ë¡œ ë˜ëŒë¦½ë‹ˆë‹¤.
        st.divider()
        st.subheader(f"ğŸ¤– AI ì¬ê³  ì˜í–¥ë„ ë¶„ì„ ({selected_menu_kr})")
        
        try:
            # [ë³µì›] compute_ingredient_metrics_for_menuê°€
            # ì´ì œ ì°¨íŠ¸(st.plotly_chart)ì™€ í…Œì´ë¸”(report_df)ì„ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            report_df = compute_ingredient_metrics_for_menu(
                selected_menu_en,
                df, 
                df_inv,
                df_params
            )
            
            # [ë³µì›] ì¬ê³  ë¶„ì„í‘œ(DataFrame)ëŠ” ì°¨íŠ¸ ì•„ë˜ì— í‘œì‹œ
            if report_df.empty:
                st.warning(f"'{selected_menu_kr}'ì— ëŒ€í•œ ë ˆì‹œí”¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë ˆì‹œí”¼ë¥¼ ë¨¼ì € ì €ì¥í•´ì£¼ì„¸ìš”.")
            else:
                display_cols = ['ìƒí’ˆìƒì„¸', 'ìƒíƒœ', 'í˜„ì¬ì¬ê³ ', 'uom', 'ê¶Œì¥ë°œì£¼', 'ì»¤ë²„ì¼ìˆ˜', 'ì¼í‰ê· ì†Œì§„', 'ROP']
                formatted_df = report_df[display_cols].copy()
                formatted_df['í˜„ì¬ì¬ê³ '] = formatted_df.apply(lambda r: f"{r['í˜„ì¬ì¬ê³ ']:,.1f} {r['uom']}", axis=1)
                formatted_df['ê¶Œì¥ë°œì£¼'] = formatted_df.apply(lambda r: f"{r['ê¶Œì¥ë°œì£¼']:,.1f} {r['uom']}", axis=1)
                formatted_df['ì¼í‰ê· ì†Œì§„'] = formatted_df.apply(lambda r: f"{r['ì¼í‰ê· ì†Œì§„']:,.1f} {r['uom']}", axis=1)
                formatted_df['ROP'] = formatted_df.apply(lambda r: f"{r['ROP']:,.1f} {r['uom']}", axis=1)
                formatted_df['ì»¤ë²„ì¼ìˆ˜'] = formatted_df['ì»¤ë²„ì¼ìˆ˜'].apply(lambda x: f"{x}ì¼")
                st.dataframe(formatted_df[['ìƒí’ˆìƒì„¸', 'ìƒíƒœ', 'í˜„ì¬ì¬ê³ ', 'ê¶Œì¥ë°œì£¼', 'ì»¤ë²„ì¼ìˆ˜', 'ì¼í‰ê· ì†Œì§„', 'ROP']], use_container_width=True)
        
        except Exception as e:
            st.error(f"AI ì¬ê³  ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            import traceback
            st.exception(traceback.format_exc())

# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [AI/ML í†µí•© ìˆ˜ì • 2] ===
# AIê°€ 'ê±°ì§“ë§'ì„ í•˜ì§€ ì•Šë„ë¡ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ì™€ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ë¦¬
# =============================================================
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [AI/ML í†µí•© ìˆ˜ì • 9] ===
# "ë ˆë²¨ 4: AI ì¬ë¬´/ìš´ì˜ ë¶„ì„ê°€"ë¡œ ì—…ê·¸ë ˆì´ë“œ
# 1. 3ëŒ€ ë¶„ì„ í•¨ìˆ˜ (ì¬ê³ ìœ„í—˜, "ë§ˆì§„ ì¸ì‚¬ì´íŠ¸", íŒë§¤íŒ¨í„´) ìë™ ì‹¤í–‰
# 2. ë¶„ì„ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ AIì—ê²Œ ì „ë‹¬ -> 'ì‹¤í–‰ ì¡°ì–¸' ìƒì„±
# =============================================================
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [UX ê°œì„ ] 'ì¼ë°©ì  ì¡°ì–¸' -> 'ì„ íƒí˜• ë¸Œë¦¬í•‘'ìœ¼ë¡œ ë³€ê²½ ===
# =============================================================
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [UX ê°œì„ ] 'ìƒˆë¡œ ë¶„ì„í•˜ê¸°' ë²„íŠ¼ ì¶”ê°€ ===
# =============================================================
elif menu == "AI ë¹„ì„œ":
    st.header("ğŸ¤– AI ë¹„ì„œ (ì„ íƒí˜• ë¸Œë¦¬í•‘)")

    # [ìˆ˜ì •] ëŒ€í™” ê¸°ë¡ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    if "messages_ai_v2" not in st.session_state:
        st.session_state.messages_ai_v2 = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”, ì‚¬ì¥ë‹˜! ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë¨¼ì € ë¸Œë¦¬í•‘í•´ ë“œë¦´ê¹Œìš”?"}]
    
    # [ìˆ˜ì •] ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "analysis_context" not in st.session_state:
        st.session_state.analysis_context = {
            "risk": None,
            "profit": None,
            "pattern": None
        }

    # [UX ê°œì„  3] 'ìƒˆë¡œ ë¶„ì„í•˜ê¸°' ë²„íŠ¼ ì¶”ê°€
    if st.button("ğŸ”„ ìµœì‹  ë°ì´í„°ë¡œ ìƒˆë¡œ ë¶„ì„í•˜ê¸°", help="ìƒˆë¡œ ì¶”ê°€ëœ ê±°ë˜ ë‚´ì—­ì„ ë°˜ì˜í•˜ì—¬ AI ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤."):
        with st.spinner("ìµœì‹  ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... â³"):
            # 1. AI ë¶„ì„ í•¨ìˆ˜ë¥¼ 'ê°•ì œë¡œ' ë‹¤ì‹œ ì‹¤í–‰
            risk_report = find_inventory_risks(df, df_inv, df_params)
            profit_report = find_profit_insights(df)
            pattern_report = find_top_correlations(df)
            
            # 2. ì„¸ì…˜ ìƒíƒœì— 'ìµœì‹ ' ë¶„ì„ ê²°ê³¼ë¥¼ ë®ì–´ì“°ê¸°
            st.session_state.analysis_context['risk'] = risk_report
            st.session_state.analysis_context['profit'] = profit_report
            st.session_state.analysis_context['pattern'] = pattern_report
            
            # 3. ëŒ€í™” ê¸°ë¡ë„ ë¦¬ì…‹
            st.session_state.messages_ai_v2 = [{"role": "assistant", "content": "âœ… ìµœì‹  ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ë¬´ì—‡ì„ ë¸Œë¦¬í•‘í•´ ë“œë¦´ê¹Œìš”?"}]
            
            st.success("ìƒˆë¡œ ë¶„ì„ ì™„ë£Œ!")
            safe_rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨

    st.markdown("ë°ì´í„° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¦¬í•‘ì„ ìš”ì²­í•˜ì„¸ìš”.")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸš¨ ì¬ê³  ìœ„í—˜ ë³´ê¸°", use_container_width=True):
            # [ìˆ˜ì •] ë²„íŠ¼ í´ë¦­ ì‹œì ì— 'ì•„ì§ ë¶„ì„ ì•ˆ í•œ' ê²½ìš°ì—ë§Œ ë¶„ì„ ì‹¤í–‰
            if st.session_state.analysis_context.get('risk') is None:
                st.session_state.analysis_context['risk'] = find_inventory_risks(df, df_inv, df_params)
                
            st.session_state.messages_ai_v2.append({"role": "user", "content": "ì¬ê³  ìœ„í—˜ ë¸Œë¦¬í•‘í•´ì¤˜."})
            st.session_state.messages_ai_v2.append({"role": "assistant", "content": f"**[AI ì‚¬ì‹¤ ë¦¬í¬íŠ¸: ì¬ê³  ìœ„í—˜]**\n\n{st.session_state.analysis_context['risk']}"})
            safe_rerun()

    with col2:
        if st.button("ğŸ’° ë§ˆì§„ ë¶„ì„ ë³´ê¸°", use_container_width=True):
            if st.session_state.analysis_context.get('profit') is None:
                st.session_state.analysis_context['profit'] = find_profit_insights(df)
                
            st.session_state.messages_ai_v2.append({"role": "user", "content": "ë§ˆì§„ ë¶„ì„ ë¸Œë¦¬í•‘í•´ì¤˜."})
            st.session_state.messages_ai_v2.append({"role": "assistant", "content": f"**[AI ì‚¬ì‹¤ ë¦¬í¬íŠ¸: ë§ˆì§„ ë¶„ì„]**\n\n{st.session_state.analysis_context['profit']}"})
            safe_rerun()

    with col3:
        if st.button("ğŸ“ˆ íŒë§¤ íŒ¨í„´ ë³´ê¸°", use_container_width=True):
            if st.session_state.analysis_context.get('pattern') is None:
                st.session_state.analysis_context['pattern'] = find_top_correlations(df)
                
            st.session_state.messages_ai_v2.append({"role": "user", "content": "íŒë§¤ íŒ¨í„´ ë¸Œë¦¬í•‘í•´ì¤˜."})
            st.session_state.messages_ai_v2.append({"role": "assistant", "content": f"**[AI ì‚¬ì‹¤ ë¦¬í¬íŠ¸: íŒë§¤ íŒ¨í„´]**\n\n{st.session_state.analysis_context['pattern']}"})
            safe_rerun()
            
    st.divider()

    # --- 2. ëŒ€í™”ì°½ UI (ê¸°ì¡´ê³¼ ë™ì¼) ---
    
    # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.messages_ai_v2:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # [ìˆ˜ì •] st.chat_input ì‚¬ìš©
    if prompt := st.chat_input("ìœ„ ë¶„ì„ ë‚´ìš©ì— ëŒ€í•´ ë” ë¬¼ì–´ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê²ƒì„ ìš”ì²­í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages_ai_v2.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("AIê°€ ë¶„ì„ ë‚´ìš©ê³¼ ì‚¬ì¥ë‹˜ì˜ ì§ˆë¬¸ì„ í•¨ê»˜ ìƒê° ì¤‘ì…ë‹ˆë‹¤... ğŸ§ "):
                
                # [ìˆ˜ì •] AIê°€ í˜„ì¬ê¹Œì§€ì˜ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ 'ì‚¬ì‹¤'ë¡œ ì¸ì§€í•˜ë„ë¡ ì»¨í…ìŠ¤íŠ¸ ì¡°í•©
                full_context = f"""
                [AI ë¶„ì„ ë¦¬í¬íŠ¸ 1: ì¬ê³  ìœ„í—˜]
                {st.session_state.analysis_context.get('risk', 'ì•„ì§ ë¶„ì„ ì•ˆ í•¨')}
                
                [AI ë¶„ì„ ë¦¬í¬íŠ¸ 2: ë§ˆì§„ ë¶„ì„]
                {st.session_state.analysis_context.get('profit', 'ì•„ì§ ë¶„ì„ ì•ˆ í•¨')}
                
                [AI ë¶„ì„ ë¦¬í¬íŠ¸ 3: í•µì‹¬ íŒë§¤ íŒ¨í„´]
                {st.session_state.analysis_context.get('pattern', 'ì•„ì§ ë¶„ì„ ì•ˆ í•¨')}
                """
                
                result_text = call_openai_api(
                    user_prompt=prompt,
                    data_context=full_context
                )
                
                if result_text:
                    st.markdown(result_text)
                    st.session_state.messages_ai_v2.append({"role": "assistant", "content": result_text})
                else:
                    st.error("AI ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# === [ë¹ˆí‹ˆ ìˆ˜ì •] 'ê°€ê²Œìœ„ì¹˜' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°(ì•± ì¶”ê°€ 0ê±´)ì—ë„ ì˜¤ë¥˜ ì—†ë„ë¡ ìˆ˜ì • ===
# ==============================================================
# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# === [UX ê°œì„ ] tab2(ê¸°ëŠ¥ ì¤‘ë³µ) ì‚­ì œ, 'ìˆ˜ìµ' ìë™ê³„ì‚°, ì‚­ì œ UI ê°„ì†Œí™” ===
# ==============================================================
elif menu == "ë°ì´í„° í¸ì§‘":
    # [ìˆ˜ì •] í—¤ë”ë¥¼ 'ê±°ë˜ ìˆ˜ì •/ì‚­ì œ'ë¡œ ëª…í™•íˆ í•¨
    st.header("âœï¸ ê±°ë˜ ìˆ˜ì •/ì‚­ì œ")
    
    # [ìˆ˜ì •] tab1, tab2 êµ¬ë¶„ ì‚­ì œ
    
    df_raw, df_view = load_sales_with_id()
    if df_view.empty:
        st.info("ìˆ˜ì •í•  Firebase ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (CSVëŠ” ì½ê¸° ì „ìš©)")
    else:
        st.caption("ğŸ’¡ Firebaseì— ì €ì¥ëœ ê±°ë˜ ë‚´ì—­ë§Œ ìˆ˜ì •/ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê°€ê²Œìœ„ì¹˜=Firebase)")
        
        if 'ê°€ê²Œìœ„ì¹˜' in df_view.columns:
            df_view_fb = df_view[df_view['ê°€ê²Œìœ„ì¹˜'] == 'Firebase'].copy()
        else:
            df_view_fb = pd.DataFrame(columns=df_view.columns) 
        
        if df_view_fb.empty:
            st.info("ì•„ì§ ì•±ì„ í†µí•´ ì¶”ê°€ëœ(ìˆ˜ì • ê°€ëŠ¥í•œ) ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            
            # [ìˆ˜ì •] 'ìˆ˜ìµ' ì»¬ëŸ¼ì„ ìˆ˜ì • ë¶ˆê°€ëŠ¥(disabled)í•˜ê²Œ ë³€ê²½
            edited_df = st.data_editor(
                df_view_fb[['_id','ë‚ ì§œ','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ']],
                column_config={
                    "_id": st.column_config.TextColumn("ë¬¸ì„œID", disabled=True),
                    "ë‚ ì§œ": st.column_config.DateColumn("ë‚ ì§œ", format="YYYY-MM-DD"),
                    "ìˆ˜ëŸ‰": st.column_config.NumberColumn("ìˆ˜ëŸ‰", min_value=0), # 0ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥
                    "ë‹¨ê°€": st.column_config.NumberColumn("ë‹¨ê°€(ì›)", format="%dì›"),
                    "ìˆ˜ìµ": st.column_config.NumberColumn(
                        "ìˆ˜ìµ (ìë™ê³„ì‚°)", 
                        disabled=True, # ğŸ‘ˆ [í•µì‹¬ ìˆ˜ì •] ì‚¬ìš©ìê°€ ì§ì ‘ ìˆ˜ì • ë¶ˆê°€
                        format="%dì›"
                    )
                },
                hide_index=True,
                num_rows="dynamic" # ğŸ‘ˆ [í•µì‹¬] ì—¬ê¸°ì„œ í–‰ ì‚­ì œ ê°€ëŠ¥
            )
            
            # [ìœ ì§€] ì´ ì²´í¬ë°•ìŠ¤ëŠ” ë””ìì´ë„ˆë‹˜ ìš”ì²­ëŒ€ë¡œ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
            reflect_inv = st.checkbox("ì €ì¥ ì‹œ ì¬ê³ ì— ë°˜ì˜(ì°¨ê°/ë³µì›)", value=True)
            
            if st.button("ë³€ê²½ëœ ë‚´ìš© ì €ì¥í•˜ê¸° ğŸ’¾"):
                changed = 0 # ìˆ˜ì •ëœ í–‰
                deleted = 0 # ì‚­ì œëœ í–‰
                
                # [ìˆ˜ì •] data_editorì—ì„œ ì‚­ì œëœ í–‰ì„ ë¨¼ì € ê°ì§€
                orig_ids = set(df_view_fb['_id'])
                edited_ids = set(edited_df['_id'])
                deleted_ids = list(orig_ids - edited_ids)

                if deleted_ids:
                    for doc_id in deleted_ids:
                        if reflect_inv: # ì‚­ì œ ì‹œ ì¬ê³  ë³µì›
                            try:
                                orig = df_raw[df_raw['_id'] == doc_id].iloc[0]
                                qty_to_restore = -int(orig.get('ìˆ˜ëŸ‰', 0)) # ìˆ˜ëŸ‰ì„ ìŒìˆ˜ë¡œ
                                detail_en = orig.get('ìƒí’ˆìƒì„¸')
                                if qty_to_restore != 0 and detail_en:
                                    adjust_inventory_by_recipe(detail_en, qty_to_restore, move_type="delete_restore", note=f"Deleted: {doc_id}")
                            except Exception as e:
                                st.warning(f"{doc_id} ì¬ê³  ë³µì› ì‹¤íŒ¨: {e}")
                        
                        db.collection(SALES_COLLECTION).document(doc_id).delete()
                        deleted += 1

                # [ìˆ˜ì •] ìˆ˜ì •ëœ í–‰ ì²˜ë¦¬
                for i, new in edited_df.iterrows():
                    doc_id = new['_id']
                    if pd.isna(doc_id): # ìƒˆë¡œ ì¶”ê°€ëœ í–‰ì€ ë¬´ì‹œ (ì´ íƒ­ì€ 'ìˆ˜ì •/ì‚­ì œ' ì „ìš©)
                        continue
                        
                    orig = df_raw[df_raw['_id'] == doc_id].iloc[0]
                    patch = {}
                    
                    try:
                        new_date_str = str(pd.to_datetime(new['ë‚ ì§œ']).date())
                    except Exception:
                        new_date_str = str(orig.get('ë‚ ì§œ'))
                    if new_date_str != str(orig.get('ë‚ ì§œ')):
                        patch['ë‚ ì§œ'] = new_date_str
                    
                    detail_en = from_korean_detail(new['ìƒí’ˆìƒì„¸'])
                    if detail_en != orig.get('ìƒí’ˆìƒì„¸'):
                        patch['ìƒí’ˆìƒì„¸'] = detail_en
                    
                    # [í•µì‹¬ ìˆ˜ì •] 'ìˆ˜ìµ' ìë™ ê³„ì‚° ë¡œì§
                    qty_new = int(new['ìˆ˜ëŸ‰'])
                    unit_new = float(new['ë‹¨ê°€'])
                    rev_new_calculated = qty_new * unit_new # ğŸ‘ˆ 'ìˆ˜ìµ' ìë™ ê³„ì‚°

                    qty_changed = qty_new != int(orig.get('ìˆ˜ëŸ‰', 0))
                    unit_changed = unit_new != float(orig.get('ë‹¨ê°€', 0))
                    
                    if qty_changed:
                        patch['ìˆ˜ëŸ‰'] = qty_new
                    if unit_changed:
                        patch['ë‹¨ê°€'] = unit_new

                    # ìˆ˜ëŸ‰/ë‹¨ê°€ê°€ ë°”ë€Œì—ˆê±°ë‚˜, ì›ë˜ ìˆ˜ìµì´ ì˜ëª» ê³„ì‚°ëì—ˆë‹¤ë©´ 'ìˆ˜ìµ' ì—…ë°ì´íŠ¸
                    if (qty_changed or unit_changed) or (rev_new_calculated != float(orig.get('ìˆ˜ìµ', 0))):
                        patch['ìˆ˜ìµ'] = rev_new_calculated
                    
                    if patch:
                        if reflect_inv and 'ìˆ˜ëŸ‰' in patch: # ì¬ê³  ë°˜ì˜
                            diff = qty_new - int(orig.get('ìˆ˜ëŸ‰', 0))
                            adjust_inventory_by_recipe(detail_en, diff, move_type="edit_adjust", note=str(doc_id))
                        
                        db.collection(SALES_COLLECTION).document(doc_id).update(patch)
                        changed += 1
                
                if changed > 0 or deleted > 0:
                    st.success(f"âœ… {changed}ê±´ ìˆ˜ì •, {deleted}ê±´ ì‚­ì œ ì™„ë£Œ")
                    safe_rerun()
                else:
                    st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

            # [ìˆ˜ì •] ID ê¸°ë°˜ì˜ multiselect ì‚­ì œ ê¸°ëŠ¥ (st.markdown("---") ì´í•˜) ëª¨ë‘ ì‚­ì œ
    
    # [ìˆ˜ì •] `with tab2:` ë¸”ë¡ ì „ì²´ ì‚­ì œ

# ==============================================================

# ğŸ“‹ ê±°ë˜ ë‚´ì—­
# ==============================================================
elif menu == "ê±°ë˜ ë‚´ì—­":
    st.header("ğŸ“‹ ì „ì²´ ê±°ë˜ ë‚´ì—­")
    if df.empty:
        st.info("í‘œì‹œí•  ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        
        # --- [UX ê°œì„  1] í•„í„° ë° ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€ ---
        max_date = df['ë‚ ì§œ'].max().date()
        min_date = df['ë‚ ì§œ'].min().date()

        # 1. ë‚ ì§œ í•„í„° (ìµœì‹  ë‚ ì§œë¶€í„° 30ì¼ ì´ì „ê¹Œì§€ ê¸°ë³¸ê°’)
        default_start_date = max_date - pd.Timedelta(days=30)
        default_start_date = max(min_date, default_start_date) # ë°ì´í„° ì‹œì‘ì¼ë³´ë‹¤ ë¹ ë¥¼ ìˆ˜ ì—†ìŒ
        
        col_date1, col_date2 = st.columns(2)
        with col_date1:
            start_date = st.date_input("ì¡°íšŒ ì‹œì‘ì¼", value=default_start_date, max_value=max_date)
        with col_date2:
            end_date = st.date_input("ì¡°íšŒ ì¢…ë£Œì¼", value=max_date, min_value=start_date, max_value=max_date)
        
        # 2. í…ìŠ¤íŠ¸ ê²€ìƒ‰ í•„í„°
        search_query = st.text_input("ìƒí’ˆ ê²€ìƒ‰ (ìƒí’ˆìƒì„¸ ë˜ëŠ” ì¹´í…Œê³ ë¦¬)", "")

        # 3. ë°ì´í„° í•„í„°ë§ ì ìš© (ë‚ ì§œ í•„í„°)
        filtered_df = df[
            (df['ë‚ ì§œ'].dt.date >= start_date) & 
            (df['ë‚ ì§œ'].dt.date <= end_date)
        ]
        
        # 4. í…ìŠ¤íŠ¸ ê²€ìƒ‰ í•„í„° ì ìš©
        if search_query:
            # ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ ìƒí’ˆ ìƒì„¸ ë˜ëŠ” ì¹´í…Œê³ ë¦¬ì—ì„œ í•„í„°ë§
            filtered_df = filtered_df[
                filtered_df['ìƒí’ˆìƒì„¸'].str.contains(search_query, case=False) |
                filtered_df['ìƒí’ˆì¹´í…Œê³ ë¦¬'].str.contains(search_query, case=False)
            ]

        # --- [UX ê°œì„  2] ìš”ì•½ ì •ë³´ í‘œì‹œ ---
        st.markdown(f"---")
        total_filtered_rows = len(filtered_df)
        total_filtered_revenue = filtered_df['ìˆ˜ìµ'].sum()
        
        c_metric1, c_metric2 = st.columns(2)
        c_metric1.metric("í‘œì‹œëœ ê±°ë˜ ê±´ìˆ˜", f"{total_filtered_rows:,} ê±´")
        c_metric2.metric("í‘œì‹œëœ ë§¤ì¶œ ì´í•©", format_krw(total_filtered_revenue))
        
        st.caption(f"ì´ {len(df)}ê±´ì˜ ê±°ë˜ ë‚´ì—­ ì¤‘, í•„í„°ë§ëœ **{total_filtered_rows}ê±´**ì„ í‘œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # 5. í•„í„°ë§ëœ ë°ì´í„° ì¶œë ¥
        cols = ['ë‚ ì§œ','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ','ìƒí’ˆì¹´í…Œê³ ë¦¬','ìš”ì¼','ì‹œ']
        cols = [c for c in cols if c in filtered_df.columns]
        
        st.dataframe(
            filtered_df[cols].sort_values('ë‚ ì§œ', ascending=False), 
            width=None, 
            use_container_width=True
        )

elif menu == "ì—°êµ¬ ê²€ì¦":
    st.header("ğŸ“ ì—°êµ¬ ê²€ì¦ ë° ê¸°ìˆ  ì‹¤ì¦ (Validation)")
    st.markdown("""
    ë³¸ ì—°êµ¬ëŠ” **ì‹œìŠ¤í…œ ì„±ëŠ¥**, **AI ëª¨ë¸ ì‹ ë¢°ë„**, **ë¹„ìš© ëª¨ë¸**ì˜ ì„¸ ê°€ì§€ í•µì‹¬ ì„±ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    """)
    st.divider()

    # --- 1. ì‹œìŠ¤í…œ ì„±ëŠ¥ (Speed) ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 1: ì‹œìŠ¤í…œ ì„±ëŠ¥ (ë°ì´í„° ì²˜ë¦¬ ì†ë„) ğŸš€")
    st.metric(f"Kaggle ì›ë³¸ ë°ì´í„° (ì´ {row_count:,}ê±´) ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œê°„", f"{load_time:.4f} ì´ˆ")
    st.caption("ì´ëŠ” 15ë§Œ ê±´ì— ê°€ê¹Œìš´ íŠ¸ëœì­ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ ë‚´ì— ì²˜ë¦¬í•  ìˆ˜ ìˆìŒì„ ì‹¤ì¦í•©ë‹ˆë‹¤.")
    
    st.divider()

    # --- 2. AI ëª¨ë¸ ì„±ëŠ¥ (MAPE) - ìë™ ì‹¤í–‰ ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 2: AI ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì‹ ë¢°ë„ (ë°±í…ŒìŠ¤íŒ…) ğŸ§ ")
    st.markdown("""
    Prophet ëª¨ë¸ì„ **ì´ˆê¸° 5ê°œì›” ë°ì´í„°ë¡œ í›ˆë ¨**í•˜ê³ , ì´í›„ ê¸°ê°„ì˜ ì‹¤ì œ íŒë§¤ëŸ‰ê³¼ ë¹„êµí•©ë‹ˆë‹¤.
    """)

    test_days_input = st.number_input(
        "ê²€ì¦ ê¸°ê°„(ì¼) ì„ íƒ", 
        min_value=7, max_value=60, value=30,
        help="ë°ì´í„°ì…‹ì˜ ë§ˆì§€ë§‰ Nì¼ì„ 'ê²€ì¦ìš©(ì‹¤ì œê°’)'ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
    )

    # [ìˆ˜ì •] ë²„íŠ¼ ì—†ì´, ì…ë ¥ê°’ ë³€ê²½ ì‹œ ìë™ ì‹¤í–‰
    with st.spinner(f"ëª¨ë¸ì„ ê²€ì¦í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... (í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_days_input}ì¼) â³"):
        # 'df_csv' ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°±í…ŒìŠ¤íŒ… í˜¸ì¶œ
        mape, fig, msg = run_prophet_backtesting(df_csv, test_days=test_days_input)
    
    # [ìˆ˜ì •] ê²°ê³¼ë¥¼ ìë™ í‘œì‹œ (st.button ë¸”ë¡ ì œê±°)
    if mape is not None:
        st.metric("ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ í‰ê·  ì˜¤ì°¨ìœ¨ (MAPE)", f"{mape:.2f} %")
        st.caption(f"**(ì—°êµ¬ ê²°ê³¼ í•´ì„)** ëª¨ë¸ì€ í–¥í›„ {test_days_input}ì¼ì„ ì˜ˆì¸¡í•  ë•Œ **í‰ê·  ì•½ {mape:.2f}%ì˜ ì˜¤ì°¨**ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.")
        # [UX ì°¸ê³ ] Plotlyë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ìœ ì¼í•œ ì°¨íŠ¸ì´ë¯€ë¡œ, Matplotlib í†µí•© ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
        st.pyplot(fig) 
    else:
        st.error(f"ê²€ì¦ ì‹¤íŒ¨: {msg}")
            
    st.divider()

    # --- 3. ì‹¤ìš©ì  ë¹„ìš© ëª¨ë¸ ì„¤ê³„ (Cost Model) ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 3: ì‹¤ìš©ì  ë¹„ìš© ëª¨ë¸ ì„¤ê³„ (Trade-off ë¶„ì„) ğŸ’°")
    st.markdown("""
    ì¸í„°ë·° ê²°ê³¼(ë¹„ìš© ë¯¼ê°ë„)ì™€ ê¸°ìˆ ì  ì‹¤ì¦(AI ë¹„ìš©)ì„ í† ëŒ€ë¡œ, ë³¸ ì—°êµ¬ëŠ” 2ê°€ì§€ ìƒìš©í™” ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    """)
    col1, col2 = st.columns(2)
    with col1:
        st.info("**A. ê¸°ë³¸í˜• (ì›” $35-50 ê³ ì •ë¹„)**")
        st.markdown("""
        * **í¬í•¨:** ì¬ê³  ê´€ë¦¬, ë°ì´í„° ì§‘ê³„, BOM/ROP ê³„ì‚°
        * **ëŒ€ìƒ:** ë¹„ìš©ì— ê·¹ë„ë¡œ ë¯¼ê°í•˜ë©°, ìš´ì˜ ìë™í™”ê°€ ìµœìš°ì„ ì¸ ì¹´í˜
        """)
    with col2:
        st.warning("**B. AI í™•ì¥í˜• (ì›” $50 + ë³€ë™ë¹„)**")
        st.markdown("""
        * **í¬í•¨:** ê¸°ë³¸í˜• + AI ë¹„ì„œ (OpenAI), ìˆ˜ìš” ì˜ˆì¸¡ (Prophet)
        * **ëŒ€ìƒ:** ë§ˆì¼€íŒ…, ì‹ ë©”ë‰´ ê°œë°œ ë“± ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•œ ì¹´í˜
        """)
    st.caption("ì´ëŠ” ì†Œìƒê³µì¸ì´ ìì‹ ì˜ ì˜ˆì‚°ê³¼ í•„ìš”ì— ë§ì¶° í•©ë¦¬ì ì¸ DX(ë””ì§€í„¸ ì „í™˜)ë¥¼ ì„ íƒí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì‹¤ìš©ì ì¸ ì„¤ê³„ì•ˆì…ë‹ˆë‹¤.")
# ==============================================================
# â“ ë„ì›€ë§
# ==============================================================
# ==============================================================
# â“ ë„ì›€ë§
# ==============================================================
else:  # menu == "ë„ì›€ë§"
    st.header("â˜•ï¸ ì»¤í”¼ ì›ë‘ ì¬ê³ ê´€ë¦¬ íŒŒì´í”„ë¼ì¸ ì‰½ê²Œ ì´í•´í•˜ê¸°")
    
    st.markdown("""
> **â€œì»¤í”¼ ì›ë‘ê°€ ì–´ë–»ê²Œ ë“¤ì–´ì˜¤ê³ , ì–¼ë§ˆë‚˜ ì“°ì´ê³ , ì–¸ì œ ë‹¤ì‹œ ì£¼ë¬¸ë¼ì•¼ í•˜ëŠ”ì§€ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ì!â€** ì—‘ì…€ ëŒ€ì‹  ERPê°€ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì¤ë‹ˆë‹¤.
""")

    # ------------------------------------------------------------------
    # âœ… (ì¶”ê°€ë¨) ì›¹ì‚¬ì´íŠ¸ ì‚¬ìš©ë²• ì„¹ì…˜
    # ------------------------------------------------------------------
    st.subheader("ğŸ“š ì›¹ì‚¬ì´íŠ¸ ì‚¬ìš©ë²• ê°€ì´ë“œ: ë©”ë‰´ë³„ í•µì‹¬ ê¸°ëŠ¥")
    st.markdown("---")
    
    st.markdown("""
    ë³¸ ëŒ€ì‹œë³´ë“œëŠ” **ë°ì´í„° í™•ì¸**, **ì¬ê³ /ì›ê°€ ê´€ë¦¬**, **ê±°ë˜ ì…ë ¥/ìˆ˜ì •**, **AI ë¶„ì„**ì˜ ë„¤ ê°€ì§€ ì˜ì—­ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.
    
    ### 1. ğŸ“Š ë°ì´í„° í™•ì¸ ë° ë¶„ì„
    
    | ë©”ë‰´ | ëª©ì  | ì£¼ìš” í‘œì‹œ í•­ëª© |
    | :--- | :--- | :--- |
    | **ê²½ì˜ í˜„í™©** | ì „ì²´ ì´ê´„ ìš”ì•½ (ë§¤ì¶œì•¡, íŒë§¤ ê±´ìˆ˜) | ì´ ë§¤ì¶œ, ê±´ë‹¹ í‰ê·  ë§¤ì¶œ, ì¹´í…Œê³ ë¦¬ë³„/ì¼ìë³„ ë§¤ì¶œ ì¶”ì´ |
    | **ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ** | ì£¼ìš” ë§¤ì¶œ ì¶”ì„¸ íŒŒì•… | ì›”ë³„/ì¹´í…Œê³ ë¦¬ë³„ ëˆ„ì  ë§¤ì¶œ, ìƒí’ˆ êµ¬ì¡°ë³„ (íŠ¸ë¦¬ë§µ) ë§¤ì¶œ ê¸°ì—¬ë„ |
    | **ê¸°ê°„ë³„ ë¶„ì„** | íŠ¹ì • ê¸°ê°„ì˜ íŒë§¤ íŠ¹ì„± ë¶„ì„ | ìš”ì¼ë³„ ë§¤ì¶œ (ë°” ì°¨íŠ¸), ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ ì¶”ì´ (ë¼ì¸ ì°¨íŠ¸) |
    | **ê±°ë˜ ë‚´ì—­** | ì›ì²œ ë°ì´í„° ì¡°íšŒ | í•„í„°ë§/ê²€ìƒ‰ ê¸°ëŠ¥ìœ¼ë¡œ íŠ¹ì • ê¸°ê°„, ìƒí’ˆì˜ ê±°ë˜ ë‚´ì—­ í™•ì¸ |
    
    ---
    
    ### 2. âš™ï¸ ê´€ë¦¬ ë° í¸ì§‘
    
    | ë©”ë‰´ | ëª©ì  | ì£¼ìš” ì‘ì—… |
    | :--- | :--- | :--- |
    | **ê±°ë˜ ì¶”ê°€** | ì‹ ê·œ íŒë§¤ ê±°ë˜ ì…ë ¥ | ì¹´í…Œê³ ë¦¬/íƒ€ì…/ìƒì„¸ ì„ íƒ í›„ ìˆ˜ëŸ‰/ë‹¨ê°€ ì…ë ¥ â†’ **ì¬ê³  ìë™ ì°¨ê°** |
    | **ë°ì´í„° í¸ì§‘** | ê¸°ì¡´ ê±°ë˜ ìˆ˜ì •/ì‚­ì œ | Firebase ë°ì´í„° ìˆ˜ì •/ì‚­ì œ, **ìˆ˜ëŸ‰ ë³€ê²½ ì‹œ ì¬ê³  ìë™ ì¡°ì •** |
    | **ì¬ê³  ê´€ë¦¬** | ì¬ë£Œ/ë©”ë‰´ ë§ˆìŠ¤í„° ë° ë ˆì‹œí”¼(BOM) ê´€ë¦¬ | ì¬ë£Œ/ì›ê°€/í˜„ì¬ ì¬ê³  ìˆ˜ê¸° ì…ë ¥, ë©”ë‰´ë³„ ë ˆì‹œí”¼ ë“±ë¡ ë° ìˆ˜ì • |
    
    ---
    
    ### 3. ğŸ¤– AI ê¸°ë°˜ ì˜ì‚¬ ê²°ì •
    
    | ë©”ë‰´ | ëª©ì  | ì£¼ìš” ì œê³µ ê¸°ëŠ¥ |
    | :--- | :--- | :--- |
    | **AI ë¹„ì„œ** | ë°ì´í„° ê¸°ë°˜ ì‹¤í–‰ ì¡°ì–¸ ì œê³µ | **ì¬ê³  ìœ„í—˜**, **ë§ˆì§„ ë¶„ì„**, **íŒë§¤ íŒ¨í„´** ë“± 3ëŒ€ ë¦¬í¬íŠ¸ ë° ì§ˆì˜ì‘ë‹µ |
    | **ì¬ê³  ê´€ë¦¬** (ë ˆì‹œí”¼ íƒ­) | ë©”ë‰´ ì œì¡°ì— í•„ìš”í•œ ì¬ë£Œì˜ ì ì • ë°œì£¼ëŸ‰ ê³„ì‚° | AI ì˜ˆì¸¡ ê¸°ë°˜ **ê¶Œì¥ ë°œì£¼ëŸ‰, ì»¤ë²„ ì¼ìˆ˜, ROP(ë°œì£¼ì )** ê³„ì‚° ë° ì°¨íŠ¸ ì œê³µ |
    
    """)
    # ------------------------------------------------------------------
    # ------------------------------------------------------------------
    
    
    # [AI/ML í†µí•© ìˆ˜ì •] ë„ì›€ë§ ë‚´ìš© ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ERP íŒŒì´í”„ë¼ì¸)
    st.markdown("## ğŸ“Š ERP íŒŒì´í”„ë¼ì¸ ì‘ë™ ì›ë¦¬")
    st.markdown("""
### 1. (ML) ìŠ¤ë§ˆíŠ¸ ë°œì£¼ ë¡œì§ (ì¬ê³  ê´€ë¦¬ íƒ­)
| ë‹¨ê³„ | í•˜ëŠ” ì¼ |
| --- | --- |
| **1. ìˆ˜ìš” ì˜ˆì¸¡** | Prophet (ML)ì´ "ì•„ë©”ë¦¬ì¹´ë…¸"ì˜ **ë¯¸ë˜ 21ì¼** íŒë§¤ëŸ‰ì„ [500ì”]ìœ¼ë¡œ ì˜ˆì¸¡ |
| **2. ì†Œì§„ëŸ‰ ê³„ì‚°** | [500ì”] x [ë ˆì‹œí”¼: ì”ë‹¹ 20g] = **[10,000g]** (ì˜ˆìƒ ì´ ì†Œì§„ëŸ‰) |
| **3. ê¶Œì¥ ë°œì£¼ëŸ‰** | [10,000g] - [í˜„ì¬ ì¬ê³ : 3,000g] = **[7,000g]** (ê¶Œì¥ ë°œì£¼ëŸ‰) |
| **4. ROP (ë°œì£¼ì )** | (ì¼í‰ê· ì†Œì§„ * ë¦¬ë“œíƒ€ì„) + ì•ˆì „ì¬ê³ . ì´ë³´ë‹¤ ì¬ê³ ê°€ ë‚®ìœ¼ë©´ **'ğŸš¨ ë°œì£¼ìš”ë§'** ì•Œë¦¼ |
### 2. (AI) ë§ˆì¼€íŒ… ë³´ì¡° (AI ë¹„ì„œ íƒ­)
| ê¸°ëŠ¥ | ì„¤ëª… |
| --- | --- |
| **ìš”ì²­ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±** | í˜„ì¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ì „ëµ, í™ë³´ ë¬¸êµ¬ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤. |
| **ìš´ì˜ ë³´ê³ ** | ì¼ì¼ ë§¤ì¶œ, íŒë§¤ ê±´ìˆ˜ ë“±ì„ ìš”ì•½í•˜ì—¬ ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. |
### 3. ê¸°ë³¸ ë°ì´í„° íë¦„
| ë‹¨ê³„ | í•˜ëŠ” ì¼ |
| --- | --- |
| **1. ì›ë‘ ì…ê³ ** | 'ì¬ê³  ê´€ë¦¬' > 'ì¬ë£Œ/ì›ê°€ ë§ˆìŠ¤í„°'ì—ì„œ [+10,000g] ìˆ˜ë™ ì…ë ¥ ë° ì €ì¥ |
| **2. íŒë§¤ ë°œìƒ** | 'ê±°ë˜ ì¶”ê°€' íƒ­ ë˜ëŠ” POSì—ì„œ 'ì•„ë©”ë¦¬ì¹´ë…¸' 1ì” íŒë§¤ (Firestore 'coffee_sales'ì— ê¸°ë¡) |
| **3. ìë™ ì°¨ê°** | ì‹œìŠ¤í…œì´ 'ì•„ë©”ë¦¬ì¹´ë…¸' ë ˆì‹œí”¼(BOM)ë¥¼ ì¡°íšŒí•˜ì—¬ [ì›ë‘: 20g] ì‚¬ìš© í™•ì¸ |
| **4. ì¬ê³  ë°˜ì˜** | 'inventory' DBì˜ 'ì›ë‘' ì¬ê³ ë¥¼ [-20g] ìë™ ì°¨ê° (ì¬ê³  ì´ë™ ë¡œê·¸ ê¸°ë¡) |
""")