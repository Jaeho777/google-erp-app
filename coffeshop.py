# ==============================================================
# â˜• Coffee ERP Dashboard â€” Company Showcase Edition (Tone-Down Blue)
#  - ì¬ê³  ê´€ë¦¬(ìë™ ì°¨ê°/ì„ê³„ì¹˜ ê²½ê³ /ìë™ ë°œì£¼ ì‹œë®¬ë ˆì´ì…˜)
#  - UI í•œê¸€í™”(ì´ë¦„ ë§¤í•‘ + ìš”ì¼ í•œê¸€ í‘œì‹œ)
#  - ì›ë³¸/FirestoreëŠ” ì˜ì–´ ì €ì¥, í™”ë©´ì€ í•œê¸€ í‘œì‹œ(ì •/ì—­ë§¤í•‘)
#  - ë°ì´í„° í¸ì§‘(ê±°ë˜ ìˆ˜ì •/ì‚­ì œ + ì¬ê³  ì¼ê´„ìˆ˜ì •)
#  - ë„ì›€ë§ íƒ­ + SKU íŒŒë¼ë¯¸í„°(ë¦¬ë“œíƒ€ì„/ì„¸ì´í”„í‹°/ëª©í‘œì¼ìˆ˜/ë ˆì‹œí”¼g) + ROP ì§€í‘œ/ê¶Œì¥ë°œì£¼
#  - NEW: ë ˆì‹œí”¼(BOM) ê¸°ë°˜ ìë™ ì°¨ê°, uom(ë‹¨ìœ„) ì§€ì›, ì‹¤ì‚¬/ì˜¤ì°¨ìœ¨, ë°œì£¼ Â±ë²”ìœ„ í‘œì‹œ
# ==============================================================

import os
import re
import warnings
from math import ceil
from pathlib import Path
from datetime import datetime

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.io as pio

import firebase_admin
from firebase_admin import credentials, firestore

# --- Pylance/static analyzer guards (no runtime effect) ---
items = []  # type: ignore
sold_qty = 0  # type: ignore
summary = []  # type: ignore

# ----------------------
# 0ï¸âƒ£ ê²½ë¡œ/ìƒìˆ˜ (íŒ€ì›ì´ ì–´ë””ì„œ ë°›ì•„ë„ ë™ì‘)
# ----------------------
BASE_DIR = Path(__file__).resolve().parent

# st.secrets ì—†ì„ ë•Œë„ ì•ˆì „
try:
    SECRETS = dict(st.secrets)
except Exception:
    SECRETS = {}

def _resolve_path(val, default: Path) -> Path:
    """ìƒëŒ€ê²½ë¡œë©´ BASE_DIR ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜"""
    if not val:
        return default
    p = Path(str(val))
    return p if p.is_absolute() else (BASE_DIR / p)

DATA_DIR   = _resolve_path(SECRETS.get("DATA_DIR")   or os.environ.get("ERP_DATA_DIR"),   BASE_DIR / "data")
ASSETS_DIR = _resolve_path(SECRETS.get("ASSETS_DIR") or os.environ.get("ERP_ASSETS_DIR"), BASE_DIR / "assets")
KEYS_DIR   = _resolve_path(SECRETS.get("KEYS_DIR")   or os.environ.get("ERP_KEYS_DIR"),   BASE_DIR / "keys")

CSV_PATH     = DATA_DIR / "Coffee Shop Sales.csv"
PIPELINE_IMG = ASSETS_DIR / "pipeline_diagram.png"
SA_FILE_PATH = KEYS_DIR / "serviceAccount.json"

SALES_COLLECTION      = "coffee_sales"
INVENTORY_COLLECTION  = "inventory"
ORDERS_COLLECTION     = "orders"
SKU_PARAMS_COLLECTION = "sku_params"

# ---- [NEW] ë ˆì‹œí”¼/ì‹¤ì‚¬ ì»¬ë ‰ì…˜ ----
RECIPES_COLLECTION      = "recipes"        # ë©”ë‰´ SKU -> [ {ingredient_en, qty, uom, waste_pct} ]
STOCK_COUNTS_COLLECTION = "stock_counts"   # ì‹¤ì‚¬ ê¸°ë¡: {sku_en, count, uom, counted_at}
STOCK_MOVES_COLLECTION  = "stock_moves"    # ì¬ê³  ì´ë™ ë¡œê·¸: íŒë§¤/ì‹œë®¬/ì…ê³  ë“±

USE_KRW_CONVERSION = False   # CSVê°€ USDë©´ Trueë¡œ
KRW_PER_USD = 1350

DEFAULT_INITIAL_STOCK   = 10000
REORDER_THRESHOLD_RATIO = 0.15  # 15%

# ë””ë ‰í† ë¦¬ ì¤€ë¹„
for p in (DATA_DIR, ASSETS_DIR, KEYS_DIR):
    p.mkdir(parents=True, exist_ok=True)

# ----------------------
# 0-1ï¸âƒ£ Firebase ì´ˆê¸°í™” (Secrets â†’ keys/ â†’ GOOGLE_APPLICATION_CREDENTIALS)
# ----------------------
def init_firestore():
    if firebase_admin._apps:
        return firestore.client()

    # 1) st.secrets ë”•ì…”ë„ˆë¦¬(ê¶Œì¥)
    svc_dict = SECRETS.get("firebase_service_account")
    if isinstance(svc_dict, dict) and svc_dict:
        cred = credentials.Certificate(svc_dict)
        firebase_admin.initialize_app(cred)
        return firestore.client()

    # 2) keys/serviceAccount.json
    if SA_FILE_PATH.exists():
        cred = credentials.Certificate(str(SA_FILE_PATH))
        firebase_admin.initialize_app(cred)
        return firestore.client()

    # 3) GOOGLE_APPLICATION_CREDENTIALS (íŒŒì¼ ê²½ë¡œ)
    gac = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if gac and Path(gac).expanduser().exists():
        firebase_admin.initialize_app()
        return firestore.client()

    # 4) ì „ë¶€ ì‹¤íŒ¨ â†’ ëª…ì‹œì ìœ¼ë¡œ ì—ëŸ¬
    st.error(
        "Firebase ìê²©ì¦ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:\n"
        "â€¢ st.secrets['firebase_service_account'] ë”•ì…”ë„ˆë¦¬\n"
        "â€¢ keys/serviceAccount.json íŒŒì¼\n"
        "â€¢ í™˜ê²½ë³€ìˆ˜ GOOGLE_APPLICATION_CREDENTIALS=ìê²©ì¦ëª…íŒŒì¼ê²½ë¡œ"
    )
    st.stop()

db = init_firestore()

# ----------------------
# 0-2ï¸âƒ£ UI/ìŠ¤íƒ€ì¼
# ----------------------
st.set_page_config(page_title="â˜• Coffee ERP Dashboard", layout="wide")
pio.templates.default = "plotly_white"
px.defaults.template = "plotly_white"
px.defaults.color_continuous_scale = "Blues"

st.markdown("""
    <style>
    .stApp { background-color: #F4F6FA; font-family: 'Pretendard','Noto Sans KR',sans-serif; }
    .dashboard-header { display:flex; align-items:center; gap:12px; background:#1E2A38; color:#fff;
                        padding:15px 25px; border-radius:10px; margin-bottom:25px; }
    .metric-card { background:#fff; border-radius:16px; padding:25px;
                   box-shadow:0 4px 12px rgba(0,0,0,0.06); text-align:center; transition:all .3s; }
    .metric-card:hover { transform: translateY(-3px); box-shadow:0 6px 14px rgba(0,0,0,0.12); }
    .metric-title { color:#7C8DA6; font-size:1em; }
    .metric-value { color:#2C3E50; font-size:1.8em; font-weight:600; }
    section[data-testid="stSidebar"] { background:#fff !important; color:#0D3B66 !important; }
    label[data-baseweb="radio"] div { color:#0D3B66 !important; font-weight:500; }
    .js-plotly-plot .plotly { background:transparent !important; }
    </style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="dashboard-header">
  <h1>â˜• Coffee ERP Dashboard</h1>
</div>
""", unsafe_allow_html=True)

# ----------------------
# 0-3ï¸âƒ£ í•œê¸€ ë§¤í•‘ í…Œì´ë¸”
# ----------------------
category_map = {
    "Coffee": "ì»¤í”¼", "Tea": "ì°¨", "Bakery": "ë² ì´ì»¤ë¦¬",
    "Coffee beans": "ì›ë‘", "Drinking Chocolate": "ì´ˆì½”ìŒë£Œ",
    "Equipment": "ì¥ë¹„", "Extras": "ê¸°íƒ€",
    "Branded": "ë¸Œëœë“œ ìƒí’ˆ",
    "Flavours": "í”Œë ˆì´ë²„(ì‹œëŸ½)",
    "Flavors": "í”Œë ˆì´ë²„(ì‹œëŸ½)",
    "Loose Tea": "ìì°¨",
    "Loose-Leaf Tea": "ìì°¨",
    "Packaged Chocolate": "í¬ì¥ ì´ˆì½œë¦¿",
}
rev_category_map = {v: k for k, v in category_map.items()}
rev_category_map.update({
    "ë² ì´ì»¤ë¦¬": "Bakery",
    "ì›ë‘": "Coffee beans",
    "ì°¨": "Tea",
    "ì´ˆì½”ìŒë£Œ": "Drinking Chocolate",
    "ì»¤í”¼": "Coffee",
})

type_map = {
    "Barista Espresso": "ë°”ë¦¬ìŠ¤íƒ€ ì—ìŠ¤í”„ë ˆì†Œ",
    "Biscotti": "ë¹„ìŠ¤ì½”í‹°",
    "Brewed Black tea": "í™ì°¨(ë¸Œë£¨ë“œ)",
    "Brewed Chai tea": "ì°¨ì´ í‹°(ë¸Œë£¨ë“œ)",
    "Brewed Green tea": "ë…¹ì°¨(ë¸Œë£¨ë“œ)",
    "Brewed herbal tea": "í—ˆë¸Œí‹°(ë¸Œë£¨ë“œ)",
    "Chai tea": "ì°¨ì´ í‹°",
    "Clothing": "ì˜ë¥˜",
    "Drinking Chocolate": "ì´ˆì½”ìŒë£Œ",
    "Drip coffee": "ë“œë¦½ ì»¤í”¼",
    "Espresso Beans": "ì—ìŠ¤í”„ë ˆì†Œ ì›ë‘",
    "Gourmet Beans": "ê³ ê¸‰ ì›ë‘",
    "Gourmet brewed coffee": "ê³ ê¸‰ ë¸Œë£¨ë“œ ì»¤í”¼",
    "Green beans": "ìƒë‘",
    "Herbal tea": "í—ˆë¸Œí‹°",
    "House blend Beans": "í•˜ìš°ìŠ¤ ë¸”ë Œë“œ ì›ë‘",
    "Housewares": "ìƒí™œìš©í’ˆ",
    "Organic Beans": "ìœ ê¸°ë† ì›ë‘",
    "Organic Chocolate": "ìœ ê¸°ë† ì´ˆì½œë¦¿",
    "Organic brewed coffee": "ìœ ê¸°ë† ë¸Œë£¨ë“œ ì»¤í”¼",
    "Premium brewed coffee": "í”„ë¦¬ë¯¸ì—„ ë¸Œë£¨ë“œ ì»¤í”¼",
    "Premium Beans": "í”„ë¦¬ë¯¸ì—„ ì›ë‘",
    "Regular syrup": "ì¼ë°˜ ì‹œëŸ½",
    "Sugar free syrup": "ë¬´ì„¤íƒ• ì‹œëŸ½",
    "Pastry": "í˜ì´ìŠ¤íŠ¸ë¦¬",
    "Scone": "ìŠ¤ì½˜",
    "Hot chocolate": "í•«ì´ˆì½”",
    "Green tea": "ë…¹ì°¨",
    "Black tea": "í™ì°¨",
    "Americano": "ì•„ë©”ë¦¬ì¹´ë…¸",
    "Latte": "ë¼ë–¼",
    "Espresso": "ì—ìŠ¤í”„ë ˆì†Œ",
    "Cappuccino": "ì¹´í‘¸ì¹˜ë…¸",
    "Mocha": "ëª¨ì¹´",
    "Flat White": "í”Œë«í™”ì´íŠ¸",
    "Premium beans": "í”„ë¦¬ë¯¸ì—„ ì›ë‘",
    "Regular Syrup": "ì¼ë°˜ ì‹œëŸ½",
    "Sugar Free Syrup": "ë¬´ì„¤íƒ• ì‹œëŸ½",
    "Organic Brewed Coffee": "ìœ ê¸°ë† ë¸Œë£¨ë“œ ì»¤í”¼",
    "Premium Brewed Coffee": "í”„ë¦¬ë¯¸ì—„ ë¸Œë£¨ë“œ ì»¤í”¼",
}
rev_type_map = {v: k for k, v in type_map.items()}

SIZE_SUFFIX_MAP = {"Lg": "ë¼ì§€", "Rg": "ë ˆê·¤ëŸ¬", "Sm": "ìŠ¤ëª°"}
REV_SIZE_SUFFIX_MAP = {"ë¼ì§€": "Lg", "ë ˆê·¤ëŸ¬": "Rg", "ìŠ¤ëª°": "Sm"}

detail_base_map = {
    "Almond Croissant": "ì•„ëª¬ë“œ í¬ë£¨ì•„ìƒ",
    "Brazilian": "ë¸Œë¼ì§ˆ",
    "Brazilian - Organic": "ë¸Œë¼ì§ˆ ìœ ê¸°ë†",
    "Cappuccino": "ì¹´í‘¸ì¹˜ë…¸",
    "Carmel syrup": "ì¹´ë¼ë©œ ì‹œëŸ½",
    "Caramel syrup": "ì¹´ë¼ë©œ ì‹œëŸ½",
    "Chili Mayan": "ì¹ ë¦¬ ë§ˆì•¼",
    "Chocolate Chip Biscotti": "ì´ˆì½”ì¹© ë¹„ìŠ¤ì½”í‹°",
    "Chocolate Croissant": "ì´ˆì½œë¦¿ í¬ë£¨ì•„ìƒ",
    "Chocolate syrup": "ì´ˆì½œë¦¿ ì‹œëŸ½",
    "Civet Cat": "ì½”í”¼ ë£¨ì™",
    "Columbian Medium Roast": "ì½œë¡¬ë¹„ì•„ ë¯¸ë””ì—„ ë¡œìŠ¤íŠ¸",
    "Colombian Medium Roast": "ì½œë¡¬ë¹„ì•„ ë¯¸ë””ì—„ ë¡œìŠ¤íŠ¸",
    "Cranberry Scone": "í¬ëœë² ë¦¬ ìŠ¤ì½˜",
    "Croissant": "í¬ë£¨ì•„ìƒ",
    "Dark chocolate": "ë‹¤í¬ ì´ˆì½œë¦¿",
    "Earl Grey": "ì–¼ê·¸ë ˆì´",
    "English Breakfast": "ì‰ê¸€ë¦¬ì‹œ ë¸Œë ‰í¼ìŠ¤íŠ¸",
    "Espresso Roast": "ì—ìŠ¤í”„ë ˆì†Œ ë¡œìŠ¤íŠ¸",
    "Espresso shot": "ì—ìŠ¤í”„ë ˆì†Œ ìƒ·",
    "Ethiopia": "ì—í‹°ì˜¤í”¼ì•„",
    "Ginger Biscotti": "ì§„ì € ë¹„ìŠ¤ì½”í‹°",
    "Ginger Scone": "ì§„ì € ìŠ¤ì½˜",
    "Guatemalan Sustainably Grown": "ê³¼í…Œë§ë¼ ì§€ì†ê°€ëŠ¥ ì¬ë°°",
    "Hazelnut Biscotti": "í—¤ì´ì¦ë„› ë¹„ìŠ¤ì½”í‹°",
    "Hazelnut syrup": "í—¤ì´ì¦ë„› ì‹œëŸ½",
    "I Need My Bean! Diner mug": "I Need My Bean! ë‹¤ì´ë„ˆ ë¨¸ê·¸",
    "I Need My Bean! Latte cup": "I Need My Bean! ë¼ë–¼ ì»µ",
    "I Need My Bean! T-shirt": "I Need My Bean! í‹°ì…”ì¸ ",
    "Jamacian Coffee River": "ìë©”ì´ì¹´ ì»¤í”¼ ë¦¬ë²„",
    "Jamaican Coffee River": "ìë©”ì´ì¹´ ì»¤í”¼ ë¦¬ë²„",
    "Jumbo Savory Scone": "ì ë³´ ì„¸ì´ë³´ë¦¬ ìŠ¤ì½˜",
    "Latte": "ë¼ë–¼",
    "Lemon Grass": "ë ˆëª¬ê·¸ë¼ìŠ¤",
    "Morning Sunrise Chai": "ëª¨ë‹ ì„ ë¼ì´ì¦ˆ ì°¨ì´",
    "Oatmeal Scone": "ì˜¤íŠ¸ë°€ ìŠ¤ì½˜",
    "Organic Decaf Blend": "ìœ ê¸°ë† ë””ì¹´í˜ì¸ ë¸”ë Œë“œ",
    "Our Old Time Diner Blend": "ì•„ì›Œ ì˜¬ë“œ íƒ€ì„ ë‹¤ì´ë„ˆ ë¸”ë Œë“œ",
    "Ouro Brasileiro shot": "ì˜¤ìš°ë¡œ ë¸Œë¼ì§ˆ ìƒ·",
    "Peppermint": "í˜í¼ë¯¼íŠ¸",
    "Primo Espresso Roast": "í”„ë¦¬ëª¨ ì—ìŠ¤í”„ë ˆì†Œ ë¡œìŠ¤íŠ¸",
    "Scottish Cream Scone": "ìŠ¤ì½”í‹°ì‹œ í¬ë¦¼ ìŠ¤ì½˜",
    "Serenity Green Tea": "ì„¸ë ˆë‹ˆí‹° ê·¸ë¦° í‹°",
    "Spicy Eye Opener Chai": "ìŠ¤íŒŒì´ì‹œ ì•„ì´ ì˜¤í”„ë„ˆ ì°¨ì´",
    "Sugar Free Vanilla syrup": "ë¬´ì„¤íƒ• ë°”ë‹ë¼ ì‹œëŸ½",
    "Sustainably Grown Organic": "ì§€ì†ê°€ëŠ¥ ìœ ê¸°ë†",
    "Traditional Blend Chai": "íŠ¸ë˜ë””ì…”ë„ ë¸”ë Œë“œ ì°¨ì´",
}
rev_detail_base_map = {v: k for k, v in detail_base_map.items()}

def to_korean_detail(name: str) -> str:
    s = str(name).strip()
    if re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s):
        return s
    m = re.search(r"\s+(Lg|Rg|Sm)$", s)
    size_en = m.group(1) if m else None
    base_en = s[: -len(size_en) - 1] if size_en else s
    base_ko = detail_base_map.get(base_en, base_en)
    if size_en:
        return f"{base_ko} ({SIZE_SUFFIX_MAP[size_en]})"
    return base_ko

def from_korean_detail(display: str) -> str:
    s = str(display).strip()
    if re.search(r"\s+(Lg|Rg|Sm)$", s):
        return s
    m = re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s)
    size_ko = m.group(1) if m else None
    base_ko = re.sub(r"\s*\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", "", s)
    base_en = rev_detail_base_map.get(base_ko, base_ko)
    if size_ko:
        return f"{base_en} {REV_SIZE_SUFFIX_MAP[size_ko]}"
    return base_en

weekday_map = {"Monday": "ì›”", "Tuesday": "í™”", "Wednesday": "ìˆ˜",
               "Thursday": "ëª©", "Friday": "ê¸ˆ", "Saturday": "í† ", "Sunday": "ì¼"}
weekday_order_kr = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]

def map_series(s: pd.Series, mapping: dict) -> pd.Series:
    return s.apply(lambda x: mapping.get(x, x))

# ----------------------
# âœ… UoM(ë‹¨ìœ„) ìœ í‹¸
# ----------------------
def normalize_uom(u: str | None) -> str:
    u = (u or "ea").strip().lower()
    if u in {"g", "gram", "grams", "ê·¸ë¨", "kg", "í‚¬ë¡œê·¸ë¨"}:
        return "g"
    if u in {"ml", "ë°€ë¦¬ë¦¬í„°", "l", "ë¦¬í„°"}:
        return "ml"
    return "ea"

def convert_qty(qty: float, from_uom: str, to_uom: str) -> float:
    """kgâ†”g, lâ†”ml ë³€í™˜. ê·¸ ì™¸ëŠ” ë™ì¼ ë‹¨ìœ„ë¡œ ê°„ì£¼.
    (ì…ë ¥ì€ g/ml/eaë§Œ ì“°ëŠ” ê²ƒì„ ê¶Œì¥)
    """
    fu = normalize_uom(from_uom)
    tu = normalize_uom(to_uom)
    if fu == tu:
        return float(qty)
    # ë°€ë„ ì—†ì´ gâ†”ml ë³€í™˜ì€ ë¶ˆê°€ â†’ ë‹¨ìœ„ ë‹¤ë¥´ë©´ ë³€í™˜í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë°˜í™˜
    return float(qty)

def safe_float(x, default=0.0):
    """
    Robust float parser.
    - Returns `default` if x is None, empty, or NaN.
    - Does NOT cast `default` to float (so default can be None).
    """
    # Fast-path for explicit None
    if x is None:
        return default
    try:
        # Numbers (handle NaN)
        if isinstance(x, (int, float)):
            try:
                if pd.isna(x):
                    return default
            except Exception:
                pass
            return float(x)
        # Strings
        if isinstance(x, str):
            s = x.strip()
            if s == "" or s.lower() in {"nan", "none"}:
                return default
            s = s.replace(",", "")
            return float(s)
        # Fallback: attempt cast
        return float(x)
    except Exception:
        return default

# ----------------------
# âœ… ë‚ ì§œ íŒŒì„œ: ëª…ì‹œ í˜•ì‹ ìš°ì„  + ê²½ê³ ì—†ëŠ” í´ë°±
# ----------------------
def parse_mixed_dates(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip()
    out = pd.Series(pd.NaT, index=s.index, dtype="datetime64[ns]")
    patterns = [
        (r'^\d{4}-\d{2}-\d{2}$', '%Y-%m-%d'),
        (r'^\d{4}/\d{2}/\d{2}$', '%Y/%m/%d'),
        (r'^\d{2}/\d{2}/\d{4}$', '%m/%d/%Y'),
        (r'^\d{2}-\d{2}-\d{4}$', '%m-%d-%Y'),
        (r'^\d{4}\.\d{2}\.\d{2}$', '%Y.%m.%d'),
        (r'^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}$', '%Y-%m-%d %H:%M:%S'),
        (r'^\d{2}/\d{2}/\d{4}\s+\d{2}:\d{2}:\d{2}$', '%m/%d/%Y %H:%M:%S'),
    ]
    for pat, fmt in patterns:
        mask = s.str.match(pat)
        if mask.any():
            out.loc[mask] = pd.to_datetime(s.loc[mask], format=fmt, errors='coerce')
    remain = out.isna()
    if remain.any():
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", UserWarning)
            out.loc[remain] = pd.to_datetime(s.loc[remain], errors='coerce')
    return out

# ----------------------
# 1ï¸âƒ£ CSV ë¡œë“œ (ìƒ˜í”Œ ìƒì„± ì—†ìŒ)
# ----------------------
@st.cache_data(ttl=0)
def load_csv(path: Path) -> pd.DataFrame:
    if not path.exists():
        st.error(f"CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì— 'Coffee Shop Sales.csv'ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\n(í˜„ì¬ ì°¾ëŠ” ê²½ë¡œ: {path})")
        st.stop()
    df = pd.read_csv(path)
    df = df.rename(columns={
        'transaction_id': 'ê±°ë˜ë²ˆí˜¸', 'transaction_date': 'ë‚ ì§œ', 'transaction_time': 'ì‹œê°„',
        'transaction_qty': 'ìˆ˜ëŸ‰', 'store_id': 'ê°€ê²ŒID', 'store_location': 'ê°€ê²Œìœ„ì¹˜',
        'product_id': 'ìƒí’ˆID', 'unit_price': 'ë‹¨ê°€', 'product_category': 'ìƒí’ˆì¹´í…Œê³ ë¦¬',
        'product_type': 'ìƒí’ˆíƒ€ì…', 'product_detail': 'ìƒí’ˆìƒì„¸', 'Revenue': 'ìˆ˜ìµ'
    })
    df['ìˆ˜ìµ'] = df['ìˆ˜ìµ'].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
    df['ë‹¨ê°€'] = df['ë‹¨ê°€'].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
    if USE_KRW_CONVERSION:
        df['ìˆ˜ìµ'] *= KRW_PER_USD
        df['ë‹¨ê°€'] *= KRW_PER_USD

    # âœ… ê²½ê³  ì—†ëŠ” ë‚ ì§œ íŒŒì‹±
    df['ë‚ ì§œ'] = parse_mixed_dates(df['ë‚ ì§œ'])

    if 'ì‹œê°„' in df.columns:
        df['ì‹œ'] = pd.to_datetime(df['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df['ì‹œ'] = None

    df['ìš”ì¼'] = df['ë‚ ì§œ'].dt.day_name()
    df['ì›”'] = df['ë‚ ì§œ'].dt.month
    return df

df_csv = load_csv(CSV_PATH)

# ----------------------
# 2ï¸âƒ£ Firestore(íŒë§¤) ë¡œë“œ
# ----------------------
def load_sales_from_firestore() -> pd.DataFrame:
    docs = db.collection(SALES_COLLECTION).stream()
    data = [d.to_dict() for d in docs]
    df_fb = pd.DataFrame(data)
    if df_fb.empty:
        return df_fb

    # âœ… ê²½ê³  ì—†ëŠ” ë‚ ì§œ íŒŒì‹±
    if 'ë‚ ì§œ' in df_fb.columns:
        df_fb['ë‚ ì§œ'] = parse_mixed_dates(df_fb['ë‚ ì§œ'])

    if 'ìˆ˜ìµ' in df_fb.columns:
        df_fb['ìˆ˜ìµ'] = pd.to_numeric(df_fb['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_fb.columns:
        df_fb['ë‹¨ê°€'] = pd.to_numeric(df_fb['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_fb.columns:
        df_fb['ìˆ˜ëŸ‰'] = pd.to_numeric(df_fb['ìˆ˜ëŸ‰'], errors='coerce')

    if 'ì‹œê°„' in df_fb.columns:
        df_fb['ì‹œ'] = pd.to_datetime(df_fb['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df_fb['ì‹œ'] = None

    df_fb['ìš”ì¼'] = df_fb['ë‚ ì§œ'].dt.day_name()
    df_fb['ì›”'] = df_fb['ë‚ ì§œ'].dt.month
    return df_fb

df_fb = load_sales_from_firestore()

# ê±°ë˜ í¸ì§‘ìš©: ë¬¸ì„œ ID í¬í•¨ ë¡œë”
def load_sales_with_id():
    docs = db.collection(SALES_COLLECTION).stream()
    rows = []
    for d in docs:
        rec = d.to_dict()
        rec["_id"] = d.id
        rows.append(rec)
    df_raw = pd.DataFrame(rows)
    if df_raw.empty:
        return df_raw, df_raw

    # âœ… ê²½ê³  ì—†ëŠ” ë‚ ì§œ íŒŒì‹±
    if 'ë‚ ì§œ' in df_raw.columns:
        df_raw['ë‚ ì§œ'] = parse_mixed_dates(df_raw['ë‚ ì§œ'])

    if 'ìˆ˜ìµ' in df_raw: df_raw['ìˆ˜ìµ'] = pd.to_numeric(df_raw['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_raw: df_raw['ë‹¨ê°€'] = pd.to_numeric(df_raw['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_raw: df_raw['ìˆ˜ëŸ‰'] = pd.to_numeric(df_raw['ìˆ˜ëŸ‰'], errors='coerce')

    df_view = df_raw.copy()
    if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df_view: df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
    if 'ìƒí’ˆíƒ€ì…' in df_view: df_view['ìƒí’ˆíƒ€ì…'] = map_series(df_view['ìƒí’ˆíƒ€ì…'], type_map)
    if 'ìƒí’ˆìƒì„¸' in df_view: df_view['ìƒí’ˆìƒì„¸'] = df_view['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)
    return df_raw, df_view

# ----------------------
# 3ï¸âƒ£ CSV + Firebase í†µí•© â†’ í™”ë©´í‘œì‹œìš© í•œê¸€í™”
# ----------------------
df = pd.concat([df_csv, df_fb], ignore_index=True)
if 'ìš”ì¼' in df.columns:
    df['ìš”ì¼'] = map_series(df['ìš”ì¼'], weekday_map)
if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df.columns:
    df['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
if 'ìƒí’ˆíƒ€ì…' in df.columns:
    df['ìƒí’ˆíƒ€ì…'] = map_series(df['ìƒí’ˆíƒ€ì…'], type_map)
if 'ìƒí’ˆìƒì„¸' in df.columns:
    df['ìƒí’ˆìƒì„¸'] = df['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)

# ----------------------
# 4ï¸âƒ£ ê³µìš© ìœ í‹¸
# ----------------------
def safe_rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    elif hasattr(st, "experimental_rerun"):
        st.experimental_rerun()

def format_krw(x: float) -> str:
    try:
        return f"{x:,.0f} ì›"
    except Exception:
        return "-"

# ---- ë‹¨ìœ„ ìœ í‹¸ ----
VALID_UOM = {"ea","g","kg","ml","l"}
UOM_SYNONYM = {
    "piece":"ea","pcs":"ea","unit":"ea","units":"ea",
    "gram":"g","grams":"g","gms":"g",
    "kilogram":"kg","kilograms":"kg",
    "milliliter":"ml","millilitre":"ml","milliliters":"ml","millilitres":"ml",
    "liter":"l","litre":"l","liters":"l","litres":"l",
}

def normalize_uom(u: str) -> str:
    if not u:
        return "ea"
    s = str(u).strip().lower()
    s = UOM_SYNONYM.get(s, s)
    if s not in VALID_UOM:
        return s  # ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ìœ„ë„ ê·¸ëŒ€ë¡œ ìœ ì§€
    return s

def convert_qty(qty: float, from_uom: str, to_uom: str) -> float:
    try:
        q = float(qty)
    except Exception:
        return 0.0
    f = normalize_uom(from_uom)
    t = normalize_uom(to_uom)
    if f == t:
        return q
    # g <-> kg
    if f == "g" and t == "kg":
        return q / 1000.0
    if f == "kg" and t == "g":
        return q * 1000.0
    # ml <-> l
    if f == "ml" and t == "l":
        return q / 1000.0
    if f == "l" and t == "ml":
        return q * 1000.0
    # ìƒì´í•œ/ë¹„ë³€í™˜ ë‹¨ìœ„ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜ (ìƒí™©ì— ë”°ë¼ ê³ ë„í™” ê°€ëŠ¥)
    return q

# (ê¸°ì¡´) ìµœì†Œ ë³´ì¥ ì¸ë²¤í† ë¦¬ ë¬¸ì„œ
# â†’ NEW ensure_inventory_docë¡œ ëŒ€ì²´ë¨

def ensure_inventory_doc(product_detail_en: str, uom: str | None = None, is_ingredient: bool | None = None):
    """ì¸ë²¤í† ë¦¬ ë¬¸ì„œ ë³´ì¥ + uom/is_ingredient ê´€ë¦¬"""
    ref = db.collection(INVENTORY_COLLECTION).document(product_detail_en)
    doc = ref.get()
    if not doc.exists:
        ref.set({
            "ìƒí’ˆìƒì„¸_en": product_detail_en,
            "ì´ˆê¸°ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "í˜„ì¬ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "uom": normalize_uom(uom or "ea"),
            "is_ingredient": bool(is_ingredient) if is_ingredient is not None else False,
        })
        return ref
    # ê¸°ì¡´ ë¬¸ì„œ ì—…ë°ì´íŠ¸
    patch = {}
    data = doc.to_dict() or {}
    if "uom" not in data or uom:
        patch["uom"] = normalize_uom(uom or data.get("uom", "ea"))
    if is_ingredient is not None and data.get("is_ingredient") != bool(is_ingredient):
        patch["is_ingredient"] = bool(is_ingredient)
    if patch:
        ref.update(patch)
    return ref

# ì¬ë£Œ í”Œë˜ê·¸ ì „ìš© í—¬í¼
def ensure_ingredient_sku(ingredient_en: str, uom: str = "ea"):
    return ensure_inventory_doc(ingredient_en, uom=uom, is_ingredient=True)
    

# (êµ¬ë²„ì „) ë‹¨ìˆœ ì°¨ê°: ë©”ë‰´ìì²´ë¥¼ eaë¡œ ì°¨ê°
def deduct_stock(product_detail_en: str, qty: int):
    ref = ensure_inventory_doc(product_detail_en)
    snap = ref.get()
    data = snap.to_dict() if snap.exists else {}
    init_stock = int(data.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    cur_stock = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    new_stock = max(cur_stock - int(qty), 0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return init_stock, new_stock

# ---- SKU ì¸ë²¤í† ë¦¬ ë¡œë“œ(uom í¬í•¨) ----
def load_inventory_df() -> pd.DataFrame:
    inv_docs = db.collection(INVENTORY_COLLECTION).stream()
    rows = []
    for d in inv_docs:
        doc = d.to_dict() or {}
        en  = doc.get("ìƒí’ˆìƒì„¸_en", d.id)
        ko  = to_korean_detail(en)
        rows.append({
            "ìƒí’ˆìƒì„¸_en": en,
            "ìƒí’ˆìƒì„¸": ko,
            "ì´ˆê¸°ì¬ê³ ": doc.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "í˜„ì¬ì¬ê³ ": doc.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "uom": normalize_uom(doc.get("uom", "ea")),
            "is_ingredient": bool(doc.get("is_ingredient", False)),
        })
    return pd.DataFrame(rows)


# ---- [NEW] ë ˆì‹œí”¼ ë¡œë”©/ì €ì¥ ----

def get_all_recipe_ingredients() -> set:
    """ë ˆì‹œí”¼ì— ë“±ì¥í•˜ëŠ” ëª¨ë“  ingredient_en ì§‘í•©"""
    try:
        docs = db.collection(RECIPES_COLLECTION).stream()
    except Exception:
        return set()
    S = set()
    for d in docs:
        items = (d.to_dict() or {}).get("items", []) or []
        for it in items:
            ing = str(it.get("ingredient_en", "")).strip()
            if ing:
                S.add(ing)
    return S

# ---- [NEW] ë ˆì‹œí”¼ ë¡œë”©/ì €ì¥ ----
def load_recipe(menu_sku_en: str) -> list[dict]:
    doc = db.collection(RECIPES_COLLECTION).document(menu_sku_en).get()
    if not doc.exists:
        return []
    items = doc.to_dict().get("items", [])
    out = []
    for it in items:
        out.append({
            "ingredient_en": str(it.get("ingredient_en", "")).strip(),
            "qty": safe_float(it.get("qty", 0.0)),
            "uom": normalize_uom(it.get("uom", "ea")),
            "waste_pct": safe_float(it.get("waste_pct", 0.0))
        })
    return out

def upsert_recipe_item(menu_sku_en: str, ingredient_en: str, qty: float, uom: str = "ea", waste_pct: float = 0.0):
    """ë ˆì‹œí”¼ í•­ëª© 1ê°œ ì¶”ê°€/ê°±ì‹  (ë™ì¼ ingredient_en ìˆìœ¼ë©´ êµì²´)"""
    ref = db.collection(RECIPES_COLLECTION).document(menu_sku_en)
    snap = ref.get()
    items = []
    if snap.exists:
        items = snap.to_dict().get("items", []) or []
        items = [it for it in items if str(it.get("ingredient_en")) != ingredient_en]
    items.append({
        "ingredient_en": ingredient_en,
        "qty": safe_float(qty),
        "uom": normalize_uom(uom),
        "waste_pct": safe_float(waste_pct),
    })
    ref.set({"menu_sku_en": menu_sku_en, "items": items})
    # ì¬ë£Œ í”Œë˜ê·¸ ë³´ì¥
    ensure_ingredient_sku(ingredient_en, uom=uom)


def load_recipe(menu_sku_en: str) -> list[dict]:
    try:
        doc = db.collection(RECIPES_COLLECTION).document(menu_sku_en).get()
        if not doc.exists:
            return []
        data = doc.to_dict() or {}
        raw_items = data.get("items", []) or []
        out: list[dict] = []
        for it in raw_items:
            ing = str(it.get("ingredient_en", "")).strip()
            if not ing:
                continue
            qty = safe_float(it.get("qty"), 0.0)
            uom = normalize_uom(it.get("uom", "ea"))
            waste = safe_float(it.get("waste_pct", 0.0), 0.0)
            out.append({
                "ingredient_en": ing,
                "qty": qty,
                "uom": uom,
                "waste_pct": waste,
            })
        return out
    except Exception:
        return []


# ---- [NEW] ì¬ê³  ì°¨ê°(ë‹¨ìœ„ ì¸ì§€) ----
def deduct_inventory(ingredient_en: str, qty: float, uom: str):
    """ingredient_en ì¸ë²¤í† ë¦¬ì—ì„œ qty(uom)ë§Œí¼ ì°¨ê°"""
    ref = ensure_inventory_doc(ingredient_en, uom=uom)
    snap = ref.get()
    data = snap.to_dict() or {}
    cur = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    inv_uom = normalize_uom(data.get("uom", "ea"))
    use_qty = convert_qty(qty, from_uom=uom, to_uom=inv_uom)
    new_stock = max(cur - use_qty, 0.0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return cur, new_stock, inv_uom

# ---- [NEW] ë ˆì‹œí”¼ ê¸°ë°˜ ì°¨ê° ----
def apply_recipe_deduction(menu_sku_en: str, sold_qty: int, commit: bool = True) -> list[dict]:
    """
    ë©”ë‰´ íŒë§¤ì‹œ: ë ˆì‹œí”¼ ìˆìœ¼ë©´ ì¬ë£Œë³„ ì°¨ê°, ì—†ìœ¼ë©´ ë©”ë‰´ ìì²´ ì°¨ê°.
    commit=Falseë©´ ì¬ê³ ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  ì˜ˆìƒ afterë§Œ ê³„ì‚°.
    ë°˜í™˜: [{"ingredient_en", "used", "uom", "before", "after"}...]
    """
    items = load_recipe(menu_sku_en)
    summary: list[dict] = []

    if not items:
        # ë ˆì‹œí”¼ ì—†ìœ¼ë©´ ë©”ë‰´ ìì²´ë¥¼ 'ea'ë¡œ ì²˜ë¦¬
        ref = ensure_inventory_doc(menu_sku_en, uom="ea")
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used = float(sold_qty)
        after = max(before - used, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": menu_sku_en, "used": used, "uom": inv_uom, "before": before, "after": after})
        return summary

    for it in items:
        ing  = it["ingredient_en"]
        uom  = it["uom"]
        base = safe_float(it["qty"])
        w    = safe_float(it["waste_pct"]) / 100.0
        need = sold_qty * base * (1.0 + w)

        # ì¸ë²¤í† ë¦¬ ì½ê¸°
        ref = ensure_inventory_doc(ing, uom=uom)
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        use_qty = convert_qty(need, from_uom=uom, to_uom=inv_uom)
        after = max(before - use_qty, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": ing, "used": use_qty, "uom": inv_uom, "before": before, "after": after})
    return summary

def log_stock_move(menu_sku_en: str, qty: int, details: list[dict], move_type: str = "sale", note: str | None = None):
    """ì¬ê³  ì´ë™ ë¡œê·¸ ê¸°ë¡ (ìƒì„¸ëŠ” ingredient ë‹¨ìœ„)."""
    try:
        db.collection(STOCK_MOVES_COLLECTION).add({
            "ts": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "type": move_type,
            "menu_sku_en": menu_sku_en,
            "menu_sku_ko": to_korean_detail(menu_sku_en),
            "qty": int(qty),
            "details": details,
            "note": note or "",
        })
    except Exception:
        # ë¡œê¹… ì‹¤íŒ¨ëŠ” ì•± ë™ì‘ì— ì˜í–¥ ì£¼ì§€ ì•ŠìŒ
        pass
def adjust_inventory_by_recipe(menu_sku_en: str, diff_qty: int, move_type: str, note: str = "") -> None:
    """
    ìˆ˜ëŸ‰ ì¦ê°(diff_qty)ì— ë”°ë¼ ë ˆì‹œí”¼ ê¸°ë°˜ìœ¼ë¡œ ì¬ê³ ë¥¼ ì¦/ì°¨ê°.
    diff_qty > 0 â†’ ì¶”ê°€ ì°¨ê°(íŒë§¤ ì¦ê°€), diff_qty < 0 â†’ ë³µì›(íŒë§¤ ê°ì†Œ/ì‚­ì œ)
    """
    if diff_qty == 0:
        return
    ded_summary = apply_recipe_deduction(menu_sku_en, int(diff_qty), commit=True)
    log_stock_move(menu_sku_en, int(diff_qty), ded_summary, move_type=move_type, note=note)

# ---------- SKU íŒŒë¼ë¯¸í„° ë¡œë” (ë‹¨ì¼ ì •ì˜; ë©”ë‰´ ë¶„ê¸° ì‹œì‘ ì „) ----------
def load_sku_params_df() -> pd.DataFrame:
    """Firestore 'sku_params' ì»¬ë ‰ì…˜ì„ DataFrameìœ¼ë¡œ ë¡œë“œí•˜ê³  ê¸°ë³¸ê°’/íƒ€ì…ì„ ë³´ì •."""
    try:
        docs = db.collection(SKU_PARAMS_COLLECTION).stream()
    except Exception:
        docs = []

    rows = []
    for d in docs:
        item = d.to_dict() or {}
        # ë¬¸ì„œ idë„ ë³´ì¡´
        try:
            item["_id"] = d.id
        except Exception:
            item["_id"] = item.get("_id", "")
        rows.append(item)

    dfp = pd.DataFrame(rows)
    if dfp.empty:
        dfp = pd.DataFrame(columns=[
            "_id","sku_en","lead_time_days","safety_stock_units","target_days","grams_per_cup","expiry_days"
        ])

    defaults = {
        "lead_time_days": 3,
        "safety_stock_units": 10,
        "target_days": 21,
        "grams_per_cup": 18.0,
        "expiry_days": 28,
    }
    for col, default in defaults.items():
        if col not in dfp.columns:
            dfp[col] = default
        else:
            dfp[col] = pd.to_numeric(dfp[col], errors="coerce").fillna(default)

    return dfp


# ---------- ì¬ë£Œ ROP/ê¶Œì¥ë°œì£¼ ê³„ì‚° (ë‹¨ì¼ ì •ì˜; ë©”ë‰´ ë¶„ê¸° ì‹œì‘ ì „) ----------
def compute_ingredient_metrics_for_menu(
    menu_sku_en: str,
    df_all_sales: pd.DataFrame,
    df_inv: pd.DataFrame,
    df_params: pd.DataFrame,
    window_days: int = 28
) -> pd.DataFrame:
    """
    íŠ¹ì • ë©”ë‰´ì˜ ë ˆì‹œí”¼ì™€ ìµœê·¼ íŒë§¤ëŸ‰(ìœˆë„ìš°) ê¸°ë°˜ìœ¼ë¡œ ì¬ë£Œë³„
    ì¼í‰ê· ì†Œì§„/ì»¤ë²„ì¼ìˆ˜/ROP/ê¶Œì¥ë°œì£¼ë¥¼ ê³„ì‚°.
    ë°˜í™˜ ì»¬ëŸ¼:
      ["ìƒí’ˆìƒì„¸","sku_en","í˜„ì¬ì¬ê³ ","ì´ˆê¸°ì¬ê³ ","uom","ìµœê·¼ì†Œì§„í•©","ì¼í‰ê· ì†Œì§„","ì»¤ë²„ì¼ìˆ˜",
       "lead_time_days","safety_stock_units","target_days","ROP","ê¶Œì¥ë°œì£¼","ìƒíƒœ"]
    """
    items = load_recipe(menu_sku_en)
    if not items:
        return pd.DataFrame()

    # íŒë§¤ ìœˆë„ìš° ì¶”ì¶œ
    if "ë‚ ì§œ" in df_all_sales.columns and pd.api.types.is_datetime64_any_dtype(df_all_sales["ë‚ ì§œ"]):
        max_day = df_all_sales["ë‚ ì§œ"].max()
        min_day = max_day - pd.Timedelta(days=window_days - 1)
        df_win = df_all_sales[(df_all_sales["ë‚ ì§œ"] >= min_day) & (df_all_sales["ë‚ ì§œ"] <= max_day)].copy()
    else:
        df_win = df_all_sales.copy()

    # ë©”ë‰´ ì˜ì–´í‚¤ ë§¤í•‘
    df_win = df_win.copy()
    if "ìƒí’ˆìƒì„¸" in df_win.columns:
        df_win["sku_en"] = df_win["ìƒí’ˆìƒì„¸"].apply(from_korean_detail)
    else:
        df_win["sku_en"] = ""

    # ëŒ€ìƒ ë©”ë‰´ íŒë§¤ìˆ˜ëŸ‰ í•©ê³„
    df_win["ìˆ˜ëŸ‰"] = pd.to_numeric(df_win.get("ìˆ˜ëŸ‰", 0), errors="coerce").fillna(0)
    sold_sum = df_win.loc[df_win["sku_en"].eq(menu_sku_en), "ìˆ˜ëŸ‰"].sum()

    # ì¬ë£Œë³„ ìµœê·¼ì†Œì§„í•©(ë ˆì‹œí”¼Ã—íŒë§¤)
    rows = []
    for it in items:
        ing  = it.get("ingredient_en", "")
        base = safe_float(it.get("qty", 0), 0)
        w    = safe_float(it.get("waste_pct", 0), 0) / 100.0
        need = sold_sum * base * (1 + w)
        rows.append({"sku_en": ing, "ìµœê·¼ì†Œì§„í•©": need, "uom_src": it.get("uom", "ea")})
    use_df = pd.DataFrame(rows)

    # ì¸ë²¤í† ë¦¬ ê²°í•© (ë ˆì‹œí”¼ ì¬ë£Œë§Œ)
    base = df_inv.rename(columns={"ìƒí’ˆìƒì„¸_en": "sku_en"}).copy()
    base = base.merge(use_df, on="sku_en", how="right")

    # ë‹¨ìœ„ ë³€í™˜: recipe uom -> inventory uom
    base["uom"] = base["uom"].apply(normalize_uom)
    base["uom_src"] = base["uom_src"].apply(normalize_uom)
    base["ìµœê·¼ì†Œì§„í•©"] = base.apply(
        lambda r: convert_qty(r["ìµœê·¼ì†Œì§„í•©"], from_uom=r["uom_src"], to_uom=r["uom"]),
        axis=1
    )

    days = max(window_days, 1)
    base["ì¼í‰ê· ì†Œì§„"] = (base["ìµœê·¼ì†Œì§„í•©"] / days).round(3)
    base.loc[base["ì¼í‰ê· ì†Œì§„"].eq(0), "ì¼í‰ê· ì†Œì§„"] = 0.01  # 0 division ë°©ì§€
    base["ì»¤ë²„ì¼ìˆ˜"] = (base["í˜„ì¬ì¬ê³ "] / base["ì¼í‰ê· ì†Œì§„"]).round(1)

    # íŒŒë¼ë¯¸í„° ê²°í•© + ê¸°ë³¸ê°’
    base = base.merge(df_params, on="sku_en", how="left")
    base["lead_time_days"] = pd.to_numeric(base.get("lead_time_days", 3), errors="coerce").fillna(3).astype(int)
    base["safety_stock_units"] = pd.to_numeric(base.get("safety_stock_units", 10), errors="coerce").fillna(10).astype(int)
    base["target_days"] = pd.to_numeric(base.get("target_days", 21), errors="coerce").fillna(21).astype(int)

    # ROP/ê¶Œì¥ë°œì£¼/ìƒíƒœ
    base["ROP"] = (base["ì¼í‰ê· ì†Œì§„"] * base["lead_time_days"] + base["safety_stock_units"]).round(0).astype(int)
    base["ê¶Œì¥ë°œì£¼"] = ((base["target_days"] * base["ì¼í‰ê· ì†Œì§„"]) - base["í˜„ì¬ì¬ê³ "]).apply(lambda x: max(int(ceil(x)), 0))
    base["ìƒíƒœ"] = base.apply(lambda r: "ë°œì£¼ìš”ë§" if r["í˜„ì¬ì¬ê³ "] <= r["ROP"] else "ì •ìƒ", axis=1)

    # í‘œì‹œëª…
    base["ìƒí’ˆìƒì„¸"] = base["sku_en"].apply(to_korean_detail)

    cols = ["ìƒí’ˆìƒì„¸","sku_en","í˜„ì¬ì¬ê³ ","ì´ˆê¸°ì¬ê³ ","uom","ìµœê·¼ì†Œì§„í•©","ì¼í‰ê· ì†Œì§„","ì»¤ë²„ì¼ìˆ˜",
            "lead_time_days","safety_stock_units","target_days","ROP","ê¶Œì¥ë°œì£¼","ìƒíƒœ"]
    for c in cols:
        if c not in base.columns:
            base[c] = None

    return base[cols].sort_values(["ìƒíƒœ","ì»¤ë²„ì¼ìˆ˜"])


# ê³µí†µ width ì„¤ì •
W = "stretch"

# ----------------------
# 5ï¸âƒ£ ì‚¬ì´ë“œë°” ë©”ë‰´
# ----------------------
menu = st.sidebar.radio(
    " ë©”ë‰´ ì„ íƒ",
    ["ê²½ì˜ í˜„í™©", "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ", "ê¸°ê°„ë³„ ë¶„ì„", "ê±°ë˜ ì¶”ê°€", "ì¬ê³  ê´€ë¦¬", "ë°ì´í„° í¸ì§‘", "ê±°ë˜ ë‚´ì—­", "ë„ì›€ë§"]
)

# ==============================================================
# ğŸ§¾ ê±°ë˜ ì¶”ê°€
# ==============================================================
if menu == "ê±°ë˜ ì¶”ê°€":
    st.header(" ê±°ë˜ ë°ì´í„° ì¶”ê°€")

    category_options = sorted(pd.Series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬']).dropna().unique().tolist())
    type_options = sorted(pd.Series(df['ìƒí’ˆíƒ€ì…']).dropna().unique().tolist())
    detail_options = sorted(pd.Series(df['ìƒí’ˆìƒì„¸']).dropna().unique().tolist())

    with st.form("add_transaction"):
        col1, col2 = st.columns(2)
        with col1:
            ë‚ ì§œ = st.date_input("ë‚ ì§œ", value=datetime.now().date())
            ìƒí’ˆì¹´í…Œê³ ë¦¬_ko = st.selectbox("ìƒí’ˆì¹´í…Œê³ ë¦¬", category_options)
            ìƒí’ˆíƒ€ì…_ko = st.selectbox("ìƒí’ˆíƒ€ì…", type_options)
        with col2:
            ìƒí’ˆìƒì„¸_ko = st.selectbox("ìƒí’ˆìƒì„¸", detail_options)
            ìˆ˜ëŸ‰ = st.number_input("ìˆ˜ëŸ‰", min_value=1, value=1)
            ë‹¨ê°€ = st.number_input("ë‹¨ê°€(ì›)", min_value=0.0, value=1000.0, step=100.0)

        ìˆ˜ìµ = ìˆ˜ëŸ‰ * ë‹¨ê°€
        st.markdown(f"### ğŸ’° ê³„ì‚°ëœ ìˆ˜ìµ: **{format_krw(ìˆ˜ìµ)}**")

        submitted = st.form_submit_button("ë°ì´í„° ì¶”ê°€")
        if submitted:
            ìƒí’ˆì¹´í…Œê³ ë¦¬_en = rev_category_map.get(ìƒí’ˆì¹´í…Œê³ ë¦¬_ko, ìƒí’ˆì¹´í…Œê³ ë¦¬_ko)
            ìƒí’ˆíƒ€ì…_en = rev_type_map.get(ìƒí’ˆíƒ€ì…_ko, ìƒí’ˆíƒ€ì…_ko)
            ìƒí’ˆìƒì„¸_en = from_korean_detail(ìƒí’ˆìƒì„¸_ko)

            new_doc = {
                "ë‚ ì§œ": str(ë‚ ì§œ),
                "ì‹œê°„": datetime.now().strftime("%H:%M:%S"),
                "ìƒí’ˆì¹´í…Œê³ ë¦¬": ìƒí’ˆì¹´í…Œê³ ë¦¬_en,
                "ìƒí’ˆíƒ€ì…": ìƒí’ˆíƒ€ì…_en,
                "ìƒí’ˆìƒì„¸": ìƒí’ˆìƒì„¸_en,
                "ìˆ˜ëŸ‰": int(ìˆ˜ëŸ‰),
                "ë‹¨ê°€": float(ë‹¨ê°€),
                "ìˆ˜ìµ": float(ìˆ˜ìµ)
            }
            db.collection(SALES_COLLECTION).add(new_doc)

            # âœ… ë ˆì‹œí”¼ ìë™ ë³´ì¥ í›„, ë ˆì‹œí”¼ ê¸°ë°˜ ì°¨ê°(ì—†ìœ¼ë©´ ë©”ë‰´ ìì²´ ì°¨ê°)
            try:
                # ê¸°ë³¸ ë ˆì‹œí”¼ ìë™ ë³´ì¥
                _auto_defaults = {
                    "Latte": [
                        {"ingredient_en": "Espresso Roast", "qty": 18, "uom": "g", "waste_pct": 0},
                        {"ingredient_en": "Milk", "qty": 300, "uom": "ml", "waste_pct": 5},
                        {"ingredient_en": "Regular syrup", "qty": 5, "uom": "ml", "waste_pct": 0},
                    ]
                }
                doc = db.collection(RECIPES_COLLECTION).document(ìƒí’ˆìƒì„¸_en).get()
                if not doc.exists and ìƒí’ˆìƒì„¸_en in _auto_defaults:
                    db.collection(RECIPES_COLLECTION).document(ìƒí’ˆìƒì„¸_en).set({
                        "menu_sku_en": ìƒí’ˆìƒì„¸_en,
                        "items": _auto_defaults[ìƒí’ˆìƒì„¸_en]
                    })
                    for it in _auto_defaults[ìƒí’ˆìƒì„¸_en]:
                        ensure_inventory_doc(it["ingredient_en"], uom=it["uom"])
            except Exception:
                pass

            ded_summary = apply_recipe_deduction(ìƒí’ˆìƒì„¸_en, int(ìˆ˜ëŸ‰), commit=True)
            # ì´ë™ ë¡œê·¸ ê¸°ë¡
            log_stock_move(ìƒí’ˆìƒì„¸_en, int(ìˆ˜ëŸ‰), ded_summary, move_type="sale")
            msg_lines = []
            for s in ded_summary:
                msg_lines.append(f"- {to_korean_detail(s['ingredient_en'])}: {s['used']:.2f}{s['uom']} â†’ ì”ì—¬ {s['after']:.2f}/{s['before']:.2f}")
            st.success("âœ… ê±°ë˜ ì €ì¥ ë° ì¬ê³  ì°¨ê° ì™„ë£Œ!\n" + "\n".join(msg_lines))
            st.balloons()
            safe_rerun()

# ==============================================================
# ğŸ“ˆ ê²½ì˜ í˜„í™©
# ==============================================================
elif menu == "ê²½ì˜ í˜„í™©":
    st.header("ğŸ“ˆ ê²½ì˜ í˜„í™© ìš”ì•½")

    if PIPELINE_IMG.exists():
        st.image(str(PIPELINE_IMG), caption="ERP íŒŒì´í”„ë¼ì¸: ì…ê³  â†’ ì¬ê³  â†’ íŒë§¤ â†’ ë°œì£¼ â†’ ì¬ì…ê³ ")
    else:
        st.caption("")

    total_rev = pd.to_numeric(df['ìˆ˜ìµ'], errors='coerce').sum()
    total_tx = len(df)
    total_qty = pd.to_numeric(df['ìˆ˜ëŸ‰'], errors='coerce').sum()

    col1, col2, col3 = st.columns(3)
    col1.markdown(f"<div class='metric-card'><p class='metric-title'>ì´ ë§¤ì¶œì•¡</p><p class='metric-value'>{format_krw(total_rev)}</p></div>", unsafe_allow_html=True)
    col2.markdown(f"<div class='metric-card'><p class='metric-title'>ì´ ê±°ë˜ ìˆ˜</p><p class='metric-value'>{int(total_tx):,} ê±´</p></div>", unsafe_allow_html=True)
    col3.markdown(f"<div class='metric-card'><p class='metric-title'>ì´ íŒë§¤ ìˆ˜ëŸ‰</p><p class='metric-value'>{int(total_qty):,} ê°œ</p></div>", unsafe_allow_html=True)

    st.markdown("---")
    if not df.empty:
        try:
            top_cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
            top_prod = df.groupby('ìƒí’ˆíƒ€ì…')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
            st.info(f"ğŸ† ê°€ì¥ ë§¤ì¶œ ë†’ì€ ì¹´í…Œê³ ë¦¬: **{top_cat.index[0]}** ({format_krw(top_cat.iloc[0])}) / ìƒí’ˆ: **{top_prod.index[0]}**")
        except Exception:
            st.info("ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ìƒìœ„ í•­ëª©ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        col4, col5 = st.columns(2)
        with col4:
            cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().reset_index()
            fig_cat = px.pie(cat, values='ìˆ˜ìµ', names='ìƒí’ˆì¹´í…Œê³ ë¦¬', title="ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ë¹„ì¤‘")
            st.plotly_chart(fig_cat, width=W)
        with col5:
            daily = df.groupby('ë‚ ì§œ')['ìˆ˜ìµ'].sum().reset_index()
            fig_trend = px.line(daily, x='ë‚ ì§œ', y='ìˆ˜ìµ', title="ì¼ìë³„ ë§¤ì¶œ ì¶”ì´")
            st.plotly_chart(fig_trend, width=W)

# ==============================================================
# ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ
# ==============================================================
elif menu == "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ":
    st.header("ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ")

    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        col1, col2 = st.columns(2)
        monthly = df.groupby(df['ë‚ ì§œ'].dt.to_period("M"))['ìˆ˜ìµ'].sum().reset_index()
        monthly['ë‚ ì§œ'] = monthly['ë‚ ì§œ'].dt.to_timestamp()

        with col1:
            fig_month = px.bar(monthly, x='ë‚ ì§œ', y='ìˆ˜ìµ', title="ì›”ë³„ ë§¤ì¶œ")
            st.plotly_chart(fig_month, width=W)

        with col2:
            cat_sales = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().reset_index()
            fig_cat2 = px.bar(cat_sales, x='ìƒí’ˆì¹´í…Œê³ ë¦¬', y='ìˆ˜ìµ', title="ìƒí’ˆ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ")
            st.plotly_chart(fig_cat2, width=W)

        prod_sales = df.groupby(['ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸'])['ìˆ˜ìµ'].sum().reset_index()
        fig_sun = px.sunburst(prod_sales, path=['ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸'], values='ìˆ˜ìµ', title="ìƒí’ˆ êµ¬ì¡°ë³„ ë§¤ì¶œ")
        st.plotly_chart(fig_sun, width=W)

# ==============================================================
# ğŸ“… ê¸°ê°„ë³„ ë¶„ì„
# ==============================================================
elif menu == "ê¸°ê°„ë³„ ë¶„ì„":
    st.header("ğŸ“… ê¸°ê°„ë³„ ë§¤ì¶œ ë¶„ì„")

    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df_week = df.groupby('ìš”ì¼')['ìˆ˜ìµ'].sum().reset_index()
        df_week['ìš”ì¼'] = pd.Categorical(df_week['ìš”ì¼'], categories=weekday_order_kr, ordered=True)
        df_week = df_week.sort_values('ìš”ì¼')

        df_hour = df.groupby('ì‹œ')['ìˆ˜ìµ'].sum().reset_index()
        df_month = df.groupby('ì›”')['ìˆ˜ìµ'].sum().reset_index()

        try:
            top_day = df_week.loc[df_week['ìˆ˜ìµ'].idxmax()]
            top_hour = df_hour.loc[df_hour['ìˆ˜ìµ'].idxmax()]
            top_month = df_month.loc[df_month['ìˆ˜ìµ'].idxmax()]
        except Exception:
            top_day = {"ìš”ì¼": "-"}
            top_hour = {"ì‹œ": "-"}
            top_month = {"ì›”": "-"}

        col1, col2, col3 = st.columns(3)
        col1.markdown(f"<div class='metric-card'><p class='metric-title'>ìµœê³  ë§¤ì¶œ ìš”ì¼</p><p class='metric-value'>{top_day['ìš”ì¼']}</p></div>", unsafe_allow_html=True)
        col2.markdown(f"<div class='metric-card'><p class='metric-title'>ìµœê³  ë§¤ì¶œ ì‹œê°„</p><p class='metric-value'>{top_hour['ì‹œ']}ì‹œ</p></div>", unsafe_allow_html=True)
        col3.markdown(f"<div class='metric-card'><p class='metric-title'>ìµœê³  ë§¤ì¶œ ë‹¬</p><p class='metric-value'>{top_month['ì›”']}ì›”</p></div>", unsafe_allow_html=True)

        st.markdown("---")
        colA, colB = st.columns(2)
        with colA:
            fig_w = px.bar(df_week, x='ìš”ì¼', y='ìˆ˜ìµ', title="ìš”ì¼ë³„ ë§¤ì¶œ")
            st.plotly_chart(fig_w, width=W)
        with colB:
            fig_h = px.line(df_hour, x='ì‹œ', y='ìˆ˜ìµ', title="ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ")
            st.plotly_chart(fig_h, width=W)
        fig_m = px.bar(df_month, x='ì›”', y='ìˆ˜ìµ', title="ì›”ë³„ ë§¤ì¶œ")
        st.plotly_chart(fig_m, width=W)

elif menu == "ì¬ê³  ê´€ë¦¬":

    st.header("ğŸ“¦ ì¬ê³  ê´€ë¦¬ í˜„í™©")

    # ===== ì¬ê³  ì´ˆê¸°í™” =====
    with st.expander("ğŸ§¹ ì¬ê³  ë°ì´í„° ì´ˆê¸°í™” ê¸°ëŠ¥"):
        st.warning("âš ï¸ ëª¨ë“  ì¬ê³ ì˜ 'ì´ˆê¸°ì¬ê³ 'ì™€ 'í˜„ì¬ì¬ê³ 'ë¥¼ ê¸°ë³¸ê°’(10000)ìœ¼ë¡œ ë˜ëŒë¦½ë‹ˆë‹¤. ë³µêµ¬ ë¶ˆê°€í•˜ë‹ˆ ì£¼ì˜í•˜ì„¸ìš”.")
        if st.button("ì¬ê³  ë°ì´í„° ì´ˆê¸°í™” ì‹¤í–‰", type="primary"):
            try:
                inv_docs = db.collection(INVENTORY_COLLECTION).stream()
                count = 0
                for d in inv_docs:
                    ref = db.collection(INVENTORY_COLLECTION).document(d.id)
                    ref.update({
                        "ì´ˆê¸°ì¬ê³ ": DEFAULT_INITIAL_STOCK,
                        "í˜„ì¬ì¬ê³ ": DEFAULT_INITIAL_STOCK
                    })
                    count += 1
                st.success(f"âœ… ì´ {count}ê°œì˜ ì¬ê³  ë¬¸ì„œë¥¼ ê¸°ë³¸ê°’({DEFAULT_INITIAL_STOCK})ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
                st.balloons()
                safe_rerun()
            except Exception as e:
                st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


    # ===== ì¬ë£Œ(Ingredient) ë·° =====
    df_inv = load_inventory_df()
    if df_inv.empty:
        st.info("í˜„ì¬ ë“±ë¡ëœ ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ê±°ë˜ ì¶”ê°€' ë˜ëŠ” ì•„ë˜ ì‹œë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
    else:
        st.subheader("ğŸ¥£ ì¬ë£Œ ì¬ê³  (ë ˆì‹œí”¼ ì—°ê²° ê¸°ë°˜)")
        ing_set = get_all_recipe_ingredients()
        df_ing = df_inv[df_inv["is_ingredient"] | df_inv["ìƒí’ˆìƒì„¸_en"].isin(ing_set)].copy()
        if df_ing.empty:
            st.info("ì•„ì§ ë ˆì‹œí”¼ì™€ ì—°ê²°ëœ ì¬ë£Œê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ 'ë¼ë–¼ ì—°ê²° ë§ˆë²•ì‚¬'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ ë³´ì„¸ìš”.")
        else:
            df_ing['ì¬ê³ ë¹„ìœ¨'] = df_ing['í˜„ì¬ì¬ê³ '] / df_ing['ì´ˆê¸°ì¬ê³ ']
            df_ing['ìƒíƒœ'] = df_ing['ì¬ê³ ë¹„ìœ¨'].apply(lambda r: "ë°œì£¼ìš”ë§" if r <= REORDER_THRESHOLD_RATIO else "ì •ìƒ")
            low_ing = df_ing[df_ing['ì¬ê³ ë¹„ìœ¨'] <= REORDER_THRESHOLD_RATIO]

            fig_ing = px.bar(
                df_ing.sort_values('ì¬ê³ ë¹„ìœ¨'),
                x='ìƒí’ˆìƒì„¸', y='í˜„ì¬ì¬ê³ ', color='ì¬ê³ ë¹„ìœ¨',
                title="ì¬ë£Œë³„ ì¬ê³  í˜„í™©",
            )
            st.plotly_chart(fig_ing, width=W)
            st.dataframe(df_ing[['ìƒí’ˆìƒì„¸','í˜„ì¬ì¬ê³ ','ì´ˆê¸°ì¬ê³ ','uom','ì¬ê³ ë¹„ìœ¨','ìƒíƒœ']], width=W)

            if not low_ing.empty:
                st.warning("âš ï¸ ì¼ë¶€ ì¬ë£Œ ì¬ê³ ê°€ 15% ì´í•˜ì…ë‹ˆë‹¤. ë°œì£¼ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")

    st.markdown("---")

    # ===== ë¼ë–¼ ì—°ê²° ë§ˆë²•ì‚¬ =====
    with st.expander("ğŸ”— ë¼ë–¼ ì—°ê²°(í•œ ë©”ë‰´ POC)"):
        st.caption("ë¼ë–¼ 1ì” = Espresso Roast 18g + Milk 300ml + Regular syrup 5ml (+Milk waste 5%)")
        if st.button("ë¼ë–¼ ë ˆì‹œí”¼ ìƒì„±/ë®ì–´ì“°ê¸°"):
            latte_items = [
                {"ingredient_en": "Espresso Roast", "qty": 18, "uom": "g", "waste_pct": 0},
                {"ingredient_en": "Milk",           "qty": 300, "uom": "ml", "waste_pct": 5},
                {"ingredient_en": "Regular syrup",   "qty": 5,   "uom": "ml", "waste_pct": 0},
            ]
            db.collection(RECIPES_COLLECTION).document("Latte").set({
                "menu_sku_en": "Latte",
                "items": latte_items
            })
            for it in latte_items:
                ensure_ingredient_sku(it["ingredient_en"], uom=it["uom"])  # ì¬ë£Œ í”Œë˜ê·¸ + uom ë³´ì¥
            st.success("âœ… ë¼ë–¼ ë ˆì‹œí”¼ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        c1, c2, c3 = st.columns(3)
        with c1:
            milk_seed = st.number_input("ìš°ìœ  ì´ˆê¸°/í˜„ì¬(ml)", min_value=0, value=5000, step=100)
        with c2:
            bean_seed = st.number_input("ì—ìŠ¤í”„ë ˆì†Œ ë¡œìŠ¤íŠ¸ ì´ˆê¸°/í˜„ì¬(g)", min_value=0, value=2000, step=50)
        with c3:
            syrup_seed = st.number_input("ë ˆê·¤ëŸ¬ ì‹œëŸ½ ì´ˆê¸°/í˜„ì¬(ml)", min_value=0, value=1000, step=10)
        if st.button("ì‹œë“œ ì¬ê³  ë°˜ì˜"):
            for en, uom, qty in [
                ("Milk","ml", milk_seed),
                ("Espresso Roast","g", bean_seed),
                ("Regular syrup","ml", syrup_seed),
            ]:
                ref = ensure_ingredient_sku(en, uom=uom)
                ref.update({"ì´ˆê¸°ì¬ê³ ": float(qty), "í˜„ì¬ì¬ê³ ": float(qty)})
            st.success("âœ… ì‹œë“œ ì¬ê³ ë¥¼ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ===== ì¬ë£Œ ROP (ë¼ë–¼ ê¸°ì¤€) =====
    st.markdown("### ğŸ§® ì¬ë£Œ ROP (ë¼ë–¼ ê¸°ì¤€)")
    df_params = load_sku_params_df()
    if not df_inv.empty:
        missing = set(df_inv["ìƒí’ˆìƒì„¸_en"]) - set(df_params["sku_en"])
        if missing:
            add_df = pd.DataFrame({
                "sku_en": list(missing),
                "lead_time_days": 3,
                "safety_stock_units": 10,
                "target_days": 21,
                "grams_per_cup": 18.0,
                "expiry_days": 28
            })
            df_params = pd.concat([df_params, add_df], ignore_index=True)

    df_sales_for_calc = df.copy()
    if "ìƒí’ˆìƒì„¸" in df_sales_for_calc.columns:
        df_sales_for_calc["ìƒí’ˆìƒì„¸"] = df_sales_for_calc["ìƒí’ˆìƒì„¸"].astype(str)

    df_ing_metrics = compute_ingredient_metrics_for_menu(
        "Latte", df_sales_for_calc, df_inv, df_params, window_days=28
    )
    if df_ing_metrics.empty:
        st.info("ë¼ë–¼ ë ˆì‹œí”¼ê°€ ì—†ê±°ë‚˜ ìµœê·¼ ë¼ë–¼ íŒë§¤ê°€ ì—†ì–´ ì¬ë£Œ ROPë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ë§ˆë²•ì‚¬ì™€ 'ê±°ë˜ ì¶”ê°€'ë¥¼ ì´ìš©í•´ í…ŒìŠ¤íŠ¸í•´ ë³´ì„¸ìš”.")
    else:
        st.dataframe(df_ing_metrics, width=W)
        need_rows = df_ing_metrics[(df_ing_metrics["ìƒíƒœ"].eq("ë°œì£¼ìš”ë§")) | (df_ing_metrics["ê¶Œì¥ë°œì£¼"] > 0)]
        if not need_rows.empty:
            st.warning("âš ï¸ ì•„ë˜ ì¬ë£ŒëŠ” ROP ì´í•˜ì´ê±°ë‚˜ ê¶Œì¥ë°œì£¼ëŸ‰ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
            st.dataframe(need_rows[["ìƒí’ˆìƒì„¸","í˜„ì¬ì¬ê³ ","uom","ROP","ê¶Œì¥ë°œì£¼","lead_time_days","safety_stock_units","target_days"]], width=W)

    st.markdown("---")

    # ===== ìµœê·¼ ì¬ê³  ì´ë™ ë¡œê·¸ =====
    st.markdown("### ğŸ§¾ ìµœê·¼ ì¬ê³  ì´ë™")
    try:
        q = db.collection(STOCK_MOVES_COLLECTION).order_by("ts", direction=firestore.Query.DESCENDING).limit(50).stream()
        docs = [d.to_dict() for d in q]
    except Exception:
        docs = [d.to_dict() for d in db.collection(STOCK_MOVES_COLLECTION).stream()]
        docs.sort(key=lambda x: x.get("ts",""), reverse=True)
    move_rows = []
    for m in docs:
        base = {
            "ì‹œê°": m.get("ts",""),
            "ìœ í˜•": m.get("type",""),
            "ë©”ë‰´": to_korean_detail(m.get("menu_sku_en","")),
            "ìˆ˜ëŸ‰": m.get("qty",0),
            "ë¹„ê³ ": m.get("note",""),
        }
        for det in (m.get("details", []) or []):
            row = base | {
                "ì¬ë£Œ": to_korean_detail(det.get("ingredient_en","")),
                "ì‚¬ìš©ëŸ‰": round(float(det.get("used",0.0)),2),
                "ë‹¨ìœ„": det.get("uom",""),
                "ì „": round(float(det.get("before",0.0)),2),
                "í›„": round(float(det.get("after",0.0)),2),
            }
            move_rows.append(row)
    if move_rows:
        kw = st.text_input("í•„í„°(ë©”ë‰´/ì¬ë£Œ í¬í•¨)", "")
        df_moves = pd.DataFrame(move_rows)
        if kw:
            df_moves = df_moves[df_moves.apply(lambda r: kw in str(r.values), axis=1)]
        st.dataframe(df_moves, hide_index=True, width=W)
    else:
        st.caption("ìµœê·¼ ì´ë™ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
elif menu == "ë°ì´í„° í¸ì§‘":
    st.header("âœï¸ ë°ì´í„° í¸ì§‘")
    tab1, tab2 = st.tabs(["ê±°ë˜ ìˆ˜ì •/ì‚­ì œ", "ì¬ê³  ì¼ê´„ìˆ˜ì •"])

    # ------------------ ê±°ë˜ ìˆ˜ì •/ì‚­ì œ ------------------
    with tab1:
        df_raw, df_view = load_sales_with_id()
        if df_view.empty:
            st.info("ìˆ˜ì •í•  Firebase ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (CSVëŠ” ì½ê¸° ì „ìš©)")
        else:
            st.caption("ğŸ’¡ CSV ê¸°ë°˜ í–‰ì€ ì—¬ê¸°ì„œ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. (Firebaseì— ì €ì¥ëœ ê±°ë˜ë§Œ í¸ì§‘ ê°€ëŠ¥)")
            edit_cols = ['_id', 'ë‚ ì§œ', 'ìƒí’ˆì¹´í…Œê³ ë¦¬', 'ìƒí’ˆíƒ€ì…', 'ìƒí’ˆìƒì„¸', 'ìˆ˜ëŸ‰', 'ë‹¨ê°€', 'ìˆ˜ìµ']
            df_edit = df_view[edit_cols].copy()

            edited = st.data_editor(
                df_edit,
                hide_index=True,
                num_rows="fixed",
                column_config={
                    "_id": st.column_config.Column("ë¬¸ì„œID", help="ì½ê¸° ì „ìš©", disabled=True),
                    "ë‚ ì§œ": st.column_config.DateColumn("ë‚ ì§œ"),
                    "ìˆ˜ëŸ‰": st.column_config.NumberColumn("ìˆ˜ëŸ‰", step=1, min_value=0),
                    "ë‹¨ê°€": st.column_config.NumberColumn("ë‹¨ê°€(ì›)", step=100.0, min_value=0.0),
                    "ìˆ˜ìµ": st.column_config.NumberColumn("ìˆ˜ìµ(ì›)", step=100.0, min_value=0.0),
                },
                width=W,
                key="trx_edit_table"
            )

            c1, c2, _ = st.columns([1,1,2])
            with c1:
                auto_rev = st.checkbox("ìˆ˜ìµ ìë™ê³„ì‚°(ìˆ˜ëŸ‰Ã—ë‹¨ê°€)", value=True)
            with c2:
                reflect_inv = st.checkbox(
                    "ìˆ˜ì • ì‹œ ì¬ê³  ë°˜ì˜",
                    value=False,
                    help="ìˆ˜ëŸ‰ ë³€ê²½ë¶„ë§Œí¼ ì¬ê³ ë¥¼ ì¦ê°í•©ë‹ˆë‹¤. (ì¦ê°€: ì¬ê³  ì°¨ê°, ê°ì†Œ: ì¬ê³  ë³µì›)"
                )

            if st.button("ğŸ’¾ ë³€ê²½ ì €ì¥"):
                raw_by_id = {r['_id']: r for _, r in df_raw.iterrows()}
                changed = 0
                for _, row in edited.iterrows():
                    doc_id = row['_id']
                    if doc_id not in raw_by_id:
                        continue
                    orig = raw_by_id[doc_id]

                    cat_en = rev_category_map.get(row['ìƒí’ˆì¹´í…Œê³ ë¦¬'], row['ìƒí’ˆì¹´í…Œê³ ë¦¬'])
                    type_en = rev_type_map.get(row['ìƒí’ˆíƒ€ì…'], row['ìƒí’ˆíƒ€ì…'])
                    detail_en = from_korean_detail(row['ìƒí’ˆìƒì„¸'])

                    qty_new = int(row['ìˆ˜ëŸ‰']) if pd.notnull(row['ìˆ˜ëŸ‰']) else 0
                    unit_new = float(row['ë‹¨ê°€']) if pd.notnull(row['ë‹¨ê°€']) else 0.0
                    rev_new = float(qty_new * unit_new) if auto_rev else float(row['ìˆ˜ìµ'] or 0)

                    patch = {}
                    try:
                        date_new_str = str(pd.to_datetime(row['ë‚ ì§œ']).date())
                        date_old_str = str(pd.to_datetime(orig.get('ë‚ ì§œ')).date())
                    except Exception:
                        date_new_str = str(row['ë‚ ì§œ'])
                        date_old_str = str(orig.get('ë‚ ì§œ'))
                    if date_new_str != date_old_str: patch['ë‚ ì§œ'] = date_new_str
                    if cat_en != orig.get('ìƒí’ˆì¹´í…Œê³ ë¦¬'): patch['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = cat_en
                    if type_en != orig.get('ìƒí’ˆíƒ€ì…'): patch['ìƒí’ˆíƒ€ì…'] = type_en
                    if detail_en != orig.get('ìƒí’ˆìƒì„¸'): patch['ìƒí’ˆìƒì„¸'] = detail_en
                    if qty_new != int(orig.get('ìˆ˜ëŸ‰', 0)): patch['ìˆ˜ëŸ‰'] = qty_new
                    if unit_new != float(orig.get('ë‹¨ê°€', 0)): patch['ë‹¨ê°€'] = unit_new
                    if rev_new != float(orig.get('ìˆ˜ìµ', 0)): patch['ìˆ˜ìµ'] = rev_new

                    if patch:
                        if reflect_inv and 'ìˆ˜ëŸ‰' in patch:
                            diff = qty_new - int(orig.get('ìˆ˜ëŸ‰', 0))
                            adjust_inventory_by_recipe(detail_en, diff, move_type="edit_adjust", note=str(doc_id))

                        db.collection(SALES_COLLECTION).document(doc_id).update(patch)
                        changed += 1
                if changed:
                    st.success(f"âœ… {changed}ê±´ ì €ì¥ ì™„ë£Œ")
                    safe_rerun()
                else:
                    st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown("---")
            del_ids = st.multiselect(
                "ğŸ—‘ï¸ ì‚­ì œí•  ê±°ë˜ ì„ íƒ (ë¬¸ì„œID ê¸°ì¤€)",
                options=df_view['_id'].tolist()
            )
            colx, _ = st.columns([1,3])
            with colx:
                restore_inv_on_delete = st.checkbox("ì‚­ì œ ì‹œ ì¬ê³  ë³µì›", value=True)
            if st.button("ì‚­ì œ ì‹¤í–‰", type="primary", disabled=(len(del_ids) == 0)):
                for did in del_ids:
                    raw = df_raw[df_raw['_id'] == did].iloc[0].to_dict()
                    if restore_inv_on_delete:
                        adjust_inventory_by_recipe(raw.get('ìƒí’ˆìƒì„¸'), -int(raw.get('ìˆ˜ëŸ‰', 0)), move_type="delete_restore", note=str(did))
                    db.collection(SALES_COLLECTION).document(did).delete()
                st.success(f"âœ… {len(del_ids)}ê±´ ì‚­ì œ ì™„ë£Œ")
                safe_rerun()

    # ------------------ ì¬ê³  ì¼ê´„ìˆ˜ì • ------------------
    with tab2:
        df_inv2 = load_inventory_df()
        if df_inv2.empty:
            st.info("ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒë§¤ ë“±ë¡ ì‹œ ìë™ ìƒì„±ë©ë‹ˆë‹¤.")
        else:
            edit_cols = ['ìƒí’ˆìƒì„¸', 'ì´ˆê¸°ì¬ê³ ', 'í˜„ì¬ì¬ê³ ']
            inv_edited = st.data_editor(
                df_inv2[edit_cols],
                hide_index=True,
                num_rows="fixed",
                column_config={
                    "ìƒí’ˆìƒì„¸": st.column_config.Column("ìƒí’ˆìƒì„¸(í‘œì‹œ)", help="ì½ê¸° ì „ìš©", disabled=True),
                    "ì´ˆê¸°ì¬ê³ ": st.column_config.NumberColumn("ì´ˆê¸°ì¬ê³ ", step=1, min_value=0),
                    "í˜„ì¬ì¬ê³ ": st.column_config.NumberColumn("í˜„ì¬ì¬ê³ ", step=1, min_value=0),
                },
                width=W,
                key="inv_edit_table"
            )
            if st.button("ğŸ’¾ ì¬ê³  ë³€ê²½ ì €ì¥"):
                changed = 0
                raw_docs = list(db.collection(INVENTORY_COLLECTION).stream())
                raw_by_en = {d.id: d.to_dict() for d in raw_docs}

                for _, row in inv_edited.iterrows():
                    detail_en = from_korean_detail(row['ìƒí’ˆìƒì„¸'])
                    orig = raw_by_en.get(detail_en, {})
                    patch = {}
                    if int(row['ì´ˆê¸°ì¬ê³ ']) != int(orig.get('ì´ˆê¸°ì¬ê³ ', DEFAULT_INITIAL_STOCK)):
                        patch['ì´ˆê¸°ì¬ê³ '] = int(row['ì´ˆê¸°ì¬ê³ '])
                    if int(row['í˜„ì¬ì¬ê³ ']) != int(orig.get('í˜„ì¬ì¬ê³ ', DEFAULT_INITIAL_STOCK)):
                        patch['í˜„ì¬ì¬ê³ '] = int(row['í˜„ì¬ì¬ê³ '])
                    if patch:
                        db.collection(INVENTORY_COLLECTION).document(detail_en).update(patch)
                        changed += 1
                if changed:
                    st.success(f"âœ… ì¬ê³  {changed}ê±´ ì €ì¥ ì™„ë£Œ")
                    safe_rerun()
                else:
                    st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

# ==============================================================
# ğŸ“‹ ê±°ë˜ ë‚´ì—­
# ==============================================================
elif menu == "ê±°ë˜ ë‚´ì—­":
    st.header("ğŸ“‹ ì „ì²´ ê±°ë˜ ë‚´ì—­")
    if df.empty:
        st.info("í‘œì‹œí•  ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        cols = ['ë‚ ì§œ','ìƒí’ˆì¹´í…Œê³ ë¦¬','ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ','ìš”ì¼','ì‹œ']
        cols = [c for c in cols if c in df.columns]
        st.dataframe(df[cols].sort_values('ë‚ ì§œ', ascending=False), width=W)

# ==============================================================
# â“ ë„ì›€ë§
# ==============================================================
else:  # menu == "ë„ì›€ë§"
    st.header("â˜•ï¸ ì»¤í”¼ ì›ë‘ ì¬ê³ ê´€ë¦¬ íŒŒì´í”„ë¼ì¸ ì‰½ê²Œ ì´í•´í•˜ê¸°")
    st.markdown("""
> **â€œì»¤í”¼ ì›ë‘ê°€ ì–´ë–»ê²Œ ë“¤ì–´ì˜¤ê³ , ì–¼ë§ˆë‚˜ ì“°ì´ê³ , ì–¸ì œ ë‹¤ì‹œ ì£¼ë¬¸ë¼ì•¼ í•˜ëŠ”ì§€ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ì!â€**  
ì—‘ì…€ ëŒ€ì‹  ERPê°€ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì¤ë‹ˆë‹¤.

### íŒŒì´í”„ë¼ì¸ í•œëˆˆì— ë³´ê¸°
| ë‹¨ê³„ | í•˜ëŠ” ì¼ | ì˜ˆì‹œ |
| --- | --- | --- |
| **1. ì›ë‘ ì…ê³ ** | ì¹´í˜ê°€ ì›ë‘ë¥¼ ì‚¬ì™€ì„œ ì°½ê³ ì— ë„£ìŒ | â€œì—í‹°ì˜¤í”¼ì•„ ì›ë‘ 10kg ì…ê³ â€ |
| **2. ì¬ê³  ë³´ê´€** | ì›ë‘ ë³´ê´€/ì‹ ì„ ë„ í™•ì¸ | ìœ í†µê¸°í•œ, ì‹ ì„ ë„ ì²´í¬ |
| **3. íŒë§¤/ì†Œì§„** | ì»¤í”¼ë¥¼ ë§Œë“¤ë©´ ì›ë‘ê°€ ì¤„ì–´ë“¦ | â€œì•„ë©”ë¦¬ì¹´ë…¸ 50ì” â†’ ì›ë‘ 2kg ì†Œëª¨â€ |
| **4. ì¬ê³  ê³„ì‚°** | ë‚¨ì€ ì›ë‘ëŸ‰ ìë™ ê³„ì‚° | â€œí˜„ì¬ 8kg (20% ë‚¨ìŒ)â€ |
| **5. ë°œì£¼ ì‹œì  ì•Œë¦¼** | ì¼ì • ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ ì•Œë ¤ì¤Œ | â€œì¬ê³  15% ì´í•˜ â†’ ë°œì£¼ ê¶Œì¥â€ |
| **6. ì¬ì£¼ë¬¸ ë° ìˆœí™˜** | ìƒˆ ì›ë‘ ì£¼ë¬¸ â†’ ë‹¤ì‹œ ì…ê³  | ìˆœí™˜ ë°˜ë³µ |

### ì™œ ë„ì›€ì´ ë˜ë‚˜ìš”?
- **ë°ì´í„°**ë¡œ ë°œì£¼ íƒ€ì´ë° ê²°ì •
- **í’ˆì ˆ/íê¸°** ì¤„ì´ê³  **ì‹ ì„ ë„** ìœ ì§€
- **ì…ê³ â†’ì¬ê³ â†’ì†Œì§„â†’ë°œì£¼** ì „ ê³¼ì •ì´ ì—°ê²°ë©ë‹ˆë‹¤.
    """)
