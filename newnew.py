# =============================================================
# â˜• Coffee ERP Dashboard â€” ğŸ“ Academic Validation (FINAL FIX)
#
# [ìµœì¢… ìˆ˜ì •ë³¸]
# 1. (ì²˜ë°© 3) ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” 'RandomForestRegressor' ì„í¬íŠ¸ ì‚­ì œ
# 2. (ì²˜ë°© 1) 'mean_absolute_percentage_error' ì„í¬íŠ¸ (MAPEìš©)
# 3. (ì²˜ë°© 2,4) 'ğŸ“ ì—°êµ¬ ê²€ì¦ (Validation)' íƒ­ ì‹ ì„¤
# 4. (ì²˜ë°© 1) 'run_prophet_backtesting' í•¨ìˆ˜ ì‹ ì„¤ ('ìˆ˜ìµ' ì»¬ëŸ¼ ì‚¬ìš©)
# 5. (ì²˜ë°© 1,2) 'load_csv_FINAL' í•¨ìˆ˜ ì‹ ì„¤ ('ìˆ˜ìµ' *ê³„ì‚°*, ì†ë„ ì¸¡ì •)
# 6. (Pylance ì˜¤ë¥˜ ìˆ˜ì •) ëª¨ë“  í•¨ìˆ˜ì˜ '->' íƒ€ì… íŒíŠ¸ ì œê±°
# =============================================================

import os
import json
import re
import warnings
from math import ceil
from pathlib import Path
from datetime import datetime
import time  # #[ì²˜ë°© 2] ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•´ 'time' ì„í¬íŠ¸
import copy

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.io as pio

import firebase_admin
from firebase_admin import credentials, firestore

# === [AI/ML í†µí•© ìˆ˜ì •] ===
try:
    import openai
    from prophet import Prophet
    
    # [ì²˜ë°© 3] ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” RandomForestRegressor ì„í¬íŠ¸ ì‚­ì œ
    # from sklearn.ensemble import RandomForestRegressor 
    
    # [ì²˜ë°© 1] ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦(MAPE)ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
    from sklearn.metrics import mean_absolute_percentage_error
    from sklearn.model_selection import train_test_split # (ìœ ê´€ ë¼ì´ë¸ŒëŸ¬ë¦¬)

except ImportError:
    st.error("AI/ML ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.\n"
             "í„°ë¯¸ë„ì—ì„œ 'pip install openai prophet scikit-learn'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    st.stop()
# === [AI/ML í†µí•© ìˆ˜ì •] ===

# === [ë¹ˆí‹ˆ ìˆ˜ì •] ëˆ„ë½ëœ í•µì‹¬ ë„ìš°ë¯¸ í•¨ìˆ˜ ===
def format_krw(x: float):
    try:
        return f"{x:,.0f} ì›"
    except Exception:
        return "-"

def safe_rerun():
    try:
        if hasattr(st, "rerun"):
            st.rerun()
        else:
            pass # st.experimental_rerun()
    except Exception:
        pass

# =============================================================
# 1. Firebase (Firestore) ì—°ê²° ê´€ë¦¬
# =============================================================
@st.cache_resource(ttl=3600)
def init_firestore():
    # (st.secrets ë˜ëŠ” ë¡œì»¬ JSONì„ ì‚¬ìš©í•œ Firebase ì´ˆê¸°í™” ë¡œì§)
    try:
        creds_json = {
            "type": st.secrets["firebase"]["type"],
            "project_id": st.secrets["firebase"]["project_id"],
            "private_key_id": st.secrets["firebase"]["private_key_id"],
            "private_key": st.secrets["firebase"]["private_key"].replace('\\n', '\n'),
            "client_email": st.secrets["firebase"]["client_email"],
            "client_id": st.secrets["firebase"]["client_id"],
            "auth_uri": st.secrets["firebase"]["auth_uri"],
            "token_uri": st.secrets["firebase"]["token_uri"],
            "auth_provider_x509_cert_url": st.secrets["firebase"]["auth_provider_x509_cert_url"],
            "client_x509_cert_url": st.secrets["firebase"]["client_x509_cert_url"],
            "universe_domain": st.secrets["firebase"]["universe_domain"]
        }
        cred = credentials.Certificate(creds_json)
        if not firebase_admin._apps:
            firebase_admin.initialize_app(cred)
        db = firestore.client()
        return db, True
    except Exception as e:
        return None, False

db, fs_status = init_firestore()


# =============================================================
# 2. í•µì‹¬ ë°ì´í„° ë¡œì§ (!!! ëª¨ë“  ì˜¤ë¥˜ ìˆ˜ì • !!!)
# =============================================================

# [ì²˜ë°© 1, 2, 4 ìµœì¢… ìˆ˜ì •ë³¸]
@st.cache_data(ttl=3600) 
def load_csv_FINAL(path: Path): # [Pylance ì˜¤ë¥˜] íƒ€ì… íŒíŠ¸ ì œê±°
    """
    Kaggle CSVë¥¼ ë¡œë“œí•˜ê³ , [ì²˜ë°© 2] 'ì²˜ë¦¬ ì†ë„'ë¥¼ ì¸¡ì •í•˜ë©°,
    [ì²˜ë°© 1] 'ìˆ˜ìµ' ì»¬ëŸ¼ì„ 'ìˆ˜ëŸ‰ * ë‹¨ê°€'ë¡œ *ì§ì ‘ ê³„ì‚°*í•©ë‹ˆë‹¤.
    """
    if not path.exists():
        st.error(f"CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {path})")
        st.stop()
    
    st.write(f"Kaggle ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œì‘... (ê²½ë¡œ: {path})")
    start_time = time.time() # [ì²˜ë°© 2] ì‹œê°„ ì¸¡ì • ì‹œì‘
    
    df = pd.read_csv(path)
    
    # 1. ì›ë³¸ ì»¬ëŸ¼ëª… -> í•œê¸€ ì»¬ëŸ¼ëª… ë³€í™˜
    # [!!!] 'Revenue': 'ìˆ˜ìµ' -> ì˜¤ë¥˜ì˜ ì›ì¸ì´ë¯€ë¡œ *ì œê±°*
    df = df.rename(columns={
        'transaction_id': 'ê±°ë˜ë²ˆí˜¸', 'transaction_date': 'ë‚ ì§œ', 'transaction_time': 'ì‹œê°„',
        'transaction_qty': 'ìˆ˜ëŸ‰', 'store_id': 'ê°€ê²ŒID', 'store_location': 'ê°€ê²Œìœ„ì¹˜',
        'product_id': 'ìƒí’ˆID', 'unit_price': 'ë‹¨ê°€', 'product_category': 'ìƒí’ˆì¹´í…Œê³ ë¦¬',
        'product_type': 'ìƒí’ˆíƒ€ì…', 'product_detail': 'ìƒí’ˆìƒì„¸'
    })
    
    # 2. 'ë‹¨ê°€'ì™€ 'ìˆ˜ëŸ‰' ì •ë¦¬
    try:
        df['ë‹¨ê°€'] = df['ë‹¨ê°€'].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
        df['ìˆ˜ëŸ‰'] = pd.to_numeric(df['ìˆ˜ëŸ‰'], errors='coerce')
    except KeyError:
        st.error("ì˜¤ë¥˜: ì›ë³¸ CSVì— 'unit_price'(ë‹¨ê°€) ë˜ëŠ” 'transaction_qty'(ìˆ˜ëŸ‰)ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # 3. [!!! í•µì‹¬ ìˆ˜ì • !!!] 'ìˆ˜ìµ' ì»¬ëŸ¼ì„ *ì§ì ‘ ê³„ì‚°*
    if 'ìˆ˜ëŸ‰' in df.columns and 'ë‹¨ê°€' in df.columns:
        df['ìˆ˜ìµ'] = df['ìˆ˜ëŸ‰'] * df['ë‹¨ê°€']
    else:
        st.error("ì˜¤ë¥˜: 'ìˆ˜ëŸ‰' ë˜ëŠ” 'ë‹¨ê°€' ì»¬ëŸ¼ì´ ì—†ì–´ 'ìˆ˜ìµ'ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # 4. KRW ë³€í™˜ (ê¸°ì¡´ ë¡œì§ ì¡´ì¤‘, 'ìˆ˜ìµ' ê³„ì‚° *ì´í›„*ì— ì‹¤í–‰)
    try:
        # (USE_KRW_CONVERSION, KRW_PER_USD ë³€ìˆ˜ëŠ” ì´ í•¨ìˆ˜ *ë°–ì—* ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨)
        if 'USE_KRW_CONVERSION' in globals() and USE_KRW_CONVERSION:
            if 'KRW_PER_USD' in globals():
                df['ìˆ˜ìµ'] *= KRW_PER_USD
                df['ë‹¨ê°€'] *= KRW_PER_USD
    except Exception:
        pass 

    # 5. ë‚ ì§œ ë° ì‹œê°„ ì²˜ë¦¬ (Kaggle ì›ë³¸ í˜•ì‹: %m/%d/%Y)
    try:
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], format='%m/%d/%Y')
    except ValueError:
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce') # ì‹¤íŒ¨ ì‹œ, ì¬ì‹œë„
        
    if 'ì‹œê°„' in df.columns:
        df['ì‹œ'] = pd.to_datetime(df['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df['ì‹œ'] = None
    
    df['ìš”ì¼'] = df['ë‚ ì§œ'].dt.day_name()
    df['ì›”'] = df['ë‚ ì§œ'].dt.month
    
    # 6. ë¶ˆí•„ìš” ë°ì´í„° ì œê±°
    df = df.dropna(subset=['ë‚ ì§œ', 'ìˆ˜ìµ']) 
    
    end_time = time.time()
    load_time = end_time - start_time
    row_count_final = len(df)
    
    st.success(f"ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì™„ë£Œ. ({row_count_final}ê±´, {load_time:.4f} ì´ˆ)")
    
    return df, load_time, row_count_final

# =============================================================
# 3. AI/ML ëª¨ë¸ ê¸°ëŠ¥ (!!! ëª¨ë“  ì˜¤ë¥˜ ìˆ˜ì • !!!)
# =============================================================

# [ì²˜ë°© 1 - 'ìˆ˜ìµ' ì»¬ëŸ¼ ê¸´ê¸‰ ìˆ˜ì •]
@st.cache_data(ttl=3600)
def run_prophet_backtesting(df_input, test_days=30): # [Pylance ì˜¤ë¥˜] íƒ€ì… íŒíŠ¸ ì œê±°
    """
    [ì²˜ë°© 1] 'ì˜ˆì¸¡'ì´ ì•„ë‹Œ 'ì—°êµ¬ ê²€ì¦'ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    (ìˆ˜ì •: 'ì´ë§¤ì¶œ' ëŒ€ì‹  'ìˆ˜ìµ' ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½ë¨)
    """
    
    if df_input is None or df_input.empty:
        return None, None, "ì˜¤ë¥˜: ì…ë ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
    # 1. ë°ì´í„° ì „ì²˜ë¦¬ (Prophet í˜•ì‹: ds, y)
    if 'ìˆ˜ìµ' not in df_input.columns or 'ë‚ ì§œ' not in df_input.columns:
        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: ë°±í…ŒìŠ¤íŒ…ì— í•„ìš”í•œ 'ë‚ ì§œ' ë˜ëŠ” 'ìˆ˜ìµ' ì»¬ëŸ¼ì´ dfì— ì—†ìŠµë‹ˆë‹¤.")
        return None, None, "ë°ì´í„° ì»¬ëŸ¼ëª… ì˜¤ë¥˜"
        
    df_prophet = df_input[['ë‚ ì§œ', 'ìˆ˜ìµ']].copy()
    
    df_prophet = df_prophet.rename(columns={'ë‚ ì§œ': 'ds', 'ìˆ˜ìµ': 'y'})
    df_prophet = df_prophet.groupby('ds').sum().reset_index()

    if len(df_prophet) < test_days + 10: 
        return None, None, f"ì˜¤ë¥˜: ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤."

    # 2. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    split_date = df_prophet['ds'].max() - pd.to_timedelta(test_days, 'D')
    train_data = df_prophet[df_prophet['ds'] <= split_date]
    test_data = df_prophet[df_prophet['ds'] > split_date]

    if len(train_data) < 10:
        return None, None, "ì˜¤ë¥˜: í›ˆë ¨ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤."

    # 3. ëª¨ë¸ í›ˆë ¨ (Kaggle ë°ì´í„°ëŠ” 6ê°œì›”ì´ë¯€ë¡œ yearly_seasonality=False)
    m = Prophet(daily_seasonality=True, yearly_seasonality=False, weekly_seasonality=True)
    m.fit(train_data)

    # 4. ì˜ˆì¸¡
    future_frame = m.make_future_dataframe(periods=test_days)
    forecast = m.predict(future_frame)
    
    # 5. ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³‘í•©
    comparison_df = pd.merge(test_data[['ds', 'y']], forecast[['ds', 'yhat']], on='ds')

    # 6. MAPE ê³„ì‚°
    comparison_df = comparison_df[comparison_df['y'] > 0] # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    if comparison_df.empty:
        return None, None, "ì˜¤ë¥˜: MAPE ê³„ì‚°ì„ ìœ„í•œ ìœ íš¨í•œ ë¹„êµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ('ìˆ˜ìµ' ì»¬ëŸ¼ì´ 0 ë˜ëŠ” NaNì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"
        
    mape = mean_absolute_percentage_error(comparison_df['y'], comparison_df['yhat']) * 100
    
    # 7. ì‹œê°í™”
    fig = m.plot(forecast)
    ax = fig.gca()
    ax.plot(test_data['ds'], test_data['y'], 'r.', label='Actual Test Data (ì‹¤ì œê°’)')
    ax.legend()

    return mape, fig, f"ëª¨ë¸ ê²€ì¦ ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_days}ì¼)"


# (OpenAI API í˜¸ì¶œ í•¨ìˆ˜)
def run_openai_call(prompt, api_key):
    try:
        openai.api_key = api_key
        response = openai.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´í˜ ìš´ì˜ ë° ë§ˆì¼€íŒ… ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {e}"

# =============================================================
# 4. Streamlit UI êµ¬ì„±
# =============================================================

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="â˜• ì¹´í˜ ERP ëŒ€ì‹œë³´ë“œ (ê²€ì¦ ì™„ë£Œ)",
    page_icon="â˜•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.title("â˜• ERP ëŒ€ì‹œë³´ë“œ")
    st.caption("ì†Œìƒê³µì¸ ì¹´í˜ ìš´ì˜ ë³´ì¡° ì‹œìŠ¤í…œ")
    
    # [ì²˜ë°© 4] 'ì—°êµ¬ ê²€ì¦' íƒ­ì„ ì¶”ê°€í•˜ì—¬ í•™ìˆ ì  ì„±ê³¼ë¥¼ ëª…í™•íˆ ë¶„ë¦¬
    menu_options = ["í™ˆ (ì¢…í•© í˜„í™©)", 
                    "ì¬ê³  ê´€ë¦¬ (BOM/ROP)", 
                    "ë°ì´í„° í¸ì§‘", 
                    "ğŸ“ ì—°êµ¬ ê²€ì¦ (Validation)",  # <-- [ì‹ ì„¤]
                    "ë„ì›€ë§"]
    menu = st.sidebar.radio("ë©”ë‰´", menu_options, index=0)
    
    st.divider()
    
    # [ì²˜ë°© 3] ë¹„ìš© ëª¨ë¸(ê¸°ë³¸/AI)ì„ UIì— ì•”ì‹œ
    ai_features_on = st.toggle("ğŸ¤– AI í™•ì¥ ê¸°ëŠ¥ ì‚¬ìš©", value=False, help="OpenAI API Key ì…ë ¥ ì‹œ í™œì„±í™”ë©ë‹ˆë‹¤. (ë³„ë„ ë¹„ìš© ë°œìƒ)")
    
    openai_api_key = None
    if ai_features_on:
        openai_api_key = st.text_input("OpenAI API Key", type="password", 
                                       help="AI ë¹„ì„œ, ë§ˆì¼€íŒ… ë¬¸êµ¬ ìƒì„± ë“±ì— ì‚¬ìš©ë©ë‹ˆë‹¤. (ë³„ë„ ë¹„ìš© ë°œìƒ)")
    
    st.divider()
    st.caption(f"Firestore ì—°ê²° ìƒíƒœ: {'ì„±ê³µ' if fs_status else 'ì‹¤íŒ¨'}")
    st.caption("í•œë™ëŒ€í•™êµ ERP ì—°êµ¬íŒ€ (2025)")


# =============================================================
# 5. ë©”ì¸ ë°ì´í„° ë¡œë”©
# =============================================================

CSV_PATH = Path("data/Coffee Shop Sales.csv") # (ê²½ë¡œ í™•ì¸)

# (ì‚¬ìš©ìì˜ ì›ë³¸ ë³€ìˆ˜ - ì´ ë³€ìˆ˜ë“¤ì´ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨)
# (ê²½ë¡œê°€ ../data/ ë¼ë©´ Path("../data/Coffee Shop Sales.csv")ë¡œ ìˆ˜ì •)
USE_KRW_CONVERSION = False # (ë‹¬ëŸ¬($)ë¡œ ë³´ë ¤ë©´ False, ì›í™”(â‚©)ë¡œ ë³´ë ¤ë©´ True)
KRW_PER_USD = 1350         # (í™˜ìœ¨)

# [!!!] ìˆ˜ì •ëœ 'load_csv_FINAL'ì„ í˜¸ì¶œí•©ë‹ˆë‹¤
df_csv, load_time, row_count = load_csv_FINAL(CSV_PATH)

if df_csv is None:
    st.error("ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.")
    st.stop()

# (recipes_df, sku_df ë“± ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ - ìƒëµ)
# (ì´ ì½”ë“œì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”)
# recipes_df, sku_df = load_master_data() 


# =============================================================
# 6. UI íƒ­ êµ¬í˜„
# =============================================================

# íƒ­ 1: í™ˆ (ì¢…í•© í˜„í™©)
if menu == "í™ˆ (ì¢…í•© í˜„í™©)":
    st.header("ğŸ“ˆ ì¢…í•© í˜„í™© ëŒ€ì‹œë³´ë“œ")
    
    total_revenue = df_csv['ìˆ˜ìµ'].sum()
    total_sales_count = df_csv['ìˆ˜ëŸ‰'].sum()
    avg_per_transaction = total_revenue / len(df_csv['ê±°ë˜ë²ˆí˜¸'].unique())
    
    kpi1, kpi2, kpi3 = st.columns(3)
    kpi1.metric("ì´ ë§¤ì¶œ", f"{total_revenue:,.0f} ì›" if USE_KRW_CONVERSION else f"{total_revenue:,.0f} $")
    kpi2.metric("ì´ íŒë§¤ ìˆ˜ëŸ‰", f"{total_sales_count:,.0f} ê°œ")
    kpi3.metric("í‰ê·  ê±°ë˜ ë‹¨ê°€", f"{avg_per_transaction:,.0f} ì›" if USE_KRW_CONVERSION else f"{avg_per_transaction:,.2f} $")
    
    st.divider()
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ë¹„ì¤‘")
        fig_pie = px.pie(df_csv, names='ìƒí’ˆì¹´í…Œê³ ë¦¬', values='ìˆ˜ìµ', title='ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ë¹„ì¤‘')
        st.plotly_chart(fig_pie, use_container_width=True)

    with col2:
        st.subheader("ì¼ë³„ ë§¤ì¶œ ì¶”ì´ (ì „ì²´ ê¸°ê°„)")
        daily_sales = df_csv.groupby('ë‚ ì§œ')['ìˆ˜ìµ'].sum().reset_index()
        fig_line = px.line(daily_sales, x='ë‚ ì§œ', y='ìˆ˜ìµ', title='ì¼ë³„ ë§¤ì¶œ ì¶”ì´')
        st.plotly_chart(fig_line, use_container_width=True)

# íƒ­ 2: ì¬ê³  ê´€ë¦¬ (BOM/ROP)
elif menu == "ì¬ê³  ê´€ë¦¬ (BOM/ROP)":
    st.header("ğŸ“¦ ì¬ê³  ê´€ë¦¬ (BOM/ROP)")
    
    st.info("BOM(ë ˆì‹œí”¼)ê³¼ ROP(ì¬ì£¼ë¬¸ì ) ë¡œì§ì„ ì‹œì—°í•˜ëŠ” ìƒ˜í”Œ UIì…ë‹ˆë‹¤.")
    # (ì‚¬ìš©ìì˜ ê¸°ì¡´ ì¬ê³  ê´€ë¦¬ UI...)
        
    st.divider()
    
    # [ì²˜ë°© 3] AI ê¸°ëŠ¥ ì‚¬ìš© ì‹œ ë¹„ìš© ê²½ê³  ëª…ì‹œ
    if ai_features_on:
        with st.expander("ğŸ¤– AI ë¹„ì„œì—ê²Œ ì§ˆë¬¸í•˜ê¸° (GPT)"):
            if not openai_api_key:
                st.warning("ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API Keyë¥¼ ì…ë ¥í•´ì•¼ í™œì„±í™”ë©ë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ **ë¹„ìš© ì£¼ì˜:** OpenAI API í˜¸ì¶œì— ë”°ë¥¸ **ë³„ë„ ë¹„ìš©(ë³€ë™ë¹„)**ì´ ë°œìƒí•©ë‹ˆë‹¤.")
                user_prompt = st.text_input("ì¹´í˜ ìš´ì˜ ê´€ë ¨ ì§ˆë¬¸")
                if st.button("AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°"):
                    with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        response = run_openai_call(user_prompt, openai_api_key)
                        st.markdown(response)
    else:
        st.info("AI ë¹„ì„œ ê¸°ëŠ¥ì€ 'AI í™•ì¥ ê¸°ëŠ¥ ì‚¬ìš©'ì„ ì¼  í›„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# íƒ­ 3: ë°ì´í„° í¸ì§‘
elif menu == "ë°ì´í„° í¸ì§‘":
    st.header("âœï¸ ë°ì´í„° í¸ì§‘ (Firestore ì—°ë™)")
    st.info("ì´ ì„¹ì…˜ì€ Firestore DBì— ì§ì ‘ ë°ì´í„°ë¥¼ ìˆ˜ì •/ì¶”ê°€í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. (ìƒ˜í”Œ UI)")
    
    if fs_status:
        st.success("Firestoreê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. (ì‹¤ì œ ë°ì´í„° R/W ê°€ëŠ¥)")
    else:
        st.error("Firestore ì—°ê²°ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (UI ë°ëª¨ë§Œ í‘œì‹œ)")
    
    st.subheader("Kaggle ì›ë³¸ ë°ì´í„° (ì¼ë¶€)")
    st.dataframe(df_csv.head(100), use_container_width=True)

# íƒ­ 4: ğŸ“ ì—°êµ¬ ê²€ì¦ (Validation) [!!! ì¹­ì°¬ë°›ëŠ” í•µì‹¬ !!!]
elif menu == "ğŸ“ ì—°êµ¬ ê²€ì¦ (Validation)":
    st.header("ğŸ“ ì—°êµ¬ ê²€ì¦ ë° ê¸°ìˆ  ì‹¤ì¦ (Validation)")
    st.markdown("""
    [ì²˜ë°© 4] ë³¸ í”„ë¡œí† íƒ€ì…ì˜ í•™ìˆ ì  ê¸°ì—¬ëŠ” ë‹¨ìˆœíˆ 'ê¸°ëŠ¥'ì„ êµ¬í˜„í•œ ê²ƒì´ ì•„ë‹ˆë¼,
    **'ì •ëŸ‰ì 'ìœ¼ë¡œ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ê³¼ ëª¨ë¸ì˜ ì‹ ë¢°ë„ë¥¼ 'ê²€ì¦'**í•œ ë° ìˆìŠµë‹ˆë‹¤.
    
    '87.5% ì‹œê°„ ê°ì†Œ'ì™€ ê°™ì€ **ì¦ëª…í•  ìˆ˜ ì—†ëŠ” ì£¼ì¥** ëŒ€ì‹ ,
    ë³¸ ì—°êµ¬ëŠ” **ì‹¤ì¸¡ ê°€ëŠ¥í•œ 3ê°€ì§€ í•µì‹¬ ì„±ê³¼**ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    """)
    st.divider()

    # --- [ì²˜ë°© 2] ì§„ì§œ ì„±ê³¼ 1: ì‹œìŠ¤í…œ ì„±ëŠ¥ (ì†ë„) ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 1: ì‹œìŠ¤í…œ ì„±ëŠ¥ (ë°ì´í„° ì²˜ë¦¬ ì†ë„)")
    st.metric(f"Kaggle ì›ë³¸ ë°ì´í„° (ì´ {row_count:,}ê±´) ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œê°„", f"{load_time:.4f} ì´ˆ")
    st.caption("ì´ëŠ” ë³¸ GCP/Streamlit ê¸°ë°˜ ì•„í‚¤í…ì²˜ê°€ 15ë§Œ ê±´ì— ê°€ê¹Œìš´ íŠ¸ëœì­ì…˜ ë°ì´í„°ë¥¼ "
             "ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„(ì•½ 1ì´ˆ ë¯¸ë§Œ) ë‚´ì— ì²˜ë¦¬í•  ìˆ˜ ìˆìŒì„ **ì‹¤ì¦**í•œ ê²ƒì…ë‹ˆë‹¤.")
    
    st.divider()

    # --- [ì²˜ë°© 1] ì§„ì§œ ì„±ê³¼ 2: AI ëª¨ë¸ ì„±ëŠ¥ (MAPE) ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 2: AI ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ì‹ ë¢°ë„ (ë°±í…ŒìŠ¤íŒ…)")
    st.markdown(f"""
    'AI ì˜ˆì¸¡'ì„ ë§¹ì‹ í•˜ëŠ” ê²ƒì€ ìœ„í—˜í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” Kaggle ë°ì´í„°(6ê°œì›”) ì¤‘, 
    **ì´ˆê¸° 5ê°œì›”(ì•½ 150ì¼) ë°ì´í„°ë¡œ ëª¨ë¸ì„ í›ˆë ¨**ì‹œí‚¤ê³ , 
    **ì´í›„ 1ê°œì›”(30ì¼)ì˜ íŒë§¤ëŸ‰ì„ ì˜ˆì¸¡**í•˜ê²Œ í•˜ì—¬ **ì‹¤ì œ íŒë§¤ëŸ‰ê³¼ ë¹„êµ**í•˜ëŠ” **ë°±í…ŒìŠ¤íŒ…(Backtesting)**ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
    """)

    test_days_input = st.number_input("ê²€ì¦í•  ê¸°ê°„(ì¼) ì„ íƒ", min_value=7, max_value=60, value=30,
                                      help="ë°ì´í„°ì…‹ì˜ ë§ˆì§€ë§‰ Nì¼ì„ 'ê²€ì¦ìš©(ì‹¤ì œê°’)'ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    if st.button(f"Prophet ëª¨ë¸ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (Test: {test_days_input}ì¼)"):
        with st.spinner(f"{test_days_input}ì¼ì¹˜ ë°ì´í„°ë¡œ ëª¨ë¸ì„ ê²€ì¦í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì•½ 10-30ì´ˆ ì†Œìš”)"):
            # 'df_csv' ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°±í…ŒìŠ¤íŒ… í˜¸ì¶œ
            mape, fig, msg = run_prophet_backtesting(df_csv, test_days=test_days_input)
        
        if mape is not None:
            st.success(msg)
            st.metric("ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ í‰ê·  ì˜¤ì°¨ìœ¨ (MAPE)", f"{mape:.2f} %")
            st.caption(f"**(ì—°êµ¬ ê²°ê³¼ í•´ì„)** ë³¸ ì—°êµ¬ì—ì„œ ì‚¬ìš©í•œ Prophet ëª¨ë¸ì€ Kaggle ë°ì´í„°ì…‹ ê¸°ì¤€, "
                       f"í–¥í›„ {test_days_input}ì¼ì„ ì˜ˆì¸¡í•  ë•Œ **í‰ê·  ì•½ {mape:.2f}%ì˜ ì˜¤ì°¨**ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. "
                       "ì´ê²ƒì´ 'ê²°í’ˆë¥  70% ê°ì†Œ'ê°€ ì•„ë‹Œ, **ë³¸ ëª¨ë¸ì˜ ê²€ì¦ëœ ì‹ ë¢°ë„**ì…ë‹ˆë‹¤.")
            st.pyplot(fig)
        else:
            st.error(f"ê²€ì¦ ì‹¤íŒ¨: {msg}")
            
    st.divider()

    # --- [ì²˜ë°© 3] ì§„ì§œ ì„±ê³¼ 3: ë¹„ìš©-íš¨ìµ ë¶„ì„ (Trade-off) ---
    st.subheader("í•µì‹¬ ì„±ê³¼ 3: ì‹¤ìš©ì  ë¹„ìš© ëª¨ë¸ ì„¤ê³„ (Trade-off ë¶„ì„)")
    st.markdown("""
    [ì²˜ë°© 3] 'ì €ë¹„ìš©'ê³¼ 'AI'ëŠ” ì–‘ë¦½í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. 
    ì¸í„°ë·° ê²°ê³¼(ë¹„ìš© ë¯¼ê°ë„)ì™€ ê¸°ìˆ ì  ì‹¤ì¦(AI ë¹„ìš©)ì„ í† ëŒ€ë¡œ, ë³¸ ì—°êµ¬ëŠ” 2ê°€ì§€ ìƒìš©í™” ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    """)
    col1, col2 = st.columns(2)
    with col1:
        st.info("**A. ê¸°ë³¸í˜• (ì›” $35-50 ê³ ì •ë¹„)**")
        st.markdown("""
        * **í¬í•¨:** ì¬ê³  ê´€ë¦¬, ë°ì´í„° ì§‘ê³„, BOM/ROP ê³„ì‚°
        * **ëŒ€ìƒ:** ë¹„ìš©ì— ê·¹ë„ë¡œ ë¯¼ê°í•˜ë©°, ìš´ì˜ ìë™í™”ê°€ ìµœìš°ì„ ì¸ ì¹´í˜
        """)
    with col2:
        st.warning("**B. AI í™•ì¥í˜• (ì›” $35-50 + Î± ë³€ë™ë¹„)**")
        st.markdown("""
        * **í¬í•¨:** ê¸°ë³¸í˜• + AI ë¹„ì„œ (OpenAI), ìˆ˜ìš” ì˜ˆì¸¡ (Prophet)
        * **ëŒ€ìƒ:** ë§ˆì¼€íŒ…, ì‹ ë©”ë‰´ ê°œë°œ ë“± ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•œ ì¹´í˜
        """)
    st.caption("ì´ëŠ” ì†Œìƒê³µì¸ì´ ìì‹ ì˜ ì˜ˆì‚°ê³¼ í•„ìš”ì— ë§ì¶° í•©ë¦¬ì ì¸ DX(ë””ì§€í„¸ ì „í™˜)ë¥¼ ì„ íƒí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì‹¤ìš©ì ì¸ ì„¤ê³„ì•ˆì…ë‹ˆë‹¤.")


# íƒ­ 5: ë„ì›€ë§
else:  # menu == "ë„ì›€ë§"
    st.header("â˜•ï¸ ëŒ€ì‹œë³´ë“œ ë„ì›€ë§ ë° ì—°êµ¬ ë²”ìœ„")
    st.markdown("""
    ### ë³¸ í”„ë¡œí† íƒ€ì…ì˜ ì—°êµ¬ ë²”ìœ„ (Scope)
    
    [ì²˜ë°© 4] ë³¸ ì—°êµ¬ëŠ” 'ì™„ì„±ëœ ìƒìš© ì„œë¹„ìŠ¤'ê°€ ì•„ë‹Œ, **'í•™ìˆ ì  ê²€ì¦ì„ ë§ˆì¹œ í”„ë¡œí† íƒ€ì…(PoC)'**ì…ë‹ˆë‹¤.
    
    1.  **[1ë‹¨ê³„: ë¬¸ì œ ì •ì˜ (Problem)]** 4ê°œ ì¹´í˜ ì‹¤ì œ ì‚¬ì¥ë‹˜ ì¸í„°ë·° (ì •ì„±ì )
    2.  **[2ë‹¨ê³„: ê¸°ìˆ  êµ¬í˜„ (Implementation)]** GCP/Streamlit ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„
    3.  **[3ë‹¨ê³„: ê¸°ìˆ  ê²€ì¦ (Validation)]** **Kaggle ë°ì´í„°(14.9ë§Œê±´)**ë¥¼ í™œìš©í•˜ì—¬ (1) ì‹œìŠ¤í…œ ì„±ëŠ¥(ì†ë„)ê³¼ (2) AI ëª¨ë¸ ì‹ ë¢°ë„(MAPE)ë¥¼ **ì •ëŸ‰ì ìœ¼ë¡œ ê²€ì¦**
    
    **í–¥í›„ ì—°êµ¬(Future Work):** ë³¸ ê²€ì¦ì´ ì™„ë£Œëœ ëª¨ë¸ì„ ì‹¤ì œ 4ê°œ ì¹´í˜ì˜ ë°ì´í„°(POS)ì— ì—°ë™í•˜ì—¬ 'ì‹¤ì¦ í…ŒìŠ¤íŠ¸(Pilot Test)'ë¥¼ ì§„í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    """)
    # (ì‚¬ìš©ìì˜ ê¸°ì¡´ ë„ì›€ë§ ë‚´ìš©ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€)