# ==============================================================
# â˜• Coffee ERP Dashboard â€” Company Showcase Edition (Tone-Down Blue)
# (ê¸°ì¡´ ì£¼ì„ ìƒëµ)
# ==============================================================

import os
import json
import re
import warnings
from math import ceil
from pathlib import Path
from datetime import datetime
import time # #[AI/ML í†µí•© ì¶”ê°€] (Mock ì‘ë‹µìš©)

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.io as pio

import firebase_admin
from firebase_admin import credentials, firestore

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1 (AI ë¹„ì„œ) ë° SPRINT 2 (ìˆ˜ìš” ì˜ˆì¸¡) ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import openai
    import time
    from prophet import Prophet
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_absolute_percentage_error
except ImportError:
    st.error("""
    AI/ML ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.
    í„°ë¯¸ë„ì—ì„œ 'pip install openai prophet scikit-learn'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
    """)
    st.stop()
# === [AI/ML í†µí•© ì¶”ê°€] ===
# === [ë¹ˆí‹ˆ ìˆ˜ì •] ëˆ„ë½ëœ í•µì‹¬ ë„ìš°ë¯¸ í•¨ìˆ˜ (format_krw, safe_rerun) ===
def format_krw(x: float) -> str:
    """ìˆ«ìë¥¼ ì›í™” í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        return f"{x:,.0f} ì›"
    except Exception:
        return "-"

def safe_rerun():
    """Streamlit ë²„ì „ì— ë§ì¶° ì•±ì„ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤."""
    try:
        if hasattr(st, "rerun"):
            st.rerun()
        elif hasattr(st, "experimental_rerun"):
            st.experimental_rerun()
    except Exception as e:
        # (ìƒˆë¡œê³ ì¹¨ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ)
        pass
# ===================================================================


st.set_page_config(page_title="â˜• Coffee ERP Dashboard", layout="wide")


# (init_firebase í•¨ìˆ˜ ì›ë³¸)
def init_firebase():
    try:
        if "GOOGLE_APPLICATION_CREDENTIALS_JSON" in os.environ:
            cred_info = json.loads(os.environ["GOOGLE_APPLICATION_CREDENTIALS_JSON"])
            cred = credentials.Certificate(cred_info)
            if not firebase_admin._apps:
                firebase_admin.initialize_app(cred)
            return firestore.client(), "success"
        else:
            return None, "no_env"
    except Exception as e:
        return None, f"error: {e}"

# âœ… í•¨ìˆ˜ í˜¸ì¶œ í›„ UI í‘œì‹œ ë¶„ë¦¬
db, fb_status = init_firebase()

# --- Pylance/static analyzer guards (no runtime effect) ---
items = []  # type: ignore
sold_qty = 0  # type: ignore
summary = []  # type: ignore

# ----------------------
# 0ï¸âƒ£ ê²½ë¡œ/ìƒìˆ˜ (íŒ€ì›ì´ ì–´ë””ì„œ ë°›ì•„ë„ ë™ì‘)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
BASE_DIR = Path(__file__).resolve().parent

try:
    SECRETS = dict(st.secrets)
except Exception:
    SECRETS = {}

def _resolve_path(val, default: Path) -> Path:
    if not val:
        return default
    p = Path(str(val))
    return p if p.is_absolute() else (BASE_DIR / p)

DATA_DIR   = _resolve_path(SECRETS.get("DATA_DIR")   or os.environ.get("ERP_DATA_DIR"),   BASE_DIR / "data")
ASSETS_DIR = _resolve_path(SECRETS.get("ASSETS_DIR") or os.environ.get("ERP_ASSETS_DIR"), BASE_DIR / "assets")
KEYS_DIR   = _resolve_path(SECRETS.get("KEYS_DIR")   or os.environ.get("ERP_KEYS_DIR"),   BASE_DIR / "keys")

CSV_PATH     = DATA_DIR / "Coffee Shop Sales.csv"
PIPELINE_IMG = ASSETS_DIR / "pipeline_diagram.png"
SA_FILE_PATH = KEYS_DIR / "serviceAccount.json"

SALES_COLLECTION      = "coffee_sales"
INVENTORY_COLLECTION  = "inventory"
ORDERS_COLLECTION     = "orders"
SKU_PARAMS_COLLECTION = "sku_params"

RECIPES_COLLECTION      = "recipes"
STOCK_COUNTS_COLLECTION = "stock_counts"
STOCK_MOVES_COLLECTION  = "stock_moves"

USE_KRW_CONVERSION = False
KRW_PER_USD = 1350
DEFAULT_INITIAL_STOCK   = 10000
REORDER_THRESHOLD_RATIO = 0.15

for p in (DATA_DIR, ASSETS_DIR, KEYS_DIR):
    p.mkdir(parents=True, exist_ok=True)


# ----------------------
# 0-1ï¸âƒ£ Firebase ì´ˆê¸°í™” (Secrets â†’ keys/ â†’ GOOGLE_APPLICATION_CREDENTIALS)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_resource
def init_firestore():
    """Firebase ì¸ì¦ ë° Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€ + ìºì‹œ ì ìš©)"""
    if firebase_admin._apps:
        return firestore.client()
    svc_dict = SECRETS.get("firebase_service_account")
    if isinstance(svc_dict, dict) and svc_dict:
        cred = credentials.Certificate(svc_dict)
        firebase_admin.initialize_app(cred)
        return firestore.client()
    if SA_FILE_PATH.exists():
        cred = credentials.Certificate(str(SA_FILE_PATH))
        firebase_admin.initialize_app(cred)
        return firestore.client()
    gac = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if gac and Path(gac).expanduser().exists():
        firebase_admin.initialize_app()
        return firestore.client()
    st.error(
        "Firebase ìê²©ì¦ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:\n"
        "â€¢ st.secrets['firebase_service_account'] ë”•ì…”ë„ˆë¦¬\n"
        "â€¢ keys/serviceAccount.json íŒŒì¼\n"
        "â€¢ í™˜ê²½ë³€ìˆ˜ GOOGLE_APPLICATION_CREDENTIALS=ìê²©ì¦ëª…íŒŒì¼ê²½ë¡œ"
    )
    st.stop()


db = init_firestore()

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í‚¤ ì„¤ì •
try:
    openai.api_key = st.secrets["openai"]["api_key"]
except (KeyError, AttributeError):
    st.warning("""
    OpenAI API í‚¤ê°€ 'secrets.toml'ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 
    AI ë¹„ì„œ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šê±°ë‚˜ Mock ë°ì´í„°ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
    [.streamlit/secrets.toml] íŒŒì¼ì— [openai] api_key = "sk-..."ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
    """)
    openai.api_key = None # í‚¤ê°€ ì—†ì–´ë„ ì•±ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡
# === [AI/ML í†µí•© ì¶”ê°€] ===

# ----------------------
# 0-2ï¸âƒ£ UI/ìŠ¤íƒ€ì¼
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
pio.templates.default = "plotly_white"
px.defaults.template = "plotly_white"
px.defaults.color_continuous_scale = "Blues"

st.markdown("""
    <style>
    /* ... (ê¸°ì¡´ ìŠ¤íƒ€ì¼ ì •ì˜) ... */
    </style>
""", unsafe_allow_html=True)


st.markdown("""
<div class="dashboard-header">
  <h1>â˜• Coffee ERP Dashboard</h1>
</div>
""", unsafe_allow_html=True)

# ----------------------
# 0-3ï¸âƒ£ í•œê¸€ ë§¤í•‘ í…Œì´ë¸”
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
category_map = {
    "Coffee": "ì»¤í”¼", "Tea": "ì°¨", "Bakery": "ë² ì´ì»¤ë¦¬",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Packaged Chocolate": "í¬ì¥ ì´ˆì½œë¦¿",
}
rev_category_map = {v: k for k, v in category_map.items()}
rev_category_map.update({
    "ë² ì´ì»¤ë¦¬": "Bakery",
    # ... (ê¸°ì¡´ ì—­ ë§¤í•‘) ...
    "ì»¤í”¼": "Coffee",
})

type_map = {
    "Barista Espresso": "ë°”ë¦¬ìŠ¤íƒ€ ì—ìŠ¤í”„ë ˆì†Œ",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Premium Brewed Coffee": "í”„ë¦¬ë¯¸ì—„ ë¸Œë£¨ë“œ ì»¤í”¼",
}
rev_type_map = {v: k for k, v in type_map.items()}

SIZE_SUFFIX_MAP = {"Lg": "ë¼ì§€", "Rg": "ë ˆê·¤ëŸ¬", "Sm": "ìŠ¤ëª°"}
REV_SIZE_SUFFIX_MAP = {"ë¼ì§€": "Lg", "ë ˆê·¤ëŸ¬": "Rg", "ìŠ¤ëª°": "Sm"}

detail_base_map = {
    "Almond Croissant": "ì•„ëª¬ë“œ í¬ë£¨ì•„ìƒ",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Traditional Blend Chai": "íŠ¸ë˜ë””ì…”ë„ ë¸”ë Œë“œ ì°¨ì´",
}
rev_detail_base_map = {v: k for k, v in detail_base_map.items()}

def to_korean_detail(name: str) -> str:
    s = str(name).strip()
    if re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s):
        return s
    m = re.search(r"\s+(Lg|Rg|Sm)$", s)
    size_en = m.group(1) if m else None
    base_en = s[: -len(size_en) - 1] if size_en else s
    base_ko = detail_base_map.get(base_en, base_en)
    if size_en:
        return f"{base_ko} ({SIZE_SUFFIX_MAP[size_en]})"
    return base_ko

def from_korean_detail(display: str) -> str:
    s = str(display).strip()
    if re.search(r"\s+(Lg|Rg|Sm)$", s):
        return s
    m = re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s)
    size_ko = m.group(1) if m else None
    base_ko = re.sub(r"\s*\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", "", s)
    base_en = rev_detail_base_map.get(base_ko, base_ko)
    if size_ko:
        return f"{base_en} {REV_SIZE_SUFFIX_MAP[size_ko]}"
    return base_en

weekday_map = {"Monday": "ì›”", "Tuesday": "í™”", "Wednesday": "ìˆ˜",
               "Thursday": "ëª©", "Friday": "ê¸ˆ", "Saturday": "í† ", "Sunday": "ì¼"}
weekday_order_kr = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]

def map_series(s: pd.Series, mapping: dict) -> pd.Series:
    return s.apply(lambda x: mapping.get(x, x))

# ----------------------
# âœ… UoM(ë‹¨ìœ„) ìœ í‹¸
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def normalize_uom(u: str | None) -> str:
    u = (u or "ea").strip().lower()
    if u in {"g", "gram", "grams", "ê·¸ë¨", "kg", "í‚¬ë¡œê·¸ë¨"}:
        return "g"
    if u in {"ml", "ë°€ë¦¬ë¦¬í„°", "l", "ë¦¬í„°"}:
        return "ml"
    return "ea"

def convert_qty(qty: float, from_uom: str, to_uom: str) -> float:
    fu = normalize_uom(from_uom)
    tu = normalize_uom(to_uom)
    if fu == tu:
        return float(qty)
    return float(qty)

def safe_float(x, default=0.0):
    if x is None:
        return default
    try:
        if isinstance(x, (int, float)):
            try:
                if pd.isna(x):
                    return default
            except Exception:
                pass
            return float(x)
        if isinstance(x, str):
            s = x.strip()
            if s == "" or s.lower() in {"nan", "none"}:
                return default
            s = s.replace(",", "")
            return float(s)
        return float(x)
    except Exception:
        return default

# ----------------------
# âœ… ë‚ ì§œ íŒŒì„œ: ëª…ì‹œ í˜•ì‹ ìš°ì„  + ê²½ê³ ì—†ëŠ” í´ë°±
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def parse_mixed_dates(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip()
    out = pd.Series(pd.NaT, index=s.index, dtype="datetime64[ns]")
    patterns = [
        (r'^\d{4}-\d{2}-\d{2}$', '%Y-%m-%d'),
        (r'^\d{4}/\d{2}/\d{2}$', '%Y/%m/%d'),
        (r'^\d{2}/\d{2}/\d{4}$', '%m/%d/%Y'),
        (r'^\d{2}-\d{2}-\d{4}$', '%m-%d-%Y'),
        (r'^\d{4}\.\d{2}\.\d{2}$', '%Y.%m.%d'),
        (r'^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}$', '%Y-%m-%d %H:%M:%S'),
        (r'^\d{2}/\d{2}/\d{4}\s+\d{2}:\d{2}:\d{2}$', '%m/%d/%Y %H:%M:%S'),
    ]
    for pat, fmt in patterns:
        mask = s.str.match(pat)
        if mask.any():
            out.loc[mask] = pd.to_datetime(s.loc[mask], format=fmt, errors='coerce')
    remain = out.isna()
    if remain.any():
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", UserWarning)
            out.loc[remain] = pd.to_datetime(s.loc[remain], errors='coerce')
    return out

# ----------------------
# 1ï¸âƒ£ CSV ë¡œë“œ (ìƒ˜í”Œ ìƒì„± ì—†ìŒ)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_data(ttl=0)
def load_csv(path: Path) -> pd.DataFrame:
    if not path.exists():
        st.error(f"CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì— 'Coffee Shop Sales.csv'ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\n(í˜„ì¬ ì°¾ëŠ” ê²½ë¡œ: {path})")
        st.stop()
    df = pd.read_csv(path)
    df = df.rename(columns={
        'transaction_id': 'ê±°ë˜ë²ˆí˜¸', 'transaction_date': 'ë‚ ì§œ', 'transaction_time': 'ì‹œê°„',
        'transaction_qty': 'ìˆ˜ëŸ‰', 'store_id': 'ê°€ê²ŒID', 'store_location': 'ê°€ê²Œìœ„ì¹˜',
        'product_id': 'ìƒí’ˆID', 'unit_price': 'ë‹¨ê°€', 'product_category': 'ìƒí’ˆì¹´í…Œê³ ë¦¬',
        'product_type': 'ìƒí’ˆíƒ€ì…', 'product_detail': 'ìƒí’ˆìƒì„¸', 'Revenue': 'ìˆ˜ìµ'
    })
    df['ìˆ˜ìµ'] = df['ìˆ˜ìµ'].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
    df['ë‹¨ê°€'] = df['ë‹¨ê°€'].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
    if USE_KRW_CONVERSION:
        df['ìˆ˜ìµ'] *= KRW_PER_USD
        df['ë‹¨ê°€'] *= KRW_PER_USD
    df['ë‚ ì§œ'] = parse_mixed_dates(df['ë‚ ì§œ'])
    if 'ì‹œê°„' in df.columns:
        df['ì‹œ'] = pd.to_datetime(df['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df['ì‹œ'] = None
    df['ìš”ì¼'] = df['ë‚ ì§œ'].dt.day_name()
    df['ì›”'] = df['ë‚ ì§œ'].dt.month
    return df

df_csv = load_csv(CSV_PATH)

# ----------------------
# 2ï¸âƒ£ Firestore(íŒë§¤) ë¡œë“œ
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def load_sales_from_firestore() -> pd.DataFrame:
    docs = db.collection(SALES_COLLECTION).stream()
    data = [d.to_dict() for d in docs]
    df_fb = pd.DataFrame(data)
    if df_fb.empty:
        return df_fb
    if 'ë‚ ì§œ' in df_fb.columns:
        df_fb['ë‚ ì§œ'] = parse_mixed_dates(df_fb['ë‚ ì§œ'])
    if 'ìˆ˜ìµ' in df_fb.columns:
        df_fb['ìˆ˜ìµ'] = pd.to_numeric(df_fb['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_fb.columns:
        df_fb['ë‹¨ê°€'] = pd.to_numeric(df_fb['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_fb.columns:
        df_fb['ìˆ˜ëŸ‰'] = pd.to_numeric(df_fb['ìˆ˜ëŸ‰'], errors='coerce')
    if 'ì‹œê°„' in df_fb.columns:
        df_fb['ì‹œ'] = pd.to_datetime(df_fb['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df_fb['ì‹œ'] = None
    df_fb['ìš”ì¼'] = df_fb['ë‚ ì§œ'].dt.day_name()
    df_fb['ì›”'] = df_fb['ë‚ ì§œ'].dt.month
    return df_fb

df_fb = load_sales_from_firestore()

def load_sales_with_id():
    docs = db.collection(SALES_COLLECTION).stream()
    rows = []
    for d in docs:
        rec = d.to_dict()
        rec["_id"] = d.id
        rows.append(rec)
    df_raw = pd.DataFrame(rows)
    if df_raw.empty:
        return df_raw, df_raw
    if 'ë‚ ì§œ' in df_raw.columns:
        df_raw['ë‚ ì§œ'] = parse_mixed_dates(df_raw['ë‚ ì§œ'])
    if 'ìˆ˜ìµ' in df_raw: df_raw['ìˆ˜ìµ'] = pd.to_numeric(df_raw['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_raw: df_raw['ë‹¨ê°€'] = pd.to_numeric(df_raw['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_raw: df_raw['ìˆ˜ëŸ‰'] = pd.to_numeric(df_raw['ìˆ˜ëŸ‰'], errors='coerce')
    df_view = df_raw.copy()
    if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df_view: df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
    if 'ìƒí’ˆíƒ€ì…' in df_view: df_view['ìƒí’ˆíƒ€ì…'] = map_series(df_view['ìƒí’ˆíƒ€ì…'], type_map)
    if 'ìƒí’ˆìƒì„¸' in df_view: df_view['ìƒí’ˆìƒì„¸'] = df_view['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)
    return df_raw, df_view

# ==============================================================
# === [L4 ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë”© ë¸”ë¡] ===
# (ìˆœì„œ ë¬¸ì œ í•´ê²°: 'ì •ì˜'ë¥¼ 'í˜¸ì¶œ'ë³´ë‹¤ ì•ìœ¼ë¡œ ì´ë™)
# ==============================================================

# --- 1. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 1: Inventory) ---
@st.cache_data(ttl=60)
def load_inventory_df() -> pd.DataFrame:
    inv_docs = db.collection(INVENTORY_COLLECTION).stream()
    rows = []
    for d in inv_docs:
        doc = d.to_dict() or {}
        en = doc.get("ìƒí’ˆìƒì„¸_en", d.id)
        ko = to_korean_detail(en)
        
        # [L4] ì›ê°€ ì •ë³´ ë¡œë“œ
        cost_unit_size = safe_float(doc.get("cost_unit_size", 1.0), 1.0)
        cost_per_unit = safe_float(doc.get("cost_per_unit", 0.0), 0.0)
        
        # 1g/1ml/1eaë‹¹ ì›ê°€ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        unit_cost = cost_per_unit / cost_unit_size if cost_unit_size > 0 else 0.0
        
        rows.append({
            "ìƒí’ˆìƒì„¸_en": en,
            "ìƒí’ˆìƒì„¸": ko,
            "ì´ˆê¸°ì¬ê³ ": doc.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "í˜„ì¬ì¬ê³ ": doc.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "uom": normalize_uom(doc.get("uom", "ea")),
            "is_ingredient": bool(doc.get("is_ingredient", False)),
            
            # [L4] ì›ê°€ ì»¬ëŸ¼ ì¶”ê°€
            "cost_unit_size": cost_unit_size, # ë§¤ì… ë‹¨ìœ„ (e.g., 1000)
            "cost_per_unit": cost_per_unit,  # ë§¤ì…ê°€ (e.g., 30000)
            "unit_cost": unit_cost           # 1g/ml/eaë‹¹ ì›ê°€ (e.g., 30)
        })
    
    # === [ë¹ˆí‹ˆ ìˆ˜ì •] inventoryê°€ ë¹„ì–´ìˆì–´ë„ ì»¬ëŸ¼ì€ ìœ ì§€ ===
    df = pd.DataFrame(rows, columns=[
        "ìƒí’ˆìƒì„¸_en", "ìƒí’ˆìƒì„¸", "ì´ˆê¸°ì¬ê³ ", "í˜„ì¬ì¬ê³ ", "uom", "is_ingredient",
        "cost_unit_size", "cost_per_unit", "unit_cost" # [L4]
    ])
    return df

# --- 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 2: SKU Params) ---
@st.cache_data(ttl=60)
def load_sku_params() -> pd.DataFrame:
    try:
        docs = db.collection(SKU_PARAMS_COLLECTION).stream()
    except Exception:
        docs = []
    rows = []
    for d in docs:
        item = d.to_dict() or {}
        try:
            item["_id"] = d.id
        except Exception:
            item["_id"] = item.get("_id", "")
        rows.append(item)
    dfp = pd.DataFrame(rows)
    if dfp.empty:
        dfp = pd.DataFrame(columns=[
            "_id","sku_en","lead_time_days","safety_stock_units","target_days","grams_per_cup","expiry_days"
        ])
    defaults = {
        "lead_time_days": 3,
        "safety_stock_units": 10,
        "target_days": 21,
        "grams_per_cup": 18.0,
        "expiry_days": 28,
    }
    for col, default in defaults.items():
        if col not in dfp.columns:
            dfp[col] = default
        else:
            dfp[col] = pd.to_numeric(dfp[col], errors="coerce").fillna(default)
    return dfp

# --- 3. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì •ì˜ 3: Ensure Inventory Doc) ---
def ensure_inventory_doc(product_detail_en: str, uom: str = "ea", is_ingredient: bool = False):
    ref = db.collection(INVENTORY_COLLECTION).document(product_detail_en)
    snap = ref.get()
    if snap.exists:
        data = snap.to_dict() or {}
        patch = {}
        if normalize_uom(data.get("uom")) != normalize_uom(uom):
            patch["uom"] = normalize_uom(uom)
        if bool(data.get("is_ingredient", False)) != bool(is_ingredient):
            patch["is_ingredient"] = bool(is_ingredient)
        if patch:
            ref.update(patch)
        return ref
    else:
        ref.set({
            "ìƒí’ˆìƒì„¸_en": product_detail_en,
            "ì´ˆê¸°ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "í˜„ì¬ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "uom": normalize_uom(uom),
            "is_ingredient": bool(is_ingredient),
            # [L4] ì›ê°€ ê¸°ë³¸ê°’
            "cost_unit_size": 1.0,
            "cost_per_unit": 0.0,
            "unit_cost": 0.0,
        })
        return ref

def ensure_ingredient_sku(ingredient_en: str, uom: str = "ea"):
    return ensure_inventory_doc(ingredient_en, uom=uom, is_ingredient=True)


# --- 4. ë©”ì¸ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (í˜¸ì¶œ 1) ---
@st.cache_data(ttl=60)
def load_all_core_data():
    """
    [L4 ìˆ˜ì •] ì•± ì‹¤í–‰ ì‹œ ëª¨ë“  í•µì‹¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    (ì´ì œ ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ì–´ë„, í•„ìš”í•œ í•¨ìˆ˜ë“¤ì´ 'ìœ„ì—' ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.)
    """
    # 1. Sales (df)
    df = pd.concat([df_csv, df_fb], ignore_index=True)
    if 'ìš”ì¼' in df.columns:
        df['ìš”ì¼'] = map_series(df['ìš”ì¼'], weekday_map)
    if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df.columns:
        df['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
    if 'ìƒí’ˆíƒ€ì…' in df.columns:
        df['ìƒí’ˆíƒ€ì…'] = map_series(df['ìƒí’ˆíƒ€ì…'], type_map)
    if 'ìƒí’ˆìƒì„¸' in df.columns:
        df['ìƒí’ˆìƒì„¸'] = df['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)
    
    # 2. Inventory (df_inv) - [L4] ì›ê°€ ê³„ì‚°ì´ í¬í•¨ëœ í•¨ìˆ˜ë¡œ í˜¸ì¶œ
    df_inv = load_inventory_df() 
    
    # 3. Recipes (recipes)
    recipes = {}
    try:
        recipe_docs = db.collection(RECIPES_COLLECTION).stream()
        for d in recipe_docs:
            data = d.to_dict()
            if data and "ingredients" in data:
                recipes[d.id] = data["ingredients"]
    except Exception as e:
        st.error(f"ë ˆì‹œí”¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
    # 4. Params (df_params)
    df_params = load_sku_params()
    
    return df, df_inv, recipes, df_params

# --- 5. ë©”ì¸ ë°ì´í„° ë¡œë“œ 'ì‹¤í–‰' ---
try:
    #data_load_state = st.info("ëª¨ë“  í•µì‹¬ ë°ì´í„°(íŒë§¤, ì¬ê³ , ë ˆì‹œí”¼) ë¡œë“œ ì¤‘... â³")
    df, df_inv, RECIPES, df_params = load_all_core_data()
    #data_load_state.success("âœ… ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
except Exception as e:
    #data_load_state.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()
    

# --- 6. ì›ê°€(COGS) ê³„ì‚° í•¨ìˆ˜ (ì •ì˜ 4) ---
@st.cache_data(ttl=600)
def calculate_menu_cogs(df_inv: pd.DataFrame, recipes: dict) -> dict:
    """
    (L4) 'df_inv'ì˜ 'unit_cost'ì™€ 'recipes'ë¥¼ ì‚¬ìš©í•´
    ëª¨ë“  ë©”ë‰´ì˜ COGS(ë§¤ì¶œ ì›ê°€)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    if 'unit_cost' not in df_inv.columns:
        st.error("calculate_menu_cogs: df_invì— 'unit_cost' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {}
        
    # 1. ì¬ë£Œ ì›ê°€ ë§µ ìƒì„± (sku_en -> unit_cost)
    ingredient_costs = df_inv[df_inv['is_ingredient'] == True].set_index('ìƒí’ˆìƒì„¸_en')['unit_cost'].to_dict()
    
    menu_cogs = {}
    
    # 2. ëª¨ë“  ë ˆì‹œí”¼ë¥¼ ìˆœíšŒí•˜ë©° ì›ê°€ ê³„ì‚°
    for menu_sku_en, ingredients in recipes.items():
        total_cogs = 0.0
        for item in ingredients:
            ing_sku_en = item["ingredient_en"]
            qty = safe_float(item.get("qty", 0.0))
            waste_pct = safe_float(item.get("waste_pct", 0.0))
            
            # 3. ì¬ë£Œ ì›ê°€ ê°€ì ¸ì˜¤ê¸°
            unit_cost = safe_float(ingredient_costs.get(ing_sku_en, 0.0))
            
            # 4. ì†ì‹¤ë¥ (waste_pct)ì„ ì›ê°€ì— ë°˜ì˜
            cost_with_waste = unit_cost * (1 + (waste_pct / 100.0))
            
            # 5. ì´ ì¬ë£Œì˜ ì´ ì›ê°€ = (ì›ê°€ * ìˆ˜ëŸ‰)
            total_cogs += (cost_with_waste * qty)
        
        menu_cogs[menu_sku_en] = total_cogs
        
    return menu_cogs

# --- 7. ì›ê°€(COGS) 'ì‹¤í–‰' ë° 'df'ì— í†µí•© ---
try:
    #cogs_load_state = st.info("ë©”ë‰´ë³„ ì›ê°€(COGS) ë° ë§ˆì§„ ê³„ì‚° ì¤‘... ğŸ’°")
    
    # 1. ë©”ë‰´ë³„ COGS ë”•ì…”ë„ˆë¦¬ ìƒì„± (e.g., {'Americano': 600.0})
    menu_cogs_map = calculate_menu_cogs(df_inv, RECIPES)
    
    # 2. 'ìƒí’ˆìƒì„¸'(í•œê¸€) <-> 'menu_sku_en' ë§µ ìƒì„±
    cogs_map_kr = {to_korean_detail(sku_en): cogs for sku_en, cogs in menu_cogs_map.items()}

    # 3. 'df'ì— 'ì›ê°€' ì»¬ëŸ¼ ì¶”ê°€
    df['ì›ê°€'] = df['ìƒí’ˆìƒì„¸'].map(cogs_map_kr).fillna(0.0)
    
    # 4. 'ìˆœì´ìµ' ë° 'ë§ˆì§„ìœ¨' ê³„ì‚°
    df['ìˆ˜ìµ'] = pd.to_numeric(df['ìˆ˜ìµ'], errors='coerce').fillna(0)
    df['ìˆœì´ìµ'] = df['ìˆ˜ìµ'] - df['ì›ê°€']
    df['ë§ˆì§„ìœ¨(%)'] = (df['ìˆœì´ìµ'] / df['ìˆ˜ìµ']).replace([pd.NA, float('inf'), float('-inf')], 0).fillna(0) * 100
    
    #cogs_load_state.success("âœ… ì›ê°€ ë° ë§ˆì§„ ê³„ì‚° ì™„ë£Œ!")

except Exception as e:
    #cogs_load_state.error(f"ì›ê°€ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
    # ì›ê°€ ì—†ì´ë„ ì•±ì€ ê³„ì† ì‘ë™í•´ì•¼ í•¨
    df['ì›ê°€'] = 0.0
    df['ìˆ˜ìµ'] = pd.to_numeric(df['ìˆ˜ìµ'], errors='coerce').fillna(0)
    df['ìˆœì´ìµ'] = df['ìˆ˜ìµ']
    df['ë§ˆì§„ìœ¨(%)'] = 0.0

# --- 8. 'load_recipe' (L4) í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---
@st.cache_data(ttl=60)
def load_recipe(menu_sku_en: str) -> list[dict]:
    """[L4 ìˆ˜ì •] DBë¥¼ ë§¤ë²ˆ ì¡°íšŒí•˜ëŠ” ëŒ€ì‹ , ì „ì—­ 'RECIPES' ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©"""
    global RECIPES
    return RECIPES.get(menu_sku_en, [])

# --- 9. (ê¸°ì¡´ í•¨ìˆ˜) ì¬ê³  ì°¨ê° í•¨ìˆ˜ë“¤ (ìˆœì„œ ë³€ê²½) ---
def deduct_stock(product_detail_en: str, qty: int):
    ref = ensure_inventory_doc(product_detail_en)
    snap = ref.get()
    data = snap.to_dict() if snap.exists else {}
    init_stock = int(data.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    cur_stock = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    new_stock = max(cur_stock - int(qty), 0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return init_stock, new_stock

def get_all_recipe_ingredients() -> set:
    ingredients = set()
    try:
        docs = db.collection(RECIPES_COLLECTION).stream()
        for d in docs:
            items = (d.to_dict() or {}).get("ingredients", [])
            for it in items:
                ingredients.add(it["ingredient_en"])
    except Exception:
        pass
    return ingredients

def deduct_inventory(ingredient_en: str, qty: float, uom: str):
    ref = ensure_inventory_doc(ingredient_en, uom=uom)
    snap = ref.get()
    data = snap.to_dict() or {}
    cur = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    inv_uom = normalize_uom(data.get("uom", "ea"))
    use_qty = convert_qty(qty, from_uom=uom, to_uom=inv_uom)
    new_stock = max(cur - use_qty, 0.0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return cur, new_stock, inv_uom

def apply_recipe_deduction(menu_sku_en: str, sold_qty: int, commit: bool = True) -> list[dict]:
    items = load_recipe(menu_sku_en)
    summary: list[dict] = []
    if not items:
        ref = ensure_inventory_doc(menu_sku_en, uom="ea")
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used = float(sold_qty)
        after = max(before - used, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": menu_sku_en, "used": used, "uom": inv_uom, "before": before, "after": after})
        return summary
    for it in items:
        ing = it["ingredient_en"]
        uom = normalize_uom(it["uom"])
        qty_per_unit = safe_float(it["qty"])
        waste_pct = safe_float(it["waste_pct"], 0)
        total_used = (qty_per_unit * sold_qty) * (1 + (waste_pct / 100.0))
        ref = ensure_inventory_doc(ing, uom=uom, is_ingredient=True)
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used_converted = convert_qty(total_used, from_uom=uom, to_uom=inv_uom)
        after = max(before - used_converted, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": ing, "used": used_converted, "uom": inv_uom, "before": before, "after": after})
    return summary

def adjust_inventory_by_recipe(menu_sku_en: str,
                               qty_diff: int,
                               move_type: str = "manual_adjust",
                               note: str = ""):
    if qty_diff == 0:
        return
    details = apply_recipe_deduction(menu_sku_en, qty_diff, commit=True)
    log_doc = {
        "ts": datetime.now().isoformat(),
        "type": move_type,
        "menu_sku_en": menu_sku_en,
        "qty": qty_diff,
        "note": note,
        "details": details,
    }
    db.collection(STOCK_MOVES_COLLECTION).add(log_doc)

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í˜¸ì¶œ í—¬í¼
def call_openai_api(user_prompt: str, data_context: str, model="gpt-3.5-turbo"):
    """
    [AI ìˆ˜ì • 2] data_context(ì‚¬ì‹¤)ì™€ user_prompt(ìš”ì²­)ë¥¼ ë¶„ë¦¬í•˜ì—¬ AIê°€ 'ê±°ì§“ë§'ì„ í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì •.
    data_contextëŠ” 'system' ë©”ì‹œì§€ë¡œ, user_promptëŠ” 'user' ë©”ì‹œì§€ë¡œ ì „ë‹¬.
    """
    
    # 1. API í‚¤ê°€ ì—†ëŠ” ê²½ìš°
    if not openai.api_key:
        time.sleep(1.5) 
        st.error("OpenAI API í‚¤ê°€ 'secrets.toml'ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return (f"âš ï¸ **[AI ì‘ë‹µ ì‹¤íŒ¨ (API í‚¤ ì—†ìŒ)]**\n\n"
                f"'secrets.toml'ì— OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
                f"--- (ë°ì´í„° ì»¨í…ìŠ¤íŠ¸) ---\n{data_context}\n\n"
                f"--- (ì‚¬ìš©ì ìš”ì²­) ---\n{user_prompt}")

    # 2. API í˜¸ì¶œ ì‹œë„
    try:
        # [ìˆ˜ì •] ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëª…í™•íˆ ë¶„ë¦¬
        response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": (
                    "ë‹¹ì‹ ì€ ì¹´í˜ ìš´ì˜ ë° ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                    "ë‹¤ìŒì€ í˜„ì¬ ì¹´í˜ì˜ ì‹¤ì œ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ 'ì‚¬ì‹¤'ë¡œ ê°„ì£¼í•˜ê³ , "
                    "ì´ 'ì‚¬ì‹¤'ì— ê¸°ë°˜í•´ì„œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì ˆëŒ€ ë°ì´í„°ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.\n\n"
                    f"--- [ì¹´í˜ ì‹¤ì œ ë°ì´í„°] ---\n{data_context}\n--- [ë°ì´í„° ë] ---"
                )},
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.choices[0].message.content
        
    # 3. [ìˆ˜ì •] ì”ì•¡ ë¶€ì¡± ë˜ëŠ” API ì˜¤ë¥˜ ë°œìƒ ì‹œ
    except openai.InsufficientQuotaError as e:
        # "ê°€ì§œ ì‘ë‹µ"ì´ ì•„ë‹Œ, ëª…í™•í•œ 'ì˜¤ë¥˜'ì™€ 'ì‹œë„í–ˆë˜ ë‚´ìš©'ì„ ë°˜í™˜
        st.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: ì”ì•¡(Quota)ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì˜¤ë¥˜: {e.message})")
        return (f"âš ï¸ **[AI ì‘ë‹µ ì‹¤íŒ¨ (ì”ì•¡ ë¶€ì¡±)]**\n\n"
                f"OpenAI ê³„ì •ì˜ ì”ì•¡ì´ ë¶€ì¡±í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"--- (AIê°€ ì „ë‹¬ë°›ì€ ë°ì´í„°) ---\n{data_context}\n\n"
                f"--- (AIê°€ ìš”ì²­ë°›ì€ ì‘ì—…) ---\n{user_prompt}")
        
    except openai.AuthenticationError as e:
        st.error("âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: API í‚¤ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. 'secrets.toml'ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# SPRINT 2: Prophet ìˆ˜ìš” ì˜ˆì¸¡ í—¬í¼
@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
def get_item_forecast(df_all_sales: pd.DataFrame, menu_sku_en: str, days_to_forecast: int):
    """Prophetì„ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ë©”ë‰´ì˜ ë¯¸ë˜ íŒë§¤ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    
    try:
        # === [ìˆ˜ì •] ë‚ ì§œ ë°ì´í„° ì•ˆì •í™” ===
        df_all_sales = df_all_sales.copy()
        df_all_sales['ë‚ ì§œ'] = pd.to_datetime(df_all_sales['ë‚ ì§œ'], errors='coerce')
        df_all_sales = df_all_sales.dropna(subset=['ë‚ ì§œ'])
        # === [ìˆ˜ì • ë] ===

        # === [ë²„ê·¸ ìˆ˜ì •] ì´ë¦„ ë¶ˆì¼ì¹˜ í•´ê²° ===
        base_sku_en = re.sub(r"\s+(Lg|Rg|Sm)$", "", menu_sku_en.strip())
        menu_name_kr_base = to_korean_detail(base_sku_en) # This should now be 'ì•„ë©”ë¦¬ì¹´ë…¸'
        
        original_menu_name_kr = to_korean_detail(menu_sku_en)
        if original_menu_name_kr != menu_name_kr_base:
            st.info(f"AI ì˜ˆì¸¡: '{original_menu_name_kr}' ë©”ë‰´ì˜ ì˜ˆì¸¡ì„ ìœ„í•´, íŒë§¤ ë°ì´í„°ì—ì„œ '{menu_name_kr_base}'(ìœ¼)ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.")
        # === [ë²„ê·¸ ìˆ˜ì • ë] ===

        df_item = df_all_sales[
            df_all_sales['ìƒí’ˆìƒì„¸'] == menu_name_kr_base
        ].copy()
        
        if df_item.empty:
            st.warning(f"íŒë§¤ ë°ì´í„°(df)ì—ì„œ '{menu_name_kr_base}' ì´ë¦„ì˜ íŒë§¤ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„° 0ê±´)")
            return None, None # íŒë§¤ ë°ì´í„° ì—†ìŒ

        # Prophetì´ ë‚ ì§œ ë°ì´í„°ë¥¼ ì‹ ë¢°í•˜ë„ë¡ ì „ì²˜ë¦¬
        df_agg = df_item.groupby('ë‚ ì§œ')['ìˆ˜ëŸ‰'].sum().reset_index()
        df_agg['ë‚ ì§œ'] = pd.to_datetime(df_agg['ë‚ ì§œ'])
        
        if not df_agg.empty:
            date_range = pd.date_range(start=df_agg['ë‚ ì§œ'].min(), end=df_agg['ë‚ ì§œ'].max())
            df_agg = df_agg.set_index('ë‚ ì§œ').reindex(date_range, fill_value=0).reset_index()
            df_agg.rename(columns={'index': 'ë‚ ì§œ'}, inplace=True)
        
        df_prophet = df_agg[['ë‚ ì§œ', 'ìˆ˜ëŸ‰']].rename(columns={"ë‚ ì§œ": "ds", "ìˆ˜ëŸ‰": "y"})

        if len(df_prophet) < 7: # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜ˆì¸¡ ë¶ˆê°€
            return None, None

        m = Prophet(weekly_seasonality=True, yearly_seasonality=False, daily_seasonality=False)
        m.fit(df_prophet)
        future = m.make_future_dataframe(periods=days_to_forecast)
        forecast = m.predict(future)
        
        # === [ë¹ˆí‹ˆ ìˆ˜ì •] 'y' ì»¬ëŸ¼ì´ ë¹ ì§€ëŠ” ì˜¤ë¥˜ ìˆ˜ì • ===
        # 'ds'(ë‚ ì§œ)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 'forecast'(ì˜ˆì¸¡ê°’)ì™€ 'df_prophet'(ì‹¤ì œê°’ y)ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.
        forecast_chart_data = forecast.merge(df_prophet, on='ds', how='left')
        
        # ìŒìˆ˜ ì˜ˆì¸¡ì€ 0ìœ¼ë¡œ
        forecast_chart_data['yhat'] = forecast_chart_data['yhat'].clip(lower=0) 
        
        # ì˜ˆì¸¡ëœ ê¸°ê°„(target_days)ì˜ ì´ ì†Œì§„ëŸ‰ í•©ê³„ ë°˜í™˜
        predicted_sum = forecast_chart_data.iloc[-days_to_forecast:]['yhat'].sum()
        
        # [ìˆ˜ì •] 'forecast'ê°€ ì•„ë‹Œ, 'y' ì»¬ëŸ¼ì´ í•©ì³ì§„ 'forecast_chart_data'ë¥¼ ë°˜í™˜
        return max(predicted_sum, 0), forecast_chart_data 

    except Exception as e:
        st.warning(f"Prophet ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None
# === [AI/ML í†µí•© ì¶”ê°€] ===

# ----------
# [AI/ML í†µí•© ìˆ˜ì • 6] 
# ( compute_ingredient_metrics_for_menu )
# SPRINT 2: ML ìˆ˜ìš” ì˜ˆì¸¡ ë¡œì§ ìˆ˜ì •
# - [ë¹ˆí‹ˆ ìˆ˜ì •] "ì „ì²´ ê±°ë˜ ë‚´ì—­"ì´ ê·¸ë˜í”„ì— ë°˜ì˜ë˜ë„ë¡ .iloc[-90:] ì‚­ì œ
# - [ê¸°ëŠ¥ ì¶”ê°€] 'ì‹¤ì œ íŒë§¤ëŸ‰(y)'ê³¼ 'AI ì˜ˆì¸¡(yhat)'ì„ ê·¸ë˜í”„ì— ë™ì‹œ í‘œì‹œ
# ----------
def compute_ingredient_metrics_for_menu(
    menu_sku_en: str,
    df_all_sales: pd.DataFrame, # ì „ì²´ íŒë§¤ ë°ì´í„°(df)
    df_inv: pd.DataFrame,
    df_params: pd.DataFrame,
    window_days: int = 28 # [ìˆ˜ì •] ì´ ê°’ì€ ì´ì œ AI ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©ë¨
) -> pd.DataFrame:
    """
    [AI ìˆ˜ì •ë¨] íŠ¹ì • ë©”ë‰´ì˜ ë ˆì‹œí”¼ì™€ *ë¯¸ë˜ ì˜ˆì¸¡ íŒë§¤ëŸ‰* ê¸°ë°˜ìœ¼ë¡œ ì¬ë£Œë³„ ì§€í‘œ ê³„ì‚°.
    ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ ê³¼ê±° ìœˆë„ìš°(window_days) í‰ê· ìœ¼ë¡œ ëŒ€ì²´.
    """
    items = load_recipe(menu_sku_en)
    if not items:
        return pd.DataFrame()

    # === [ë²„ê·¸ ìˆ˜ì •] ì´ë¦„ ë¶ˆì¼ì¹˜ í•´ê²° (Historical) ===
    base_sku_en = re.sub(r"\s+(Lg|Rg|Sm)$", "", menu_sku_en.strip())
    menu_name_kr_base = to_korean_detail(base_sku_en) # 'ì•„ë©”ë¦¬ì¹´ë…¸'
    # === [ë²„ê·¸ ìˆ˜ì • ë] ===

    # === [ìˆ˜ì •] ì˜ˆì¸¡ ê¸°ê°„ì„ 21ì¼ë¡œ ê³ ì •í•˜ì—¬ ë²„ê·¸ í•´ê²° ===
    target_days_forecast = 21
    window_days_fallback = 21 # AI ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„ë„ 21ì¼ë¡œ í†µì¼
    st.info(f"ğŸ¤– AI ìˆ˜ìš” ì˜ˆì¸¡ì„ í–¥í›„ **{target_days_forecast}ì¼** ê¸°ì¤€ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    # === [ìˆ˜ì • ë] ===

    # 1. (Fallbackìš©) ê³¼ê±° ìœˆë„ìš° íŒë§¤ëŸ‰ ì§‘ê³„
    sold_sum_historical = 0.0
    if "ë‚ ì§œ" in df_all_sales.columns and pd.api.types.is_datetime64_any_dtype(df_all_sales["ë‚ ì§œ"]):
        max_day = df_all_sales["ë‚ ì§œ"].max()
        min_day = max_day - pd.Timedelta(days=window_days_fallback - 1)
        df_win = df_all_sales[(df_all_sales["ë‚ ì§œ"] >= min_day) & (df_all_sales["ë‚ ì§œ"] <= max_day)]
        sold_sum_historical = df_win[df_win['ìƒí’ˆìƒì„¸'] == menu_name_kr_base]['ìˆ˜ëŸ‰'].sum()
    
    # 2. [AI/ML] ë¯¸ë˜ ìˆ˜ìš” ì˜ˆì¸¡
    predicted_menu_sales, forecast_chart_data = get_item_forecast(
        df_all_sales, menu_sku_en, days_to_forecast=target_days_forecast
    )

    # 3. ì‚¬ìš©í•  íŒë§¤ëŸ‰(sold_sum) ë° ê¸°ì¤€ì¼(days) ê²°ì •
    use_historical_fallback = False
    
    if predicted_menu_sales is None or predicted_menu_sales == 0:
        st.warning(f"ğŸ¤– AI ì˜ˆì¸¡: '{to_korean_detail(menu_sku_en)}'ì˜ íŒë§¤ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ê³¼ê±° {window_days_fallback}ì¼ íŒë§¤ëŸ‰: {sold_sum_historical}ê°œ)ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        sold_sum = sold_sum_historical # ê³¼ê±° ë°ì´í„° ì‚¬ìš©
        days = window_days_fallback
        use_historical_fallback = True
    else:
        st.success(f"ğŸ¤– **AI ì˜ˆì¸¡**: '{to_korean_detail(menu_sku_en)}'ì˜ í–¥í›„ **{target_days_forecast}ì¼ê°„** ì˜ˆìƒ íŒë§¤ëŸ‰ì„ **{predicted_menu_sales:,.0f}ê°œ**ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.")
        sold_sum = predicted_menu_sales # ì˜ˆì¸¡ê°’ìœ¼ë¡œ ëŒ€ì²´
        days = target_days_forecast # ê¸°ì¤€ì¼ë„ ì˜ˆì¸¡ ê¸°ê°„ìœ¼ë¡œ ë³€ê²½
        
        # (ì˜µì…˜) ì˜ˆì¸¡ ì°¨íŠ¸ í‘œì‹œ
        if forecast_chart_data is not None:
            try:
                # === [ë¹ˆí‹ˆ ìˆ˜ì •] .iloc[-90:] ì‚­ì œ! ===
                # ì´ì œ Prophetì´ í•™ìŠµí•œ 'ì „ì²´' ê³¼ê±° ë°ì´í„°ì™€ 'ë¯¸ë˜' ì˜ˆì¸¡ì„ ëª¨ë‘ í‘œì‹œí•©ë‹ˆë‹¤.
                fig = px.line(forecast_chart_data, x='ds', y='yhat', 
                                title=f"'{to_korean_detail(menu_sku_en)}' ì „ì²´ ê¸°ê°„ ìˆ˜ìš” ì˜ˆì¸¡", 
                                labels={'ds':'ë‚ ì§œ', 'yhat':'ì˜ˆì¸¡ íŒë§¤ëŸ‰'})
                
                # === [ê¸°ëŠ¥ ì¶”ê°€] 'ì‹¤ì œ' íŒë§¤ëŸ‰ ë°ì´í„°(y)ë¥¼ 'ì 'ìœ¼ë¡œ ì¶”ê°€ ===
                # (forecast_chart_dataì—ëŠ” Prophetì´ í•™ìŠµí•œ 'ì‹¤ì œ' yê°’ì´ í¬í•¨ë¨)
                # 'y' ê°’ì´ NaNì´ ì•„ë‹Œ (ì¦‰, ê³¼ê±° ë°ì´í„°ê°€ ìˆëŠ”) ë¶€ë¶„ë§Œ
                actual_data = forecast_chart_data.dropna(subset=['y'])
                fig.add_scatter(x=actual_data['ds'], y=actual_data['y'], 
                                mode='markers', 
                                name='ì‹¤ì œ íŒë§¤ëŸ‰', 
                                marker=dict(color='rgba(0,0,255,0.5)', size=5)) # ë°˜íˆ¬ëª… íŒŒë€ìƒ‰ ì 
                
                # ë¶ˆí™•ì‹¤ì„± (ê¸°ì¡´ê³¼ ë™ì¼)
                fig.add_scatter(x=forecast_chart_data['ds'], y=forecast_chart_data['yhat_lower'], fill='tozeroy', mode='lines', line=dict(color='rgba(0,0,0,0)'), name='ë¶ˆí™•ì‹¤ì„±(í•˜í•œ)')
                fig.add_scatter(x=forecast_chart_data['ds'], y=forecast_chart_data['yhat_upper'], fill='tonexty', mode='lines', line=dict(color='rgba(0,0,0,0)'), fillcolor='rgba(231, 234, 241, 0.5)', name='ë¶ˆí™•ì‹¤ì„±(ìƒí•œ)')
                
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

    # 4. ë ˆì‹œí”¼ ê¸°ë°˜ ì›ì¬ë£Œ ì†Œì§„ëŸ‰ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ í™œìš©)
    rows = []
    for item in items:
        sku_en = item["ingredient_en"]
        qty_per_unit = safe_float(item.get("qty", 0.0))
        uom = normalize_uom(item.get("uom", "ea"))
        waste_pct = safe_float(item.get("waste_pct", 0.0))
        
        total_used = (qty_per_unit * sold_sum) * (1 + (waste_pct / 100.0))
        
        rows.append({
            "sku_en": sku_en,
            "uom_recipe": uom,
            "total_consumption": total_used # ì˜ˆì¸¡/ê³¼ê±° ê¸°ë°˜ ì´ ì†Œì§„ëŸ‰
        })

    if not rows:
        return pd.DataFrame()
    
    use_df = pd.DataFrame(rows).groupby("sku_en").agg({
        "total_consumption": "sum",
        "uom_recipe": "first" 
    }).reset_index()
    
    base = use_df.rename(columns={"total_consumption": "ìµœê·¼ì†Œì§„í•©"})

    # 5. ì¬ê³  ì§€í‘œ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ í™œìš©)
    base["ì¼í‰ê· ì†Œì§„"] = (base["ìµœê·¼ì†Œì§„í•©"] / max(days, 1)).round(3)
    base.loc[base["ì¼í‰ê· ì†Œì§„"].eq(0), "ì¼í‰ê· ì†Œì§„"] = 0.01

    base = base.merge(df_inv[['ìƒí’ˆìƒì„¸_en', 'í˜„ì¬ì¬ê³ ', 'ì´ˆê¸°ì¬ê³ ', 'uom']], left_on='sku_en', right_on='ìƒí’ˆìƒì„¸_en', how='left')
    base['í˜„ì¬ì¬ê³ '] = base['í˜„ì¬ì¬ê³ '].fillna(0)
    base['ì´ˆê¸°ì¬ê³ '] = base['ì´ˆê¸°ì¬ê³ '].fillna(DEFAULT_INITIAL_STOCK)
    base['uom'] = base['uom'].fillna('ea').apply(normalize_uom)

    base["ì»¤ë²„ì¼ìˆ˜"] = (base["í˜„ì¬ì¬ê³ "] / base["ì¼í‰ê· ì†Œì§„"]).round(1)

    # 6. ROP ë° ê¶Œì¥ ë°œì£¼ëŸ‰ ê³„ì‚°
    base = base.merge(df_params, on="sku_en", how="left")
    
    # íŒŒë¼ë¯¸í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
    base['lead_time_days'] = base['lead_time_days'].fillna(3)
    base['safety_stock_units'] = base['safety_stock_units'].fillna(0)
    base['target_days'] = base['target_days'].fillna(21) # ì¬ë£Œì˜ ëª©í‘œì¼ìˆ˜

    # === [ì˜¤íƒ€ ìˆ˜ì •] 'ì¼í‰Yê· ì†Œì§„' -> 'ì¼í‰ê· ì†Œì§„' ===
    base["ROP"] = (base["ì¼í‰ê· ì†Œì§„"] * base["lead_time_days"] + base["safety_stock_units"]).round(0).astype(int)
    
    # [í•µì‹¬] ê¶Œì¥ ë°œì£¼ëŸ‰: (AIê°€ ì˜ˆì¸¡í•œ ì´ ì†Œì§„ëŸ‰) - (í˜„ì¬ ì¬ê³ )
    base["ê¶Œì¥ë°œì£¼"] = (base["ìµœê·¼ì†Œì§„í•©"] - base["í˜„ì¬ì¬ê³ "]).apply(lambda x: max(int(ceil(x)), 0))
    
    base["ìƒíƒœ"] = base.apply(lambda r: "ğŸš¨ ë°œì£¼ìš”ë§" if r["í˜„ì¬ì¬ê³ "] <= r["ROP"] else "âœ… ì •ìƒ", axis=1)

    base["ìƒí’ˆìƒì„¸"] = base["sku_en"].apply(to_korean_detail)
    cols = ["ìƒí’ˆìƒì„¸","sku_en","í˜„ì¬ì¬ê³ ","ì´ˆê¸°ì¬ê³ ","uom","ìµœê·¼ì†Œì§„í•©","ì¼í‰ê· ì†Œì§„","ì»¤ë²„ì¼ìˆ˜",
            "lead_time_days","safety_stock_units","target_days","ROP","ê¶Œì¥ë°œì£¼","ìƒíƒœ"]
    for c in cols:
        if c not in base.columns:
            base[c] = None
            
    # === [ì˜¤íƒ€ ìˆ˜ì •] 'ì»¤ë²„ì¼S' -> 'ì»¤ë²„ì¼ìˆ˜' ===
    return base[cols].sort_values(["ìƒíƒœ","ì»¤ë²„ì¼ìˆ˜"])

# =============================================================
# === [AI/ML ì—…ê·¸ë ˆì´ë“œ] í”„ë¡œì•¡í‹°ë¸Œ ë¶„ì„ í•¨ìˆ˜ (L3 + L4) ===
# =============================================================

@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
def find_inventory_risks(df, df_inv, df_params):
    """(AI ë ˆë²¨ 3) AI ì˜ˆì¸¡ ê¸°ë°˜, ì¬ê³  ìœ„í—˜ í’ˆëª© ìƒìœ„ 3ê°œ ì°¾ê¸°"""
    try:
        # 1. ë ˆì‹œí”¼ê°€ ìˆëŠ” ë©”ë‰´ë§Œ
        # [L4] ì „ì—­ RECIPES ì‚¬ìš©
        menu_list_en = list(RECIPES.keys())
        if not menu_list_en:
            return "ë ˆì‹œí”¼ê°€ ë“±ë¡ë˜ì§€ ì•Šì•„ ì¬ê³  ìœ„í—˜ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        all_risks = []
        
        for menu_sku_en in menu_list_en:
            # 2. ëª¨ë“  ë©”ë‰´ì— ëŒ€í•´ 'AI ì˜ˆì¸¡' ë° 'ì¬ê³  ê³„ì‚°' ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
            report_df = compute_ingredient_metrics_for_menu(
                menu_sku_en, df, df_inv, df_params, window_days=21
            )
            
            # 3. 'ë°œì£¼ìš”ë§' ìƒíƒœì¸ ì¬ë£Œ í•„í„°ë§
            risk_items = report_df[report_df['ìƒíƒœ'] == 'ğŸš¨ ë°œì£¼ìš”ë§']
            
            if not risk_items.empty:
                for _, row in risk_items.iterrows():
                    all_risks.append(
                        f"- '{row['ìƒí’ˆìƒì„¸']}' (ë©”ë‰´ '{to_korean_detail(menu_sku_en)}'ìš©): "
                        f"í˜„ì¬ ì¬ê³  {row['í˜„ì¬ì¬ê³ ']}{row['uom']}, "
                        f"AI ì˜ˆì¸¡ ê¸°ë°˜ ê¶Œì¥ ë°œì£¼ëŸ‰ {row['ê¶Œì¥ë°œì£¼']}{row['uom']}. (ì»¤ë²„ì¼ìˆ˜: {row['ì»¤ë²„ì¼ìˆ˜']}ì¼)"
                    )
                    
        if not all_risks:
            return "AI ì˜ˆì¸¡ ê²°ê³¼, í˜„ì¬ ì¬ê³ ê°€ ì¶©ë¶„í•©ë‹ˆë‹¤. (ìœ„í—˜ 0ê±´)"
        
        # ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
        return "\n".join(list(set(all_risks))[:3])

    except Exception as e:
        return f"ì¬ê³  ìœ„í—˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_slow_moving_items(df, df_inv):
    """(AI ë ˆë²¨ 3) ì•…ì„± ì¬ê³  (30ì¼ê°„ 5ê°œ ì´í•˜ íŒë§¤) ì°¾ê¸°"""
    try:
        # 1. 30ì¼ê°„ ë©”ë‰´ë³„ íŒë§¤ëŸ‰ ì§‘ê³„
        min_day = df["ë‚ ì§œ"].max() - pd.Timedelta(days=29)
        df_30d = df[df["ë‚ ì§œ"] >= min_day]
        sales_counts = df_30d.groupby('ìƒí’ˆìƒì„¸')['ìˆ˜ëŸ‰'].sum()
        
        # 2. 30ì¼ê°„ 5ê°œ ì´í•˜ë¡œ íŒ”ë¦° 'ë¹„ì¸ê¸° ë©”ë‰´'
        slow_menus_kr = sales_counts[sales_counts <= 5].index.tolist()
        if not slow_menus_kr:
            return "ì§€ë‚œ 30ì¼ê°„ íŒë§¤ê°€ ë¶€ì§„í•œ ë©”ë‰´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # 3. ë¹„ì¸ê¸° ë©”ë‰´ì˜ ë ˆì‹œí”¼ -> ì¬ë£Œ ì°¾ê¸°
        slow_ingredients = set()
        for menu_kr in slow_menus_kr:
            menu_en = from_korean_detail(menu_kr)
            items = load_recipe(menu_en) # [L4] ì „ì—­ RECIPES ì‚¬ìš©
            for item in items:
                slow_ingredients.add(item['ingredient_en'])
        
        if not slow_ingredients:
            return "ì§€ë‚œ 30ì¼ê°„ íŒë§¤ê°€ ë¶€ì§„í•œ ë©”ë‰´ê°€ ìˆìœ¼ë‚˜, ë ˆì‹œí”¼ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
        # 4. í•´ë‹¹ ì¬ë£Œë“¤ì˜ í˜„ì¬ ì¬ê³  í™•ì¸
        df_ing_stock = df_inv[df_inv['ìƒí’ˆìƒì„¸_en'].isin(list(slow_ingredients))]
        df_ing_stock = df_ing_stock.sort_values('í˜„ì¬ì¬ê³ ', ascending=False)
        
        if df_ing_stock.empty:
            return "íŒë§¤ ë¶€ì§„ ë©”ë‰´ì™€ ì—°ê²°ëœ ì¬ë£Œ ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
            
        report = []
        for _, row in df_ing_stock.head(3).iterrows(): # ì¬ê³  ë§ì€ ìƒìœ„ 3ê°œ
            report.append(
                f"- '{row['ìƒí’ˆìƒì„¸']}' (ë¹„ì¸ê¸° ë©”ë‰´ìš© ì¬ë£Œ): "
                f"í˜„ì¬ ì¬ê³  {row['í˜„ì¬ì¬ê³ ']}{row['uom']}"
            )
        return "\n".join(report)

    except Exception as e:
        return f"ì•…ì„± ì¬ê³  ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_top_correlations(df):
    """(AI ë ˆë²¨ 3) í•¨ê»˜ ì˜ íŒ”ë¦¬ëŠ” ë©”ë‰´ (ìƒê´€ê´€ê³„) ì°¾ê¸°"""
    try:
        # 1. ë‚ ì§œ-ìƒí’ˆë³„ íŒë§¤ëŸ‰ í”¼ë²— í…Œì´ë¸” ìƒì„±
        df_pivot = df.pivot_table(
            index='ë‚ ì§œ', 
            columns='ìƒí’ˆìƒì„¸', 
            values='ìˆ˜ëŸ‰', 
            aggfunc='sum'
        ).fillna(0)
        
        # (ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 20ê°œë§Œ)
        top_20_items = df_pivot.sum().nlargest(20).index
        df_pivot = df_pivot[top_20_items]
        
        # 2. ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        corr_matrix = df_pivot.corr()
        
        # 3. ìê¸° ìì‹ (1.0)ì„ ì œì™¸í•œ ìƒìœ„ 3ê°œ íŒ¨í„´ ì°¾ê¸°
        corr_pairs = corr_matrix.unstack()
        corr_pairs = corr_pairs[corr_pairs < 1].sort_values(ascending=False)
        
        top_3 = corr_pairs.head(3)
        if top_3.empty:
            return "ìœ ì˜ë¯¸í•œ ë™ì‹œ íŒë§¤ íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        report = []
        for (item1, item2), corr_val in top_3.items():
            report.append(f"- '{item1}' + '{item2}' (ìƒê´€ê´€ê³„: {corr_val:.2f})")
        return "\n".join(report)
        
    except Exception as e:
        return f"íŒë§¤ íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data(ttl=3600)
def find_profit_insights(df_with_margin: pd.DataFrame):
    """(AI ë ˆë²¨ 4) 'ìˆœì´ìµ'ê³¼ 'ë§ˆì§„ìœ¨' ê¸°ë°˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
    
    if 'ìˆœì´ìµ' not in df_with_margin.columns or df_with_margin['ì›ê°€'].sum() == 0:
        return ("'ì›ê°€' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ì›ê°€ & ë ˆì‹œí”¼ í—ˆë¸Œ' íƒ­ì—ì„œ "
                "ë¨¼ì € 'ì¬ë£Œ ì›ê°€'ì™€ 'ë ˆì‹œí”¼'ë¥¼ ë“±ë¡í•´ì•¼ 'ìˆœì´ìµ' ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    try:
        # 1. ë©”ë‰´ë³„ ì§‘ê³„
        df_agg = df_with_margin.groupby('ìƒí’ˆìƒì„¸').agg(
            ì´íŒë§¤ìˆ˜ëŸ‰=('ìˆ˜ëŸ‰', 'sum'),
            ì´ë§¤ì¶œ=('ìˆ˜ìµ', 'sum'),
            ì´ìˆœì´ìµ=('ìˆœì´ìµ', 'sum')
        ).reset_index()
        
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] = (df_agg['ì´ìˆœì´ìµ'] / df_agg['ì´ë§¤ì¶œ']).replace([pd.NA, float('inf'), float('-inf')], 0).fillna(0) * 100
        
        # 2. íš¨ì ìƒí’ˆ (ìˆœì´ìµ ê¸°ì—¬ë„ Top 3)
        stars = df_agg.sort_values('ì´ìˆœì´ìµ', ascending=False).head(3)
        star_report = "\n".join([
            f"- '{row['ìƒí’ˆìƒì„¸']}' (ì´ ìˆœì´ìµ: {format_krw(row['ì´ìˆœì´ìµ'])}, ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
            for _, row in stars.iterrows()
        ])
        
        # 3. ìˆ˜ìµì„± í•¨ì • (ë§ˆì§„ìœ¨ í•˜ìœ„ 3ê°œ - ë‹¨, ì›ê°€ê°€ 0ì´ ì•„ë‹Œ ë©”ë‰´ ì¤‘)
        traps = df_agg[df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] > 0].sort_values('í‰ê· ë§ˆì§„ìœ¨(%)', ascending=True).head(3)
        trap_report = "\n".join([
            f"- '{row['ìƒí’ˆìƒì„¸']}' (ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
            for _, row in traps.iterrows()
        ])

        # 4. ì†ì‹¤ ìƒí’ˆ (ë§ˆì§„ìœ¨ì´ 0 ë˜ëŠ” ë§ˆì´ë„ˆìŠ¤)
        loss = df_agg[df_agg['í‰ê· ë§ˆì§„ìœ¨(%)'] <= 0]
        loss_report = "ì†ì‹¤ ë°œìƒ ë©”ë‰´ ì—†ìŒ."
        if not loss.empty:
            loss_report = "\n".join([
                f"- '{row['ìƒí’ˆìƒì„¸']}' (ë§ˆì§„ìœ¨: {row['í‰ê· ë§ˆì§„ìœ¨(%)']:.1f}%)"
                for _, row in loss.iterrows()
            ])

        return f"""
[íš¨ì ìƒí’ˆ (ìˆœì´ìµ Top 3)]
{star_report}

[ìˆ˜ìµì„± í•¨ì • (ë§ˆì§„ìœ¨ í•˜ìœ„ 3)]
{trap_report}

[ì†ì‹¤ ë°œìƒ ë©”ë‰´ (ë§ˆì§„ìœ¨ <= 0)]
{loss_report}
"""
    except Exception as e:
        return f"ë§ˆì§„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"


# ----------------------
# 5ï¸âƒ£ ì‚¬ì´ë“œë°” ë©”ë‰´
# ----------------------
# [AI/ML í†µí•© ìˆ˜ì •] "AI ë¹„ì„œ" ë©”ë‰´ ì¶”ê°€
menu = st.sidebar.radio(
    " ë©”ë‰´ ì„ íƒ",
    ["ê²½ì˜ í˜„í™©", "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ", "ê¸°ê°„ë³„ ë¶„ì„", "ê±°ë˜ ì¶”ê°€", "ì¬ê³  ê´€ë¦¬", "AI ë¹„ì„œ", "ë°ì´í„° í¸ì§‘", "ê±°ë˜ ë‚´ì—­", "ë„ì›€ë§"]
)

# ==============================================================
# ğŸ§¾ ê±°ë˜ ì¶”ê°€
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
if menu == "ê±°ë˜ ì¶”ê°€":
    st.header(" ê±°ë˜ ë°ì´í„° ì¶”ê°€")
    category_options = sorted(pd.Series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬']).dropna().unique().tolist())
    type_options = sorted(pd.Series(df['ìƒí’ˆíƒ€ì…']).dropna().unique().tolist())
    detail_options = sorted(pd.Series(df['ìƒí’ˆìƒì„¸']).dropna().unique().tolist())

    with st.form("add_transaction"):
        col1, col2 = st.columns(2)
        with col1:
            ë‚ ì§œ = st.date_input("ë‚ ì§œ", value=datetime.now().date())
            ìƒí’ˆì¹´í…Œê³ ë¦¬_ko = st.selectbox("ìƒí’ˆì¹´í…Œê³ ë¦¬", category_options)
            ìƒí’ˆíƒ€ì…_ko = st.selectbox("ìƒí’ˆíƒ€ì…", type_options)
        with col2:
            ìƒí’ˆìƒì„¸_ko = st.selectbox("ìƒí’ˆìƒì„¸", detail_options)
            ìˆ˜ëŸ‰ = st.number_input("ìˆ˜ëŸ‰", min_value=1, value=1)
            ë‹¨ê°€ = st.number_input("ë‹¨ê°€(ì›)", min_value=0.0, value=1000.0, step=100.0)
        
        ìˆ˜ìµ = ìˆ˜ëŸ‰ * ë‹¨ê°€
        st.markdown(f"### ğŸ’° ê³„ì‚°ëœ ìˆ˜ìµ: **{format_krw(ìˆ˜ìµ)}**")
        
        submitted = st.form_submit_button("ë°ì´í„° ì¶”ê°€")
        
        if submitted:
            ìƒí’ˆì¹´í…Œê³ ë¦¬_en = rev_category_map.get(ìƒí’ˆì¹´í…Œê³ ë¦¬_ko, ìƒí’ˆì¹´í…Œê³ ë¦¬_ko)
            ìƒí’ˆíƒ€ì…_en = rev_type_map.get(ìƒí’ˆíƒ€ì…_ko, ìƒí’ˆíƒ€ì…_ko)
            ìƒí’ˆìƒì„¸_en = from_korean_detail(ìƒí’ˆìƒì„¸_ko)
            
            new_doc = {
                "ë‚ ì§œ": str(ë‚ ì§œ),
                "ì‹œê°„": datetime.now().strftime("%H:%M:%S"),
                "ìƒí’ˆì¹´í…Œê³ ë¦¬": ìƒí’ˆì¹´í…Œê³ ë¦¬_en,
                "ìƒí’ˆíƒ€ì…": ìƒí’ˆíƒ€ì…_en,
                "ìƒí’ˆìƒì„¸": ìƒí’ˆìƒì„¸_en,
                "ìˆ˜ëŸ‰": ìˆ˜ëŸ‰,
                "ë‹¨ê°€": ë‹¨ê°€,
                "ìˆ˜ìµ": ìˆ˜ìµ,
                "ê°€ê²Œìœ„ì¹˜": "Firebase",
            }
            
            try:
                db.collection(SALES_COLLECTION).add(new_doc)
                st.success(f"âœ… '{ìƒí’ˆìƒì„¸_ko}' {ìˆ˜ëŸ‰}ê±´ ì¶”ê°€ ì™„ë£Œ!")
                
                # ì¬ê³  ìë™ ì°¨ê°
                with st.spinner("ì¬ê³  ìë™ ì°¨ê° ì ìš© ì¤‘..."):
                    adjust_inventory_by_recipe(
                        ìƒí’ˆìƒì„¸_en,
                        ìˆ˜ëŸ‰,
                        move_type="sale",
                        note=f"ê±°ë˜ ì¶”ê°€: {ìƒí’ˆìƒì„¸_ko} x{ìˆ˜ëŸ‰}"
                    )
                st.success("âœ… ì¬ê³  ì°¨ê° ì™„ë£Œ!")
                safe_rerun()
                
            except Exception as e:
                st.error(f"ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {e}")

# ==============================================================
# ğŸ“Š ê²½ì˜ í˜„í™©
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê²½ì˜ í˜„í™©":
    st.header("ğŸ“Š ê²½ì˜ í˜„í™©")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        total_revenue = df['ìˆ˜ìµ'].sum()
        total_sales_count = df.shape[0]
        avg_revenue_per_sale = total_revenue / total_sales_count if total_sales_count > 0 else 0
        
        st.markdown(
            f"""
            <div style="display:grid; grid-template-columns:1fr 1fr 1fr; gap:16px; margin-bottom:20px;">
                <div class="metric-card">
                    <div class="metric-title">ì´ ë§¤ì¶œ</div>
                    <div class="metric-value">{format_krw(total_revenue)}</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">ì´ íŒë§¤ ê±´ìˆ˜</div>
                    <div class="metric-value">{total_sales_count:,} ê±´</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">ê±´ë‹¹ í‰ê·  ë§¤ì¶œ</div>
                    <div class="metric-value">{format_krw(avg_revenue_per_sale)}</div>
                </div>
            </div>
            """, unsafe_allow_html=True
        )

        if not df.empty:
            try:
                top_cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
                top_prod = df.groupby('ìƒí’ˆíƒ€ì…')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
                st.info(f"ğŸ† ê°€ì¥ ë§¤ì¶œ ë†’ì€ ì¹´í…Œê³ ë¦¬: **{top_cat.index[0]}** ({format_krw(top_cat.iloc[0])}) / ìƒí’ˆ: **{top_prod.index[0]}**")
            except Exception:
                st.info("ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ìƒìœ„ í•­ëª©ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        col4, col5 = st.columns(2)
        with col4:
            cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().reset_index()
            fig_cat = px.pie(cat, values='ìˆ˜ìµ', names='ìƒí’ˆì¹´í…Œê³ ë¦¬', title="ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ë¹„ì¤‘")
            st.plotly_chart(fig_cat, use_container_width=True)
        with col5:
            daily = df.groupby('ë‚ ì§œ')['ìˆ˜ìµ'].sum().reset_index()
            fig_trend = px.line(daily, x='ë‚ ì§œ', y='ìˆ˜ìµ', title="ì¼ìë³„ ë§¤ì¶œ ì¶”ì´")
            st.plotly_chart(fig_trend, use_container_width=True)

# ==============================================================
# ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ":
    st.header("ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        col1, col2 = st.columns(2)
        monthly = df.groupby(df['ë‚ ì§œ'].dt.to_period("M"))['ìˆ˜ìµ'].sum().reset_index()
        monthly['ë‚ ì§œ'] = monthly['ë‚ ì§œ'].dt.to_timestamp()
        
        with col1:
            fig_month = px.bar(monthly, x='ë‚ ì§œ', y='ìˆ˜ìµ', title="ì›”ë³„ ë§¤ì¶œ")
            st.plotly_chart(fig_month, use_container_width=True)
        with col2:
            cat_sales = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().reset_index()
            fig_cat2 = px.bar(cat_sales, x='ìƒí’ˆì¹´í…Œê³ ë¦¬', y='ìˆ˜ìµ', title="ìƒí’ˆ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ")
            st.plotly_chart(fig_cat2, use_container_width=True)

        prod_sales = df.groupby(['ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸'])['ìˆ˜ìµ'].sum().reset_index()
        fig_sun = px.sunburst(prod_sales, path=['ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸'], values='ìˆ˜ìµ', title="ìƒí’ˆ êµ¬ì¡°ë³„ ë§¤ì¶œ")
        st.plotly_chart(fig_sun, use_container_width=True)

# ==============================================================
# ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê¸°ê°„ë³„ ë¶„ì„":
    st.header("ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        min_date = df['ë‚ ì§œ'].min().date()
        max_date = df['ë‚ ì§œ'].max().date()
        
        date_filter = st.slider(
            "ì¡°íšŒ ê¸°ê°„",
            min_value=min_date, max_value=max_date,
            value=(min_date, max_date),
            format="YYYY/MM/DD"
        )
        
        filtered_df = df[
            (df['ë‚ ì§œ'].dt.date >= date_filter[0]) &
            (df['ë‚ ì§œ'].dt.date <= date_filter[1])
        ]
        
        if filtered_df.empty:
            st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            c1, c2 = st.columns(2)
            with c1:
                week_sales = filtered_df.groupby('ìš”ì¼')['ìˆ˜ìµ'].sum().reindex(weekday_order_kr)
                fig_week = px.bar(week_sales, x=week_sales.index, y='ìˆ˜ìµ', title="ìš”ì¼ë³„ ë§¤ì¶œ")
                st.plotly_chart(fig_week, use_container_width=True)
            with c2:
                hour_sales = filtered_df.groupby('ì‹œ')['ìˆ˜ìµ'].sum().reset_index()
                fig_hour = px.bar(hour_sales, x='ì‹œ', y='ìˆ˜ìµ', title="ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ")
                st.plotly_chart(fig_hour, use_container_width=True)

# ==============================================================
# ğŸ“¦ ì¬ê³  ê´€ë¦¬
# (ì›ë³¸ ì½”ë“œ ìƒëµ, [AI/ML í†µí•© ìˆ˜ì •]ì´ ì ìš©ëœ í•¨ìˆ˜ë¥¼ ì‚¬ìš©)
# ==============================================================
elif menu == "ì¬ê³  ê´€ë¦¬":
    st.header("ğŸ“¦ ì¬ê³  ê´€ë¦¬ (AI ì˜ˆì¸¡ ê¸°ë°˜)")
    
    # [L4] ì „ì—­ ë¡œë“œëœ df_inv, df_params ì‚¬ìš© (ìƒˆë¡œ ë¡œë“œ X)
    # df_inv = load_inventory_df()
    # df_params = load_sku_params()
    
    # === [ìˆ˜ì •] "ì›ê°€" ê¸°ëŠ¥ ë°˜ì˜ ===
    tab1, tab2 = st.tabs(["ğŸ›ï¸ ë©”ë‰´ë³„ ì¬ê³  í˜„í™© (AI ì˜ˆì¸¡)", "ğŸ”— ì›ê°€ & ë ˆì‹œí”¼ í—ˆë¸Œ"])

    # ==============================================================
    # TAB 1: ë©”ë‰´ë³„ ì¬ê³  í˜„í™© (AI ì˜ˆì¸¡) - (ë³€ê²½ ì—†ìŒ)
    # ==============================================================
    with tab1:
        st.subheader("ğŸ›ï¸ ë©”ë‰´ë³„ ì¬ê³  í˜„í™© (AI ì˜ˆì¸¡ ê¸°ë°˜)")
        
        # [L4] ì „ì—­ ë¡œë“œëœ RECIPES ì‚¬ìš©
        menu_list_en = list(RECIPES.keys())

        if not menu_list_en:
            st.warning("ë¨¼ì € 'ì›ê°€ & ë ˆì‹œí”¼ í—ˆë¸Œ' íƒ­ì—ì„œ ë©”ë‰´ì˜ ë ˆì‹œí”¼ë¥¼ 1ê°œ ì´ìƒ ë“±ë¡í•´ì•¼ í•©ë‹ˆë‹¤.")
            st.stop()

        menu_list_kr = sorted([to_korean_detail(sku) for sku in menu_list_en])
        
        selected_menu_kr = st.selectbox("ë¶„ì„í•  ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", menu_list_kr, index=0)
        selected_menu_en = from_korean_detail(selected_menu_kr)
        
        st.markdown("---")
        
        try:
            # [L4] ì „ì—­ ë¡œë“œëœ df, df_inv, df_params ì „ë‹¬
            report_df = compute_ingredient_metrics_for_menu(
                selected_menu_en,
                df, 
                df_inv,
                df_params
            )
            
            if report_df.empty:
                st.info(f"'{selected_menu_kr}'ì— ëŒ€í•œ ë ˆì‹œí”¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                display_cols = [
                    'ìƒí’ˆìƒì„¸', 'ìƒíƒœ', 'í˜„ì¬ì¬ê³ ', 'uom', 'ê¶Œì¥ë°œì£¼', 'ì»¤ë²„ì¼ìˆ˜', 'ì¼í‰ê· ì†Œì§„', 'ROP',
                ]
                
                # (ì´í•˜ í¬ë§·íŒ… ì½”ë“œ ë™ì¼)
                formatted_df = report_df[display_cols].copy()
                formatted_df['í˜„ì¬ì¬ê³ '] = formatted_df.apply(lambda r: f"{r['í˜„ì¬ì¬ê³ ']:,.1f} {r['uom']}", axis=1)
                formatted_df['ê¶Œì¥ë°œì£¼'] = formatted_df.apply(lambda r: f"{r['ê¶Œì¥ë°œì£¼']:,.1f} {r['uom']}", axis=1)
                formatted_df['ì¼í‰ê· ì†Œì§„'] = formatted_df.apply(lambda r: f"{r['ì¼í‰ê· ì†Œì§„']:,.1f} {r['uom']}", axis=1)
                formatted_df['ROP'] = formatted_df.apply(lambda r: f"{r['ROP']:,.1f} {r['uom']}", axis=1)
                formatted_df['ì»¤ë²„ì¼ìˆ˜'] = formatted_df['ì»¤ë²„ì¼ìˆ˜'].apply(lambda x: f"{x}ì¼")
                
                st.dataframe(
                    formatted_df[['ìƒí’ˆìƒì„¸', 'ìƒíƒœ', 'í˜„ì¬ì¬ê³ ', 'ê¶Œì¥ë°œì£¼', 'ì»¤ë²„ì¼ìˆ˜', 'ì¼í‰ê· ì†Œì§„', 'ROP']],
                    use_container_width=True
                )
        except Exception as e:
            st.error(f"ì¬ê³  ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            import traceback
            st.exception(traceback.format_exc())

    # ==============================================================
    # === [ìˆ˜ì •] "ì›ê°€ & ë ˆì‹œí”¼ í—ˆë¸Œ"ë¡œ ì—…ê·¸ë ˆì´ë“œ (ë ˆë²¨ 4) ===
    # ==============================================================
    with tab2:
        st.subheader("âœ¨ ì›ê°€ & ë ˆì‹œí”¼ í—ˆë¸Œ (L4)")
        st.caption("ì—¬ê¸°ì„œ (1) ì¬ë£Œì˜ 'ì›ê°€'ë¥¼ ì…ë ¥í•˜ê³ , (2) ë ˆì‹œí”¼ë¥¼ ë§Œë“¤ê³ , (3) ì¬ê³ ë¥¼ ë´…ë‹ˆë‹¤.")

        # === [ìˆ˜ì •] íƒ­ 3ê°œë¡œ í™•ì¥ ===
        sub_tab1, sub_tab2, sub_tab3 = st.tabs(["ğŸ’° 1. ì¬ë£Œ ì›ê°€ ê´€ë¦¬", "ğŸ“œ 2. ë ˆì‹œí”¼ í¸ì§‘ê¸°", "ğŸ“Š 3. ì „ì²´ ì¬ë£Œ í˜„í™©"])

        # --- 1. ì¬ë£Œ ì›ê°€ ê´€ë¦¬ (L4 ì—…ê·¸ë ˆì´ë“œ) ---
        with sub_tab1:
            st.info("AIê°€ 'ìˆœì´ìµ'ì„ ê³„ì‚°í•˜ë„ë¡, ì¬ë£Œì˜ **'ë§¤ì… ì›ê°€'**ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            st.caption("ì˜ˆ: 'ì›ë‘ A'ë¥¼ '1000'gì— '30000'ì›ì— ì‚¬ì™”ë‹¤ë©´, ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì„¸ìš”.")

            # === [ë¹ˆí‹ˆ ìˆ˜ì •] inventoryê°€ ë¹„ì–´ìˆì„ ë•Œ (Cold Start) ì²˜ë¦¬ ===
            if df_inv.empty:
                st.warning("ğŸ“¦ 'inventory'ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. (ë°ì´í„° 0ê±´)")
                st.info("AI ì˜ˆì¸¡ê³¼ ì¬ê³  ê´€ë¦¬ë¥¼ ì‹œì‘í•˜ë ¤ë©´, 'inventory'ì— í’ˆëª©ì´ ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
                
                st.markdown("---")
                st.subheader("ğŸš€ 1íšŒ ìë™ ì„¤ì • (ê¶Œì¥)")
                st.markdown("ê¸°ì¡´ íŒë§¤ ë‚´ì—­(CSV)ì—ì„œ ì°¾ì€ **ëª¨ë“  í’ˆëª©**ì„ 'inventory'ì— ìë™ìœ¼ë¡œ ë“±ë¡í•©ë‹ˆë‹¤.")
                
                if st.button("ëª¨ë“  íŒë§¤ í’ˆëª©ì„ 'inventory'ì— 1íšŒ ë“±ë¡í•˜ê¸°"):
                    all_menu_items_kr = df['ìƒí’ˆìƒì„¸'].unique()
                    all_menu_items_en = [from_korean_detail(name_kr) for name_kr in all_menu_items_kr if name_kr]
                    
                    with st.spinner(f"{len(all_menu_items_en)}ê°œ í’ˆëª©ì„ 'inventory'ë¡œ ì˜®ê¸°ëŠ” ì¤‘..."):
                        count = 0
                        for sku_en in all_menu_items_en:
                            if sku_en:
                                ensure_inventory_doc(sku_en, uom="ea", is_ingredient=False)
                                count += 1
                    
                    st.success(f"âœ… ì´ {count}ê°œì˜ í’ˆëª©ì„ 'inventory'ì— ë“±ë¡í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
                    st.balloons()
                    safe_rerun()
                
                st.stop() # í…… ë¹ˆ ìƒíƒœì—ì„œëŠ” ì•„ë˜ í¸ì§‘ê¸°ë¥¼ ë³´ì—¬ì£¼ì§€ ì•ŠìŒ
            # === [ìˆ˜ì • ì™„ë£Œ] ===
            
            # (inventoryê°€ ë¹„ì–´ìˆì§€ ì•Šì„ ë•Œë§Œ ì´ ì½”ë“œê°€ ì‹¤í–‰ë¨)
            df_inv_edit = df_inv.copy()
            
            # [L4] load_inventory_dfê°€ ì´ë¯¸ ì²˜ë¦¬í–ˆì§€ë§Œ, ì•ˆì „ì„ ìœ„í•´ í•œë²ˆ ë” ì²´í¬
            if 'cost_per_unit' not in df_inv_edit.columns:
                df_inv_edit['cost_per_unit'] = 0.0 
            if 'cost_unit_size' not in df_inv_edit.columns:
                df_inv_edit['cost_unit_size'] = 1.0 
            
            df_inv_edit = df_inv_edit.sort_values('ìƒí’ˆìƒì„¸')
            
            edited_inv_df = st.data_editor(
                df_inv_edit[['ìƒí’ˆìƒì„¸', 'is_ingredient', 'uom', 'cost_unit_size', 'cost_per_unit', 'ìƒí’ˆìƒì„¸_en']],
                column_config={
                    "ìƒí’ˆìƒì„¸": st.column_config.TextColumn("í’ˆëª©ëª…", disabled=True),
                    "is_ingredient": st.column_config.CheckboxColumn("ì¬ë£Œ ì—¬ë¶€ (ì²´í¬)"),
                    "uom": st.column_config.TextColumn("ê¸°ë³¸ ë‹¨ìœ„", disabled=True),
                    "cost_unit_size": st.column_config.NumberColumn(
                        "ë§¤ì… ë‹¨ìœ„(g/ml/ea)", 
                        help="ì›ê°€ ê³„ì‚°ì˜ ê¸°ì¤€ ë‹¨ìœ„ì…ë‹ˆë‹¤. (ì˜ˆ: 1kg -> 1000, 1L -> 1000)",
                        min_value=1.0, 
                        format="%.0f"
                    ),
                    "cost_per_unit": st.column_config.NumberColumn(
                        "ë§¤ì…ê°€(ì›)",
                        help="ìœ„ 'ë§¤ì… ë‹¨ìœ„'ì— í•´ë‹¹í•˜ëŠ” ê°€ê²©ì…ë‹ˆë‹¤. (ì˜ˆ: 30000)",
                        min_value=0,
                        format="%dì›"
                    ),
                    "ìƒí’ˆìƒì„¸_en": st.column_config.TextColumn("SKU (Eng)", disabled=True),
                },
                hide_index=True,
                use_container_width=True
            )

            if st.button("ğŸ’¾ 'ì¬ë£Œ ë° ì›ê°€' ì„¤ì • ì €ì¥í•˜ê¸°", type="primary"):
                changed = 0
                batch = db.batch()
                
                original_map = df_inv.set_index('ìƒí’ˆìƒì„¸_en').to_dict('index')

                for _, item in edited_inv_df.iterrows():
                    sku_en = item['ìƒí’ˆìƒì„¸_en']
                    orig_item = original_map.get(sku_en, {})
                    patch = {}
                    
                    is_ingr_new = bool(item['is_ingredient'])
                    if orig_item.get('is_ingredient') != is_ingr_new:
                        patch['is_ingredient'] = is_ingr_new
                    
                    cost_unit_new = safe_float(item['cost_unit_size'], 1.0)
                    if orig_item.get('cost_unit_size', 1.0) != cost_unit_new:
                        patch['cost_unit_size'] = cost_unit_new
                        
                    cost_new = safe_float(item['cost_per_unit'], 0.0)
                    if orig_item.get('cost_per_unit', 0.0) != cost_new:
                        patch['cost_per_unit'] = cost_new

                    if patch: 
                        doc_ref = db.collection(INVENTORY_COLLECTION).document(sku_en)
                        batch.update(doc_ref, patch)
                        changed += 1
                
                if changed > 0:
                    batch.commit()
                    st.success(f"âœ… {changed}ê±´ì˜ ì¬ë£Œ/ì›ê°€ ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.balloons()
                    safe_rerun()
                else:
                    st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

        # --- 2. ë ˆì‹œí”¼ í¸ì§‘ê¸° (ë³€ê²½ ì—†ìŒ) ---
        with sub_tab2:
            st.info("ìœ„ '1. ì¬ë£Œ ì›ê°€ ê´€ë¦¬'ì—ì„œ ì²´í¬í•œ ì¬ë£Œë“¤ë¡œ ë ˆì‹œí”¼ë¥¼ ë§Œë“­ë‹ˆë‹¤.")
            
            try:
                df_ingredients = df_inv[df_inv['is_ingredient'] == True].copy()
                
                if df_ingredients.empty:
                    st.error("ì˜¤ë¥˜: '1. ì¬ë£Œ ì›ê°€ ê´€ë¦¬' íƒ­ì—ì„œ ì¬ë£Œë¥¼ 1ê°œ ì´ìƒ ì²´í¬í•´ì•¼ í•©ë‹ˆë‹¤.")
                    st.caption("ë§Œì•½ í’ˆëª©ì´ ì—†ë‹¤ë©´, '1. ì¬ë£Œ ì›ê°€ ê´€ë¦¬' íƒ­ì˜ 'ìë™ ì„¤ì •' ë²„íŠ¼ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
                    st.stop()
                
                ingredient_options_kr = sorted(df_ingredients['ìƒí’ˆìƒì„¸'].unique().tolist())
                ing_kr_to_en_map = dict(zip(df_ingredients['ìƒí’ˆìƒì„¸'], df_ingredients['ìƒí’ˆìƒì„¸_en']))
                ing_en_to_kr_map = dict(zip(df_ingredients['ìƒí’ˆìƒì„¸_en'], df_ingredients['ìƒí’ˆìƒì„¸']))

            except Exception as e:
                st.error(f"ì¬ë£Œ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
                st.stop()

            all_menus_kr = sorted(df['ìƒí’ˆìƒì„¸'].unique().tolist())
            selected_menu_kr = st.selectbox(
                "ë ˆì‹œí”¼ë¥¼ ë“±ë¡/ìˆ˜ì •í•  ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                all_menus_kr
            )
            selected_menu_en = from_korean_detail(selected_menu_kr)
            
            st.caption(f"(Firebase ë¬¸ì„œ ID: `{selected_menu_en}`)")
            st.markdown("---")

            current_recipe_items = load_recipe(selected_menu_en)
            recipe_df_rows = []
            if current_recipe_items:
                for item in current_recipe_items:
                    sku_en = item.get("ingredient_en")
                    recipe_df_rows.append({
                        "ì¬ë£Œ": ing_en_to_kr_map.get(sku_en, f"ì˜¤ë¥˜: {sku_en}?"), # ì˜ë¬¸ -> í•œê¸€
                        "ìˆ˜ëŸ‰": safe_float(item.get("qty", 0.0)),
                        "ë‹¨ìœ„": normalize_uom(item.get("uom", "g")),
                        "ì†ì‹¤ë¥ (%)": safe_float(item.get("waste_pct", 0.0)),
                    })
            
            if not recipe_df_rows:
                recipe_df_rows = [{"ì¬ë£Œ": None, "ìˆ˜ëŸ‰": 0.0, "ë‹¨ìœ„": "g", "ì†ì‹¤ë¥ (%)": 0.0}]

            df_recipe_editor = pd.DataFrame(recipe_df_rows)
            st.subheader(f"ğŸ“ `{selected_menu_kr}` ë ˆì‹œí”¼ í¸ì§‘")
            
            edited_df = st.data_editor(
                df_recipe_editor,
                column_config={
                    "ì¬ë£Œ": st.column_config.SelectboxColumn(
                        "ì¬ë£Œ (í•„ìˆ˜)",
                        options=ingredient_options_kr, # [ì—°ë™] 1ë²ˆ íƒ­ì˜ ê²°ê³¼
                        required=True,
                    ),
                    "ìˆ˜ëŸ‰": st.column_config.NumberColumn(
                        "ìˆ˜ëŸ‰", min_value=0.0, format="%.2f", required=True,
                    ),
                    "ë‹¨ìœ„": st.column_config.SelectboxColumn(
                        "ë‹¨ìœ„", options=["g", "ml", "ea"], required=True,
                    ),
                    "ì†ì‹¤ë¥ (%)": st.column_config.NumberColumn(
                        "ì†ì‹¤ë¥ (%)", min_value=0.0, max_value=100.0, format="%.1f %%", required=True,
                    ),
                },
                num_rows="dynamic", # í–‰ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥
                use_container_width=True
            )

            if st.button(f"ğŸ’¾ `{selected_menu_kr}` ë ˆì‹œí”¼ ì €ì¥í•˜ê¸°", type="primary"):
                final_ingredients = []
                valid = True
                
                for index, row in edited_df.iterrows():
                    ì¬ë£Œ_kr = row["ì¬ë£Œ"]
                    if not ì¬ë£Œ_kr:
                        continue 

                    ì¬ë£Œ_en = ing_kr_to_en_map.get(ì¬ë£Œ_kr)
                    
                    if not ì¬ë£Œ_en:
                        st.error(f"'{ì¬ë£Œ_kr}'ëŠ” ìœ íš¨í•œ ì¬ë£Œê°€ ì•„ë‹™ë‹ˆë‹¤. '1. ì¬ë£Œ ì›ê°€ ê´€ë¦¬' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
                        valid = False
                        break
                    
                    final_ingredients.append({
                        "ingredient_en": ì¬ë£Œ_en,
                        "qty": safe_float(row["ìˆ˜ëŸ‰"]),
                        "uom": normalize_uom(row["ë‹¨ìœ„"]),
                        "waste_pct": safe_float(row["ì†ì‹¤ë¥ (%)"]),
                    })

                if valid and not final_ingredients:
                    st.warning("ì €ì¥í•  ì¬ë£Œê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  í–‰ì´ ë¹„ì–´ìˆìŒ)")
                
                elif valid and final_ingredients:
                    try:
                        db.collection(RECIPES_COLLECTION).document(selected_menu_en).set({
                            "ingredients": final_ingredients
                        })
                        st.success(f"âœ… `{selected_menu_kr}` ë ˆì‹œí”¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.balloons()
                        safe_rerun()
                    except Exception as e:
                        st.error(f"Firebase ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # === [ë³µì›] 3. ì „ì²´ ì¬ë£Œ í˜„í™© ===
        with sub_tab3:
            st.subheader("ğŸ“Š ì „ì²´ ì¬ë£Œ ì¬ê³  í˜„í™©")
            st.info("í˜„ì¬ 'inventory'ì— ë“±ë¡ëœ ëª¨ë“  ì¬ë£Œ('is_ingredient' = True)ì˜ í˜„í™©ì…ë‹ˆë‹¤.")

            df_ing = df_inv[df_inv["is_ingredient"] == True].copy()

            if df_ing.empty:
                st.warning("ì•„ì§ ì¬ë£Œë¡œ ì„¤ì •ëœ í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤. '1. ì¬ë£Œ ì›ê°€ ê´€ë¦¬' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
            else:
                df_ing['ì´ˆê¸°ì¬ê³ _calc'] = df_ing['ì´ˆê¸°ì¬ê³ '].replace(0, 0.01)
                df_ing['ì¬ê³ ë¹„ìœ¨'] = df_ing['í˜„ì¬ì¬ê³ '] / df_ing['ì´ˆê¸°ì¬ê³ _calc']
                df_ing['ìƒíƒœ'] = df_ing['ì¬ê³ ë¹„ìœ¨'].apply(lambda r: "ğŸš¨ ë°œì£¼ìš”ë§" if r <= REORDER_THRESHOLD_RATIO else "âœ… ì •ìƒ")

                low_ing = df_ing[df_ing['ì¬ê³ ë¹„ìœ¨'] <= REORDER_THRESHOLD_RATIO]
                
                fig_ing = px.bar(
                    df_ing.sort_values('ì¬ê³ ë¹„ìœ¨'),
                    x='ìƒí’ˆìƒì„¸', y='í˜„ì¬ì¬ê³ ', color='ì¬ê³ ë¹„ìœ¨', title="ì¬ë£Œë³„ ì¬ê³  í˜„í™© (ì°¨íŠ¸)",
                    hover_data=['ìƒí’ˆìƒì„¸', 'í˜„ì¬ì¬ê³ ', 'uom', 'ìƒíƒœ']
                )
                st.plotly_chart(fig_ing, use_container_width=True)
                
                st.markdown("---")
                st.subheader("ì¬ë£Œë³„ ì¬ê³  í˜„í™© (í…Œì´ë¸”)")
                st.dataframe(df_ing[['ìƒí’ˆìƒì„¸','í˜„ì¬ì¬ê³ ','ì´ˆê¸°ì¬ê³ ','uom','ì¬ê³ ë¹„ìœ¨','ìƒíƒœ']], use_container_width=True)
                
                if not low_ing.empty:
                    st.warning(f"âš ï¸ {', '.join(low_ing['ìƒí’ˆìƒì„¸'])} ì¬ê³ ê°€ 15% ì´í•˜ì…ë‹ˆë‹¤. ë°œì£¼ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [AI/ML í†µí•© ìˆ˜ì • 2] ===
# AIê°€ 'ê±°ì§“ë§'ì„ í•˜ì§€ ì•Šë„ë¡ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ì™€ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ë¦¬
# =============================================================
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [AI/ML í†µí•© ìˆ˜ì • 9] ===
# "ë ˆë²¨ 4: AI ì¬ë¬´/ìš´ì˜ ë¶„ì„ê°€"ë¡œ ì—…ê·¸ë ˆì´ë“œ
# 1. 3ëŒ€ ë¶„ì„ í•¨ìˆ˜ (ì¬ê³ ìœ„í—˜, "ë§ˆì§„ ì¸ì‚¬ì´íŠ¸", íŒë§¤íŒ¨í„´) ìë™ ì‹¤í–‰
# 2. ë¶„ì„ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ AIì—ê²Œ ì „ë‹¬ -> 'ì‹¤í–‰ ì¡°ì–¸' ìƒì„±
# =============================================================
elif menu == "AI ë¹„ì„œ":
    st.header("AI ì¬ë¬´/ìš´ì˜ ë¶„ì„ê°€")

    # [ìˆ˜ì •] ëŒ€í™” ê¸°ë¡ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ì´ë¦„ ë³€ê²½ìœ¼ë¡œ ê°•ì œ ë¦¬ì…‹)
    if "messages_l4" not in st.session_state:
        st.session_state.messages_l4 = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”, ì‚¬ì¥ë‹˜! ê°€ê²Œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ 'ìˆœì´ìµ'ê³¼ 'ì¬ê³  ìœ„í—˜' ê¸°ë°˜ì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."}]
    if "analysis_done_l4" not in st.session_state:
        st.session_state.analysis_done_l4 = False

    # --- 1. (ì‹ ê·œ) í”„ë¡œì•¡í‹°ë¸Œ ë¶„ì„ ì‹¤í–‰ (1íšŒë§Œ) ---
    if not st.session_state.analysis_done_l4:
        with st.spinner("AIê°€ ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¤ìº”í•˜ì—¬ 'ì¬ê³  ìœ„í—˜', 'ë§ˆì§„ ë¶„ì„', 'íŒë§¤ íŒ¨í„´'ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (ìµœëŒ€ 1-2ë¶„ ì†Œìš”)"):
            
            # (1) ì¬ê³  ìœ„í—˜ ë¶„ì„ (L3)
            risk_report = find_inventory_risks(df, df_inv, df_params)
            
            # (2) "ë§ˆì§„ ì¸ì‚¬ì´íŠ¸" ë¶„ì„ (L4)
            profit_report = find_profit_insights(df) # (dfëŠ” ì´ì œ ë§ˆì§„ ì •ë³´ í¬í•¨)
            
            # (3) íŒë§¤ íŒ¨í„´ ë¶„ì„ (L3)
            pattern_report = find_top_correlations(df)
            
            # (4) ë¶„ì„ ê²°ê³¼ë¥¼ AIì—ê²Œ ì „ë‹¬í•  'í•µì‹¬ ì»¨í…ìŠ¤íŠ¸'ë¡œ ì¡°í•©
            st.session_state.proactive_context_l4 = f"""
            [AI ë¶„ì„ ë¦¬í¬íŠ¸ 1: ì¬ê³  ìœ„í—˜ (AI ì˜ˆì¸¡ ê¸°ë°˜)]
            {risk_report}
            
            [AI ë¶„ì„ ë¦¬í¬íŠ¸ 2: ë§ˆì§„ ë¶„ì„ (ì›ê°€ ê¸°ë°˜)]
            {profit_report}
            
            [AI ë¶„ì„ ë¦¬í¬íŠ¸ 3: í•µì‹¬ íŒë§¤ íŒ¨í„´]
            {pattern_report}
            """
            
            st.session_state.analysis_done_l4 = True
            
            # (5) AIë¥¼ í˜¸ì¶œí•˜ì—¬ 'ì‹¤í–‰ ì¡°ì–¸' ìƒì„±
            initial_prompt = (
                "ìœ„ 3ê°€ì§€ ë¶„ì„ ë¦¬í¬íŠ¸(ì¬ê³  ìœ„í—˜, ë§ˆì§„ ë¶„ì„, íŒë§¤ íŒ¨í„´)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, "
                "ì‚¬ì¥ë‹˜ì—ê²Œ 'ë‹¤ìŒ ì£¼ì— ì¦‰ì‹œ ì‹¤í–‰í•  ì•¡ì…˜ í”Œëœ 3ê°€ì§€'ë¥¼ ì¹œê·¼í•œ ë§íˆ¬ë¡œ ë‹´ë°±í•˜ê²Œ ìš”ì•½/ì œì•ˆí•´ ì£¼ì„¸ìš”. "
                "íŠ¹íˆ 'ë§ˆì§„'ê³¼ 'ì¬ê³ 'ë¥¼ ì—°ê³„í•˜ì—¬ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒ 1~2ê°œë§Œ ë½‘ì•„ì„œ ì¡°ì–¸í•´ì£¼ì„¸ìš”."
            )
            
            initial_advice = call_openai_api(
                user_prompt=initial_prompt,
                data_context=st.session_state.proactive_context_l4
            )
            
            if initial_advice:
                st.session_state.messages_l4 = [
                    {"role": "assistant", "content": f"âœ… AI ì¬ë¬´/ìš´ì˜ ë¶„ì„ ì™„ë£Œ! ì‚¬ì¥ë‹˜ì„ ìœ„í•œ **í•µì‹¬ ì‹¤í–‰ ì¡°ì–¸**ì…ë‹ˆë‹¤.\n\n{initial_advice}"}
                ]
            else:
                st.session_state.messages_l4 = [
                    {"role": "assistant", "content": "AI ë¶„ì„ì€ ì™„ë£Œí–ˆìœ¼ë‚˜, ì¡°ì–¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
                ]
            
            safe_rerun() # ë¶„ì„ ì™„ë£Œ í›„ í™”ë©´ ê°±ì‹ 

    # --- 2. ëŒ€í™”ì°½ UI (ê¸°ì¡´ê³¼ ë™ì¼) ---
    
    # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.messages_l4:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # (ë””ë²„ê¹…ìš©) ê´€ë¦¬ìì—ê²Œë§Œ ë³´ì´ëŠ” ì»¨í…ìŠ¤íŠ¸
    if "proactive_context_l4" in st.session_state:
        with st.expander("AIê°€ í˜„ì¬ ì•Œê³  ìˆëŠ” 'í”„ë¡œì•¡í‹°ë¸Œ ë¶„ì„' ë°ì´í„° ğŸ“‹"):
            st.text(st.session_state.proactive_context_l4)

    # [ìˆ˜ì •] st.chat_input ì‚¬ìš©
    if prompt := st.chat_input("ìœ„ ë¶„ì„ ë‚´ìš©ì— ëŒ€í•´ ë” ë¬¼ì–´ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê²ƒì„ ìš”ì²­í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages_l4.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("AIê°€ ë¶„ì„ ë‚´ìš©ê³¼ ì‚¬ì¥ë‹˜ì˜ ì§ˆë¬¸ì„ í•¨ê»˜ ìƒê° ì¤‘ì…ë‹ˆë‹¤... ğŸ§ "):
                
                # [ìˆ˜ì •] AI í˜¸ì¶œ (ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ì™€ ì‚¬ìš©ì ìš”ì²­ ë¶„ë¦¬)
                result_text = call_openai_api(
                    user_prompt=prompt,
                    data_context=st.session_state.get("proactive_context_l4", "ë¶„ì„ ë°ì´í„° ì—†ìŒ")
                )
                
                if result_text:
                    st.markdown(result_text)
                    st.session_state.messages_l4.append({"role": "assistant", "content": result_text})
                else:
                    st.error("AI ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# === [ë¹ˆí‹ˆ ìˆ˜ì •] 'ê°€ê²Œìœ„ì¹˜' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°(ì•± ì¶”ê°€ 0ê±´)ì—ë„ ì˜¤ë¥˜ ì—†ë„ë¡ ìˆ˜ì • ===
# ==============================================================
elif menu == "ë°ì´í„° í¸ì§‘":
    st.header("âœï¸ ë°ì´í„° í¸ì§‘")
    tab1, tab2 = st.tabs(["ê±°ë˜ ìˆ˜ì •/ì‚­ì œ", "ì¬ê³  ì¼ê´„ìˆ˜ì •"])

    # ------------------ ê±°ë˜ ìˆ˜ì •/ì‚­ì œ ------------------
    with tab1:
        df_raw, df_view = load_sales_with_id()
        if df_view.empty:
            st.info("ìˆ˜ì •í•  Firebase ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (CSVëŠ” ì½ê¸° ì „ìš©)")
        else:
            st.caption("ğŸ’¡ Firebaseì— ì €ì¥ëœ ê±°ë˜ ë‚´ì—­ë§Œ ìˆ˜ì •/ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê°€ê²Œìœ„ì¹˜=Firebase)")
            
            # === [ë¹ˆí‹ˆ ìˆ˜ì •] ===
            # 'ê°€ê²Œìœ„ì¹˜' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°(ì•±ìœ¼ë¡œ ì¶”ê°€ëœ ë°ì´í„°ê°€ 0ê±´)ì— ëŒ€í•œ ë°©ì–´ ì½”ë“œ
            if 'ê°€ê²Œìœ„ì¹˜' in df_view.columns:
                df_view_fb = df_view[df_view['ê°€ê²Œìœ„ì¹˜'] == 'Firebase'].copy()
            else:
                # 'ê°€ê²Œìœ„ì¹˜' ì»¬ëŸ¼ ìì²´ê°€ ì—†ìœ¼ë©´, ì•±ìœ¼ë¡œ ì¶”ê°€ëœ ë°ì´í„°ê°€ 0ê±´ì´ë¼ëŠ” ëœ».
                # ë¹ˆ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€.
                df_view_fb = pd.DataFrame(columns=df_view.columns) 
            # === [ìˆ˜ì • ì™„ë£Œ] ===
            
            if df_view_fb.empty:
                st.info("ì•„ì§ ì•±ì„ í†µí•´ ì¶”ê°€ëœ(ìˆ˜ì • ê°€ëŠ¥í•œ) ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                edited_df = st.data_editor(
                    df_view_fb[['_id','ë‚ ì§œ','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ']],
                    column_config={
                        "_id": st.column_config.TextColumn("ë¬¸ì„œID", disabled=True),
                        "ë‚ ì§œ": st.column_config.DateColumn("ë‚ ì§œ", format="YYYY-MM-DD"),
                    },
                    hide_index=True,
                    num_rows="dynamic"
                )
                
                reflect_inv = st.checkbox("ì €ì¥ ì‹œ ì¬ê³ ì— ë°˜ì˜(ì°¨ê°/ë³µì›)", value=True)
                
                if st.button("ë³€ê²½ëœ ë‚´ìš© ì €ì¥í•˜ê¸° ğŸ’¾"):
                    changed = 0
                    for i, new in edited_df.iterrows():
                        doc_id = new['_id']
                        orig = df_raw[df_raw['_id'] == doc_id].iloc[0]
                        patch = {}
                        
                        try:
                            new_date_str = str(pd.to_datetime(new['ë‚ ì§œ']).date())
                        except Exception:
                            new_date_str = str(orig.get('ë‚ ì§œ'))

                        if new_date_str != str(orig.get('ë‚ ì§œ')):
                            patch['ë‚ ì§œ'] = new_date_str
                        
                        detail_en = from_korean_detail(new['ìƒí’ˆìƒì„¸'])
                        if detail_en != orig.get('ìƒí’ˆìƒì„¸'):
                            patch['ìƒí’ˆìƒì„¸'] = detail_en
                        
                        qty_new = int(new['ìˆ˜ëŸ‰'])
                        if qty_new != int(orig.get('ìˆ˜ëŸ‰', 0)):
                            patch['ìˆ˜ëŸ‰'] = qty_new
                        
                        unit_new = float(new['ë‹¨ê°€'])
                        rev_new = float(new['ìˆ˜ìµ'])
                        
                        if unit_new != float(orig.get('ë‹¨ê°€', 0)):
                            patch['ë‹¨ê°€'] = unit_new
                        if rev_new != float(orig.get('ìˆ˜ìµ', 0)):
                            patch['ìˆ˜ìµ'] = rev_new
                        
                        if patch:
                            if reflect_inv and 'ìˆ˜ëŸ‰' in patch:
                                diff = qty_new - int(orig.get('ìˆ˜ëŸ‰', 0))
                                adjust_inventory_by_recipe(detail_en, diff, move_type="edit_adjust", note=str(doc_id))
                            
                            db.collection(SALES_COLLECTION).document(doc_id).update(patch)
                            changed += 1
                    
                    if changed:
                        st.success(f"âœ… {changed}ê±´ ì €ì¥ ì™„ë£Œ")
                        safe_rerun()
                    else:
                        st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            st.markdown("---")
            
            # [ìˆ˜ì •] df_view_fbì—ì„œ ID ëª©ë¡ì„ ê°€ì ¸ì˜¤ë„ë¡ ë³€ê²½
            del_options = df_view_fb['_id'].tolist() if not df_view_fb.empty else []

            del_ids = st.multiselect(
                "ğŸ—‘ï¸ ì‚­ì œí•  ê±°ë˜ ì„ íƒ (ë¬¸ì„œID ê¸°ì¤€)",
                options=del_options
            )
            colx, _ = st.columns([1,3])
            with colx:
                restore_inv_on_delete = st.checkbox("ì‚­ì œ ì‹œ ì¬ê³  ë³µì›", value=True)
            
            if st.button("ì‚­ì œ ì‹¤í–‰", type="primary", disabled=(len(del_ids) == 0)):
                for did in del_ids:
                    if restore_inv_on_delete:
                        try:
                            raw = df_raw[df_raw['_id'] == did].iloc[0]
                            qty_to_restore = -int(raw.get('ìˆ˜ëŸ‰', 0)) # ìˆ˜ëŸ‰ì„ ìŒìˆ˜ë¡œ
                            detail_en = raw.get('ìƒí’ˆìƒì„¸')
                            if qty_to_restore != 0 and detail_en:
                                adjust_inventory_by_recipe(detail_en, qty_to_restore, move_type="delete_restore", note=str(did))
                        except Exception as e:
                            st.warning(f"{did} ì¬ê³  ë³µì› ì‹¤íŒ¨: {e}")
                    
                    db.collection(SALES_COLLECTION).document(did).delete()
                
                st.success(f"âœ… {len(del_ids)}ê±´ ì‚­ì œ ì™„ë£Œ")
                safe_rerun()

    # ------------------ ì¬ê³  ì¼ê´„ìˆ˜ì • ------------------
    with tab2:
        st.subheader("âœï¸ ì¬ê³  ìˆ˜ê¸° ê´€ë¦¬ (ì‹¤ì‚¬ ë°˜ì˜)")
        st.info("ì‹¤ì œ ì¬ê³ ë¥¼ í™•ì¸í•œ í›„, ìˆ˜ëŸ‰ì„ ì§ì ‘ ìˆ˜ì •í•˜ê³  ì €ì¥í•˜ì„¸ìš”.")
        
        df_inv = load_inventory_df()
        
        if df_inv.empty:
            st.warning("ì¬ê³  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            edited_inv = st.data_editor(
                df_inv,
                column_config={
                    "ìƒí’ˆìƒì„¸_en": st.column_config.TextColumn("SKU (Eng)", disabled=True),
                    "ìƒí’ˆìƒì„¸": st.column_config.TextColumn("í’ˆëª©ëª…", disabled=True),
                    "ì´ˆê¸°ì¬ê³ ": st.column_config.NumberColumn("ì´ˆê¸° ì¬ê³ ", disabled=True),
                    "í˜„ì¬ì¬ê³ ": st.column_config.NumberColumn("í˜„ì¬ ì¬ê³ ", min_value=0.0, format="%.2f"),
                    "uom": st.column_config.TextColumn("ë‹¨ìœ„", disabled=True),
                    "is_ingredient": st.column_config.CheckboxColumn("ì¬ë£Œ ì—¬ë¶€", disabled=True),
                },
                hide_index=True,
                use_container_width=True
            )
            
            if st.button("ì‹¤ì‚¬ ì¬ê³  ì €ì¥í•˜ê¸° ğŸ’¾", type="primary"):
                changed = 0
                original_map = {row['ìƒí’ˆìƒì„¸_en']: row['í˜„ì¬ì¬ê³ '] for _, row in df_inv.iterrows()}
                
                batch = db.batch()
                
                for item in edited_inv:
                    sku = item['ìƒí’ˆìƒì„¸_en']
                    new_stock = safe_float(item['í˜„ì¬ì¬ê³ '])
                    
                    if sku in original_map and original_map[sku] != new_stock:
                        doc_ref = db.collection(INVENTORY_COLLECTION).document(sku)
                        batch.update(doc_ref, {'í˜„ì¬ì¬ê³ ': new_stock})
                        changed += 1
                        
                if changed > 0:
                    batch.commit()
                    st.success(f"âœ… ì¬ê³  {changed}ê±´ ì €ì¥ ì™„ë£Œ")
                    safe_rerun()
                else:
                    st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

# ==============================================================

# ğŸ“‹ ê±°ë˜ ë‚´ì—­
# ==============================================================
elif menu == "ê±°ë˜ ë‚´ì—­":
    st.header("ğŸ“‹ ì „ì²´ ê±°ë˜ ë‚´ì—­")
    if df.empty:
        st.info("í‘œì‹œí•  ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        cols = ['ë‚ ì§œ','ìƒí’ˆì¹´í…Œê³ ë¦¬','ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ','ìš”ì¼','ì‹œ']
        cols = [c for c in cols if c in df.columns]
        st.caption(f"í˜„ì¬ ë°ì´í„° í¬ê¸°: {len(df)}í–‰")
        
        # [ìˆ˜ì •] ì›ë³¸ì˜ st.dataframe(df.head(1000)) ì¤‘ë³µ ì œê±°
        st.dataframe(df[cols].sort_values('ë‚ ì§œ', ascending=False), width=None, use_container_width=True)


# ==============================================================
# â“ ë„ì›€ë§
# ==============================================================
else:  # menu == "ë„ì›€ë§"
    st.header("â˜•ï¸ ì»¤í”¼ ì›ë‘ ì¬ê³ ê´€ë¦¬ íŒŒì´í”„ë¼ì¸ ì‰½ê²Œ ì´í•´í•˜ê¸°")
    
    # [AI/ML í†µí•© ìˆ˜ì •] ë„ì›€ë§ ë‚´ìš© ì—…ë°ì´íŠ¸
    st.markdown("""
> **â€œì»¤í”¼ ì›ë‘ê°€ ì–´ë–»ê²Œ ë“¤ì–´ì˜¤ê³ , ì–¼ë§ˆë‚˜ ì“°ì´ê³ , ì–¸ì œ ë‹¤ì‹œ ì£¼ë¬¸ë¼ì•¼ í•˜ëŠ”ì§€ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ì!â€** ì—‘ì…€ ëŒ€ì‹  ERPê°€ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì¤ë‹ˆë‹¤.

### 1. (AI) ìŠ¤ë§ˆíŠ¸ ë°œì£¼ ë¡œì§ (ì¬ê³  ê´€ë¦¬ íƒ­)
| ë‹¨ê³„ | í•˜ëŠ” ì¼ | ì˜ˆì‹œ |
| --- | --- | --- |
| **1. (AI) ìˆ˜ìš” ì˜ˆì¸¡** | Prophet (ML)ì´ "ì•„ë©”ë¦¬ì¹´ë…¸"ì˜ **ë¯¸ë˜ 21ì¼** íŒë§¤ëŸ‰ì„ **[500ì”]**ìœ¼ë¡œ ì˜ˆì¸¡ |
| **2. ì†Œì§„ëŸ‰ ê³„ì‚°** | [500ì”] x [ë ˆì‹œí”¼: ì”ë‹¹ 20g] = **[10,000g]** (ì˜ˆìƒ ì´ ì†Œì§„ëŸ‰) |
| **3. ê¶Œì¥ ë°œì£¼ëŸ‰** | [10,000g] - [í˜„ì¬ ì¬ê³ : 3,000g] = **[7,000g]** (ê¶Œì¥ ë°œì£¼ëŸ‰) |
| **4. ROP (ë°œì£¼ì )** | (ì¼í‰ê· ì†Œì§„ * ë¦¬ë“œíƒ€ì„) + ì•ˆì „ì¬ê³ . ì´ë³´ë‹¤ ì¬ê³ ê°€ ë‚®ìœ¼ë©´ **'ğŸš¨ ë°œì£¼ìš”ë§'** ì•Œë¦¼ |
| **(ëŒ€ì²´)** | AI ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ, ê³¼ê±° 28ì¼ í‰ê·  íŒë§¤ëŸ‰ìœ¼ë¡œ ìë™ ì „í™˜ë˜ì–´ ê³„ì‚°ë©ë‹ˆë‹¤. |

### 2. (AI) ë§ˆì¼€íŒ… ë³´ì¡° (AI ë¹„ì„œ íƒ­)
| ê¸°ëŠ¥ | ì„¤ëª… |
| --- | --- |
| **ì¸ìŠ¤íƒ€ê·¸ë¨ ìƒì„±** | í˜„ì¬ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ í™ë³´ ë¬¸êµ¬ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤. |
| **ìš´ì˜ ë³´ê³ ** | ì¼ì¼ ë§¤ì¶œ, íŒë§¤ ê±´ìˆ˜ ë“±ì„ ìš”ì•½í•˜ì—¬ ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. |

### 3. ê¸°ë³¸ ë°ì´í„° íë¦„
| ë‹¨ê³„ | í•˜ëŠ” ì¼ | ì˜ˆì‹œ |
| --- | --- | --- |
| **1. ì›ë‘ ì…ê³ ** | 'ë°ì´í„° í¸ì§‘' > 'ì¬ê³  ì¼ê´„ìˆ˜ì •' íƒ­ì—ì„œ **[+10,000g]** ìˆ˜ë™ ì…ë ¥ |
| **2. íŒë§¤ ë°œìƒ** | 'ê±°ë˜ ì¶”ê°€' íƒ­ ë˜ëŠ” POSì—ì„œ 'ì•„ë©”ë¦¬ì¹´ë…¸' 1ì” íŒë§¤ (Firestore 'coffee_sales'ì— ê¸°ë¡) |
| **3. ìë™ ì°¨ê°** | ì‹œìŠ¤í…œì´ 'ì•„ë©”ë¦¬ì¹´ë…¸' ë ˆì‹œí”¼(BOM)ë¥¼ ì¡°íšŒí•˜ì—¬ [ì›ë‘: 20g] ì‚¬ìš© í™•ì¸ |
| **4. ì¬ê³  ë°˜ì˜** | 'inventory' DBì˜ 'ì›ë‘' ì¬ê³ ë¥¼ **[-20g]** ìë™ ì°¨ê° (ì¬ê³  ì´ë™ ë¡œê·¸ ê¸°ë¡) |
""")