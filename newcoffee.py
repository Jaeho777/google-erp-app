# ==============================================================
# â˜• Coffee ERP Dashboard â€” Company Showcase Edition (Tone-Down Blue)
# (ê¸°ì¡´ ì£¼ì„ ìƒëµ)
# ==============================================================

import os
import json
import re
import warnings
from math import ceil
from pathlib import Path
from datetime import datetime
import time # #[AI/ML í†µí•© ì¶”ê°€] (Mock ì‘ë‹µìš©)

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.io as pio

import firebase_admin
from firebase_admin import credentials, firestore

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1 (AI ë¹„ì„œ) ë° SPRINT 2 (ìˆ˜ìš” ì˜ˆì¸¡) ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import openai
    from prophet import Prophet
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
except ImportError:
    st.error("""
    AI/ML ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.
    í„°ë¯¸ë„ì—ì„œ 'pip install openai prophet scikit-learn'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
    """)
    st.stop()
# === [AI/ML í†µí•© ì¶”ê°€] ===


st.set_page_config(page_title="â˜• Coffee ERP Dashboard", layout="wide")


# (init_firebase í•¨ìˆ˜ ì›ë³¸)
def init_firebase():
    try:
        if "GOOGLE_APPLICATION_CREDENTIALS_JSON" in os.environ:
            cred_info = json.loads(os.environ["GOOGLE_APPLICATION_CREDENTIALS_JSON"])
            cred = credentials.Certificate(cred_info)
            if not firebase_admin._apps:
                firebase_admin.initialize_app(cred)
            return firestore.client(), "success"
        else:
            return None, "no_env"
    except Exception as e:
        return None, f"error: {e}"

# âœ… í•¨ìˆ˜ í˜¸ì¶œ í›„ UI í‘œì‹œ ë¶„ë¦¬
db, fb_status = init_firebase()

# --- Pylance/static analyzer guards (no runtime effect) ---
items = []  # type: ignore
sold_qty = 0  # type: ignore
summary = []  # type: ignore

# ----------------------
# 0ï¸âƒ£ ê²½ë¡œ/ìƒìˆ˜ (íŒ€ì›ì´ ì–´ë””ì„œ ë°›ì•„ë„ ë™ì‘)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
BASE_DIR = Path(__file__).resolve().parent

try:
    SECRETS = dict(st.secrets)
except Exception:
    SECRETS = {}

def _resolve_path(val, default: Path) -> Path:
    if not val:
        return default
    p = Path(str(val))
    return p if p.is_absolute() else (BASE_DIR / p)

DATA_DIR   = _resolve_path(SECRETS.get("DATA_DIR")   or os.environ.get("ERP_DATA_DIR"),   BASE_DIR / "data")
ASSETS_DIR = _resolve_path(SECRETS.get("ASSETS_DIR") or os.environ.get("ERP_ASSETS_DIR"), BASE_DIR / "assets")
KEYS_DIR   = _resolve_path(SECRETS.get("KEYS_DIR")   or os.environ.get("ERP_KEYS_DIR"),   BASE_DIR / "keys")

CSV_PATH     = DATA_DIR / "Coffee Shop Sales.csv"
PIPELINE_IMG = ASSETS_DIR / "pipeline_diagram.png"
SA_FILE_PATH = KEYS_DIR / "serviceAccount.json"

SALES_COLLECTION      = "coffee_sales"
INVENTORY_COLLECTION  = "inventory"
ORDERS_COLLECTION     = "orders"
SKU_PARAMS_COLLECTION = "sku_params"

RECIPES_COLLECTION      = "recipes"
STOCK_COUNTS_COLLECTION = "stock_counts"
STOCK_MOVES_COLLECTION  = "stock_moves"

USE_KRW_CONVERSION = False
KRW_PER_USD = 1350
DEFAULT_INITIAL_STOCK   = 10000
REORDER_THRESHOLD_RATIO = 0.15

for p in (DATA_DIR, ASSETS_DIR, KEYS_DIR):
    p.mkdir(parents=True, exist_ok=True)


# ----------------------
# 0-1ï¸âƒ£ Firebase ì´ˆê¸°í™” (Secrets â†’ keys/ â†’ GOOGLE_APPLICATION_CREDENTIALS)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_resource
def init_firestore():
    """Firebase ì¸ì¦ ë° Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€ + ìºì‹œ ì ìš©)"""
    if firebase_admin._apps:
        return firestore.client()
    svc_dict = SECRETS.get("firebase_service_account")
    if isinstance(svc_dict, dict) and svc_dict:
        cred = credentials.Certificate(svc_dict)
        firebase_admin.initialize_app(cred)
        return firestore.client()
    if SA_FILE_PATH.exists():
        cred = credentials.Certificate(str(SA_FILE_PATH))
        firebase_admin.initialize_app(cred)
        return firestore.client()
    gac = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if gac and Path(gac).expanduser().exists():
        firebase_admin.initialize_app()
        return firestore.client()
    st.error(
        "Firebase ìê²©ì¦ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:\n"
        "â€¢ st.secrets['firebase_service_account'] ë”•ì…”ë„ˆë¦¬\n"
        "â€¢ keys/serviceAccount.json íŒŒì¼\n"
        "â€¢ í™˜ê²½ë³€ìˆ˜ GOOGLE_APPLICATION_CREDENTIALS=ìê²©ì¦ëª…íŒŒì¼ê²½ë¡œ"
    )
    st.stop()


db = init_firestore()

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í‚¤ ì„¤ì •
try:
    openai.api_key = st.secrets["openai"]["api_key"]
except (KeyError, AttributeError):
    st.warning("""
    OpenAI API í‚¤ê°€ 'secrets.toml'ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 
    AI ë¹„ì„œ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šê±°ë‚˜ Mock ë°ì´í„°ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
    [.streamlit/secrets.toml] íŒŒì¼ì— [openai] api_key = "sk-..."ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
    """)
    openai.api_key = None # í‚¤ê°€ ì—†ì–´ë„ ì•±ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡
# === [AI/ML í†µí•© ì¶”ê°€] ===

# ----------------------
# 0-2ï¸âƒ£ UI/ìŠ¤íƒ€ì¼
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
pio.templates.default = "plotly_white"
px.defaults.template = "plotly_white"
px.defaults.color_continuous_scale = "Blues"

st.markdown("""
    <style>
    /* ... (ê¸°ì¡´ ìŠ¤íƒ€ì¼ ì •ì˜) ... */
    </style>
""", unsafe_allow_html=True)


st.markdown("""
<div class="dashboard-header">
  <h1>â˜• Coffee ERP Dashboard</h1>
</div>
""", unsafe_allow_html=True)

# ----------------------
# 0-3ï¸âƒ£ í•œê¸€ ë§¤í•‘ í…Œì´ë¸”
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
category_map = {
    "Coffee": "ì»¤í”¼", "Tea": "ì°¨", "Bakery": "ë² ì´ì»¤ë¦¬",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Packaged Chocolate": "í¬ì¥ ì´ˆì½œë¦¿",
}
rev_category_map = {v: k for k, v in category_map.items()}
rev_category_map.update({
    "ë² ì´ì»¤ë¦¬": "Bakery",
    # ... (ê¸°ì¡´ ì—­ ë§¤í•‘) ...
    "ì»¤í”¼": "Coffee",
})

type_map = {
    "Barista Espresso": "ë°”ë¦¬ìŠ¤íƒ€ ì—ìŠ¤í”„ë ˆì†Œ",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Premium Brewed Coffee": "í”„ë¦¬ë¯¸ì—„ ë¸Œë£¨ë“œ ì»¤í”¼",
}
rev_type_map = {v: k for k, v in type_map.items()}

SIZE_SUFFIX_MAP = {"Lg": "ë¼ì§€", "Rg": "ë ˆê·¤ëŸ¬", "Sm": "ìŠ¤ëª°"}
REV_SIZE_SUFFIX_MAP = {"ë¼ì§€": "Lg", "ë ˆê·¤ëŸ¬": "Rg", "ìŠ¤ëª°": "Sm"}

detail_base_map = {
    "Almond Croissant": "ì•„ëª¬ë“œ í¬ë£¨ì•„ìƒ",
    # ... (ê¸°ì¡´ ë§¤í•‘) ...
    "Traditional Blend Chai": "íŠ¸ë˜ë””ì…”ë„ ë¸”ë Œë“œ ì°¨ì´",
}
rev_detail_base_map = {v: k for k, v in detail_base_map.items()}

def to_korean_detail(name: str) -> str:
    s = str(name).strip()
    if re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s):
        return s
    m = re.search(r"\s+(Lg|Rg|Sm)$", s)
    size_en = m.group(1) if m else None
    base_en = s[: -len(size_en) - 1] if size_en else s
    base_ko = detail_base_map.get(base_en, base_en)
    if size_en:
        return f"{base_ko} ({SIZE_SUFFIX_MAP[size_en]})"
    return base_ko

def from_korean_detail(display: str) -> str:
    s = str(display).strip()
    if re.search(r"\s+(Lg|Rg|Sm)$", s):
        return s
    m = re.search(r"\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", s)
    size_ko = m.group(1) if m else None
    base_ko = re.sub(r"\s*\((ë¼ì§€|ë ˆê·¤ëŸ¬|ìŠ¤ëª°)\)$", "", s)
    base_en = rev_detail_base_map.get(base_ko, base_ko)
    if size_ko:
        return f"{base_en} {REV_SIZE_SUFFIX_MAP[size_ko]}"
    return base_en

weekday_map = {"Monday": "ì›”", "Tuesday": "í™”", "Wednesday": "ìˆ˜",
               "Thursday": "ëª©", "Friday": "ê¸ˆ", "Saturday": "í† ", "Sunday": "ì¼"}
weekday_order_kr = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]

def map_series(s: pd.Series, mapping: dict) -> pd.Series:
    return s.apply(lambda x: mapping.get(x, x))

# ----------------------
# âœ… UoM(ë‹¨ìœ„) ìœ í‹¸
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def normalize_uom(u: str | None) -> str:
    u = (u or "ea").strip().lower()
    if u in {"g", "gram", "grams", "ê·¸ë¨", "kg", "í‚¬ë¡œê·¸ë¨"}:
        return "g"
    if u in {"ml", "ë°€ë¦¬ë¦¬í„°", "l", "ë¦¬í„°"}:
        return "ml"
    return "ea"

def convert_qty(qty: float, from_uom: str, to_uom: str) -> float:
    fu = normalize_uom(from_uom)
    tu = normalize_uom(to_uom)
    if fu == tu:
        return float(qty)
    return float(qty)

def safe_float(x, default=0.0):
    if x is None:
        return default
    try:
        if isinstance(x, (int, float)):
            try:
                if pd.isna(x):
                    return default
            except Exception:
                pass
            return float(x)
        if isinstance(x, str):
            s = x.strip()
            if s == "" or s.lower() in {"nan", "none"}:
                return default
            s = s.replace(",", "")
            return float(s)
        return float(x)
    except Exception:
        return default

# ----------------------
# âœ… ë‚ ì§œ íŒŒì„œ: ëª…ì‹œ í˜•ì‹ ìš°ì„  + ê²½ê³ ì—†ëŠ” í´ë°±
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def parse_mixed_dates(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip()
    out = pd.Series(pd.NaT, index=s.index, dtype="datetime64[ns]")
    patterns = [
        (r'^\d{4}-\d{2}-\d{2}$', '%Y-%m-%d'),
        (r'^\d{4}/\d{2}/\d{2}$', '%Y/%m/%d'),
        (r'^\d{2}/\d{2}/\d{4}$', '%m/%d/%Y'),
        (r'^\d{2}-\d{2}-\d{4}$', '%m-%d-%Y'),
        (r'^\d{4}\.\d{2}\.\d{2}$', '%Y.%m.%d'),
        (r'^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}$', '%Y-%m-%d %H:%M:%S'),
        (r'^\d{2}/\d{2}/\d{4}\s+\d{2}:\d{2}:\d{2}$', '%m/%d/%Y %H:%M:%S'),
    ]
    for pat, fmt in patterns:
        mask = s.str.match(pat)
        if mask.any():
            out.loc[mask] = pd.to_datetime(s.loc[mask], format=fmt, errors='coerce')
    remain = out.isna()
    if remain.any():
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", UserWarning)
            out.loc[remain] = pd.to_datetime(s.loc[remain], errors='coerce')
    return out

# ----------------------
# 1ï¸âƒ£ CSV ë¡œë“œ (ìƒ˜í”Œ ìƒì„± ì—†ìŒ)
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_data(ttl=0)
def load_csv(path: Path) -> pd.DataFrame:
    if not path.exists():
        st.error(f"CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì— 'Coffee Shop Sales.csv'ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\n(í˜„ì¬ ì°¾ëŠ” ê²½ë¡œ: {path})")
        st.stop()
    df = pd.read_csv(path)
    df = df.rename(columns={
        'transaction_id': 'ê±°ë˜ë²ˆí˜¸', 'transaction_date': 'ë‚ ì§œ', 'transaction_time': 'ì‹œê°„',
        'transaction_qty': 'ìˆ˜ëŸ‰', 'store_id': 'ê°€ê²ŒID', 'store_location': 'ê°€ê²Œìœ„ì¹˜',
        'product_id': 'ìƒí’ˆID', 'unit_price': 'ë‹¨ê°€', 'product_category': 'ìƒí’ˆì¹´í…Œê³ ë¦¬',
        'product_type': 'ìƒí’ˆíƒ€ì…', 'product_detail': 'ìƒí’ˆìƒì„¸', 'Revenue': 'ìˆ˜ìµ'
    })
    df['ìˆ˜ìµ'] = df['ìˆ˜ìµ'].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
    df['ë‹¨ê°€'] = df['ë‹¨ê°€'].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
    if USE_KRW_CONVERSION:
        df['ìˆ˜ìµ'] *= KRW_PER_USD
        df['ë‹¨ê°€'] *= KRW_PER_USD
    df['ë‚ ì§œ'] = parse_mixed_dates(df['ë‚ ì§œ'])
    if 'ì‹œê°„' in df.columns:
        df['ì‹œ'] = pd.to_datetime(df['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df['ì‹œ'] = None
    df['ìš”ì¼'] = df['ë‚ ì§œ'].dt.day_name()
    df['ì›”'] = df['ë‚ ì§œ'].dt.month
    return df

df_csv = load_csv(CSV_PATH)

# ----------------------
# 2ï¸âƒ£ Firestore(íŒë§¤) ë¡œë“œ
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def load_sales_from_firestore() -> pd.DataFrame:
    docs = db.collection(SALES_COLLECTION).stream()
    data = [d.to_dict() for d in docs]
    df_fb = pd.DataFrame(data)
    if df_fb.empty:
        return df_fb
    if 'ë‚ ì§œ' in df_fb.columns:
        df_fb['ë‚ ì§œ'] = parse_mixed_dates(df_fb['ë‚ ì§œ'])
    if 'ìˆ˜ìµ' in df_fb.columns:
        df_fb['ìˆ˜ìµ'] = pd.to_numeric(df_fb['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_fb.columns:
        df_fb['ë‹¨ê°€'] = pd.to_numeric(df_fb['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_fb.columns:
        df_fb['ìˆ˜ëŸ‰'] = pd.to_numeric(df_fb['ìˆ˜ëŸ‰'], errors='coerce')
    if 'ì‹œê°„' in df_fb.columns:
        df_fb['ì‹œ'] = pd.to_datetime(df_fb['ì‹œê°„'], format='%H:%M:%S', errors='coerce').dt.hour
    else:
        df_fb['ì‹œ'] = None
    df_fb['ìš”ì¼'] = df_fb['ë‚ ì§œ'].dt.day_name()
    df_fb['ì›”'] = df_fb['ë‚ ì§œ'].dt.month
    return df_fb

df_fb = load_sales_from_firestore()

def load_sales_with_id():
    docs = db.collection(SALES_COLLECTION).stream()
    rows = []
    for d in docs:
        rec = d.to_dict()
        rec["_id"] = d.id
        rows.append(rec)
    df_raw = pd.DataFrame(rows)
    if df_raw.empty:
        return df_raw, df_raw
    if 'ë‚ ì§œ' in df_raw.columns:
        df_raw['ë‚ ì§œ'] = parse_mixed_dates(df_raw['ë‚ ì§œ'])
    if 'ìˆ˜ìµ' in df_raw: df_raw['ìˆ˜ìµ'] = pd.to_numeric(df_raw['ìˆ˜ìµ'], errors='coerce')
    if 'ë‹¨ê°€' in df_raw: df_raw['ë‹¨ê°€'] = pd.to_numeric(df_raw['ë‹¨ê°€'], errors='coerce')
    if 'ìˆ˜ëŸ‰' in df_raw: df_raw['ìˆ˜ëŸ‰'] = pd.to_numeric(df_raw['ìˆ˜ëŸ‰'], errors='coerce')
    df_view = df_raw.copy()
    if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df_view: df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df_view['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
    if 'ìƒí’ˆíƒ€ì…' in df_view: df_view['ìƒí’ˆíƒ€ì…'] = map_series(df_view['ìƒí’ˆíƒ€ì…'], type_map)
    if 'ìƒí’ˆìƒì„¸' in df_view: df_view['ìƒí’ˆìƒì„¸'] = df_view['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)
    return df_raw, df_view

# ----------------------
# 3ï¸âƒ£ CSV + Firebase í†µí•© â†’ í™”ë©´í‘œì‹œìš© í•œê¸€í™”
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
df = pd.concat([df_csv, df_fb], ignore_index=True)
if 'ìš”ì¼' in df.columns:
    df['ìš”ì¼'] = map_series(df['ìš”ì¼'], weekday_map)
if 'ìƒí’ˆì¹´í…Œê³ ë¦¬' in df.columns:
    df['ìƒí’ˆì¹´í…Œê³ ë¦¬'] = map_series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬'], category_map)
if 'ìƒí’ˆíƒ€ì…' in df.columns:
    df['ìƒí’ˆíƒ€ì…'] = map_series(df['ìƒí’ˆíƒ€ì…'], type_map)
if 'ìƒí’ˆìƒì„¸' in df.columns:
    df['ìƒí’ˆìƒì„¸'] = df['ìƒí’ˆìƒì„¸'].apply(to_korean_detail)

# ----------------------
# 4ï¸âƒ£ ê³µìš© ìœ í‹¸
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
def safe_rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    elif hasattr(st, "experimental_rerun"):
        st.experimental_rerun()

def format_krw(x: float) -> str:
    try:
        return f"{x:,.0f} ì›"
    except Exception:
        return "-"

VALID_UOM = {"ea","g","kg","ml","l"}
UOM_SYNONYM = {
    "piece":"ea","pcs":"ea","unit":"ea","units":"ea",
    "gram":"g","grams":"g","gms":"g",
    "kilogram":"kg","kilograms":"kg",
    "milliliter":"ml","millilitre":"ml","milliliters":"ml","millilitres":"ml",
    "liter":"l","litre":"l","liters":"l","litres":"l",
}

def normalize_uom(u: str) -> str:
    if not u:
        return "ea"
    s = str(u).strip().lower()
    s = UOM_SYNONYM.get(s, s)
    if s not in VALID_UOM:
        return s
    return s

def convert_qty(qty: float, from_uom: str, to_uom: str) -> float:
    try:
        q = float(qty)
    except Exception:
        return 0.0
    f = normalize_uom(from_uom)
    t = normalize_uom(to_uom)
    if f == t:
        return q
    if f == "g" and t == "kg":
        return q / 1000.0
    if f == "kg" and t == "g":
        return q * 1000.0
    if f == "ml" and t == "l":
        return q / 1000.0
    if f == "l" and t == "ml":
        return q * 1000.0
    return q

# ----------------------
# 4-1ï¸âƒ£ [NEW] ì¬ê³ ê´€ë¦¬
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_data(ttl=60)
def load_recipe(menu_sku_en: str) -> list[dict]:
    try:
        ref = db.collection(RECIPES_COLLECTION).document(menu_sku_en).get()
        if ref.exists:
            data = ref.to_dict()
            return data.get("ingredients", [])
    except Exception:
        pass
    return []

def ensure_inventory_doc(product_detail_en: str, uom: str = "ea", is_ingredient: bool = False):
    ref = db.collection(INVENTORY_COLLECTION).document(product_detail_en)
    snap = ref.get()
    if snap.exists:
        data = snap.to_dict() or {}
        patch = {}
        if normalize_uom(data.get("uom")) != normalize_uom(uom):
            patch["uom"] = normalize_uom(uom)
        if bool(data.get("is_ingredient", False)) != bool(is_ingredient):
            patch["is_ingredient"] = bool(is_ingredient)
        if patch:
            ref.update(patch)
        return ref
    else:
        ref.set({
            "ìƒí’ˆìƒì„¸_en": product_detail_en,
            "ì´ˆê¸°ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "í˜„ì¬ì¬ê³ ": DEFAULT_INITIAL_STOCK,
            "uom": normalize_uom(uom),
            "is_ingredient": bool(is_ingredient),
        })
        return ref

def ensure_ingredient_sku(ingredient_en: str, uom: str = "ea"):
    return ensure_inventory_doc(ingredient_en, uom=uom, is_ingredient=True)

def deduct_stock(product_detail_en: str, qty: int):
    ref = ensure_inventory_doc(product_detail_en)
    snap = ref.get()
    data = snap.to_dict() if snap.exists else {}
    init_stock = int(data.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    cur_stock = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    new_stock = max(cur_stock - int(qty), 0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return init_stock, new_stock

def load_inventory_df() -> pd.DataFrame:
    inv_docs = db.collection(INVENTORY_COLLECTION).stream()
    rows = []
    for d in inv_docs:
        doc = d.to_dict() or {}
        en = doc.get("ìƒí’ˆìƒì„¸_en", d.id)
        ko = to_korean_detail(en)
        rows.append({
            "ìƒí’ˆìƒì„¸_en": en,
            "ìƒí’ˆìƒì„¸": ko,
            "ì´ˆê¸°ì¬ê³ ": doc.get("ì´ˆê¸°ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "í˜„ì¬ì¬ê³ ": doc.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK),
            "uom": normalize_uom(doc.get("uom", "ea")),
            "is_ingredient": bool(doc.get("is_ingredient", False)),
        })
    return pd.DataFrame(rows)

def get_all_recipe_ingredients() -> set:
    ingredients = set()
    try:
        docs = db.collection(RECIPES_COLLECTION).stream()
        for d in docs:
            items = (d.to_dict() or {}).get("ingredients", [])
            for it in items:
                ingredients.add(it["ingredient_en"])
    except Exception:
        pass
    return ingredients

def deduct_inventory(ingredient_en: str, qty: float, uom: str):
    ref = ensure_inventory_doc(ingredient_en, uom=uom)
    snap = ref.get()
    data = snap.to_dict() or {}
    cur = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
    inv_uom = normalize_uom(data.get("uom", "ea"))
    use_qty = convert_qty(qty, from_uom=uom, to_uom=inv_uom)
    new_stock = max(cur - use_qty, 0.0)
    ref.update({"í˜„ì¬ì¬ê³ ": new_stock})
    return cur, new_stock, inv_uom

def apply_recipe_deduction(menu_sku_en: str, sold_qty: int, commit: bool = True) -> list[dict]:
    items = load_recipe(menu_sku_en)
    summary: list[dict] = []
    if not items:
        ref = ensure_inventory_doc(menu_sku_en, uom="ea")
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used = float(sold_qty)
        after = max(before - used, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": menu_sku_en, "used": used, "uom": inv_uom, "before": before, "after": after})
        return summary
    for it in items:
        ing = it["ingredient_en"]
        uom = normalize_uom(it["uom"])
        qty_per_unit = safe_float(it["qty"])
        waste_pct = safe_float(it["waste_pct"], 0)
        total_used = (qty_per_unit * sold_qty) * (1 + (waste_pct / 100.0))
        ref = ensure_inventory_doc(ing, uom=uom, is_ingredient=True)
        snap = ref.get()
        data = snap.to_dict() or {}
        before = safe_float(data.get("í˜„ì¬ì¬ê³ ", DEFAULT_INITIAL_STOCK))
        inv_uom = normalize_uom(data.get("uom", "ea"))
        used_converted = convert_qty(total_used, from_uom=uom, to_uom=inv_uom)
        after = max(before - used_converted, 0.0)
        if commit:
            ref.update({"í˜„ì¬ì¬ê³ ": after})
        summary.append({"ingredient_en": ing, "used": used_converted, "uom": inv_uom, "before": before, "after": after})
    return summary

def adjust_inventory_by_recipe(menu_sku_en: str,
                               qty_diff: int,
                               move_type: str = "manual_adjust",
                               note: str = ""):
    if qty_diff == 0:
        return
    details = apply_recipe_deduction(menu_sku_en, qty_diff, commit=True)
    log_doc = {
        "ts": datetime.now().isoformat(),
        "type": move_type,
        "menu_sku_en": menu_sku_en,
        "qty": qty_diff,
        "note": note,
        "details": details,
    }
    db.collection(STOCK_MOVES_COLLECTION).add(log_doc)

# ----------------------
# 4-2ï¸âƒ£ [NEW] SKU íŒŒë¼ë¯¸í„°
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ----------------------
@st.cache_data(ttl=60)
def load_sku_params() -> pd.DataFrame:
    try:
        docs = db.collection(SKU_PARAMS_COLLECTION).stream()
    except Exception:
        docs = []
    rows = []
    for d in docs:
        item = d.to_dict() or {}
        try:
            item["_id"] = d.id
        except Exception:
            item["_id"] = item.get("_id", "")
        rows.append(item)
    dfp = pd.DataFrame(rows)
    if dfp.empty:
        dfp = pd.DataFrame(columns=[
            "_id","sku_en","lead_time_days","safety_stock_units","target_days","grams_per_cup","expiry_days"
        ])
    defaults = {
        "lead_time_days": 3,
        "safety_stock_units": 10,
        "target_days": 21,
        "grams_per_cup": 18.0,
        "expiry_days": 28,
    }
    for col, default in defaults.items():
        if col not in dfp.columns:
            dfp[col] = default
        else:
            dfp[col] = pd.to_numeric(dfp[col], errors="coerce").fillna(default)
    return dfp

# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í˜¸ì¶œ í—¬í¼
# === [AI/ML í†µí•© ì¶”ê°€] ===
# SPRINT 1: OpenAI API í˜¸ì¶œ í—¬í¼
def call_openai_api(user_prompt: str, data_context: str, model="gpt-3.5-turbo"):
    """
    [AI ìˆ˜ì • 2] data_context(ì‚¬ì‹¤)ì™€ user_prompt(ìš”ì²­)ë¥¼ ë¶„ë¦¬í•˜ì—¬ AIê°€ 'ê±°ì§“ë§'ì„ í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì •.
    data_contextëŠ” 'system' ë©”ì‹œì§€ë¡œ, user_promptëŠ” 'user' ë©”ì‹œì§€ë¡œ ì „ë‹¬.
    """
    
    # 1. API í‚¤ê°€ ì—†ëŠ” ê²½ìš°
    if not openai.api_key:
        time.sleep(1.5) 
        st.error("OpenAI API í‚¤ê°€ 'secrets.toml'ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return (f"âš ï¸ **[AI ì‘ë‹µ ì‹¤íŒ¨ (API í‚¤ ì—†ìŒ)]**\n\n"
                f"'secrets.toml'ì— OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
                f"--- (ë°ì´í„° ì»¨í…ìŠ¤íŠ¸) ---\n{data_context}\n\n"
                f"--- (ì‚¬ìš©ì ìš”ì²­) ---\n{user_prompt}")

    # 2. API í˜¸ì¶œ ì‹œë„
    try:
        # [ìˆ˜ì •] ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëª…í™•íˆ ë¶„ë¦¬
        response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": (
                    "ë‹¹ì‹ ì€ ì¹´í˜ ìš´ì˜ ë° ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                    "ë‹¤ìŒì€ í˜„ì¬ ì¹´í˜ì˜ ì‹¤ì œ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ 'ì‚¬ì‹¤'ë¡œ ê°„ì£¼í•˜ê³ , "
                    "ì´ 'ì‚¬ì‹¤'ì— ê¸°ë°˜í•´ì„œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì ˆëŒ€ ë°ì´í„°ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.\n\n"
                    f"--- [ì¹´í˜ ì‹¤ì œ ë°ì´í„°] ---\n{data_context}\n--- [ë°ì´í„° ë] ---"
                )},
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.choices[0].message.content
        
    # 3. [ìˆ˜ì •] ì”ì•¡ ë¶€ì¡± ë˜ëŠ” API ì˜¤ë¥˜ ë°œìƒ ì‹œ
    except openai.InsufficientQuotaError as e:
        # "ê°€ì§œ ì‘ë‹µ"ì´ ì•„ë‹Œ, ëª…í™•í•œ 'ì˜¤ë¥˜'ì™€ 'ì‹œë„í–ˆë˜ ë‚´ìš©'ì„ ë°˜í™˜
        st.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: ì”ì•¡(Quota)ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì˜¤ë¥˜: {e.message})")
        return (f"âš ï¸ **[AI ì‘ë‹µ ì‹¤íŒ¨ (ì”ì•¡ ë¶€ì¡±)]**\n\n"
                f"OpenAI ê³„ì •ì˜ ì”ì•¡ì´ ë¶€ì¡±í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"--- (AIê°€ ì „ë‹¬ë°›ì€ ë°ì´í„°) ---\n{data_context}\n\n"
                f"--- (AIê°€ ìš”ì²­ë°›ì€ ì‘ì—…) ---\n{user_prompt}")
        
    except openai.AuthenticationError as e:
        st.error("âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: API í‚¤ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. 'secrets.toml'ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# SPRINT 2: Prophet ìˆ˜ìš” ì˜ˆì¸¡ í—¬í¼
# SPRINT 2: Prophet ìˆ˜ìš” ì˜ˆì¸¡ í—¬í¼
@st.cache_data(ttl=3600) # 1ì‹œê°„ ìºì‹œ
def get_item_forecast(df_all_sales: pd.DataFrame, menu_sku_en: str, days_to_forecast: int):
    """Prophetì„ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ë©”ë‰´ì˜ ë¯¸ë˜ íŒë§¤ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    
    try:
        # === [ìˆ˜ì •] ë‚ ì§œ ë°ì´í„° ì•ˆì •í™” ===
        # í•¨ìˆ˜ë¡œ ì „ë‹¬ëœ dfì˜ ë‚ ì§œ ì»¬ëŸ¼ì„ í•œë²ˆ ë” ë³´ì • (NaT ì œê±°)
        df_all_sales = df_all_sales.copy()
        df_all_sales['ë‚ ì§œ'] = pd.to_datetime(df_all_sales['ë‚ ì§œ'], errors='coerce')
        df_all_sales = df_all_sales.dropna(subset=['ë‚ ì§œ'])
        # === [ìˆ˜ì • ë] ===

        # ì›ë³¸ dfëŠ” 'ìƒí’ˆìƒì„¸'ê°€ í•œê¸€ì´ë¯€ë¡œ í•œê¸€ëª… ì‚¬ìš©
        menu_name_kr = to_korean_detail(menu_sku_en)
        
        df_item = df_all_sales[
            df_all_sales['ìƒí’ˆìƒì„¸'] == menu_name_kr
        ].copy()
        
        if df_item.empty:
            return None, None # íŒë§¤ ë°ì´í„° ì—†ìŒ

        # Prophetì´ ë‚ ì§œ ë°ì´í„°ë¥¼ ì‹ ë¢°í•˜ë„ë¡ ì „ì²˜ë¦¬
        df_agg = df_item.groupby('ë‚ ì§œ')['ìˆ˜ëŸ‰'].sum().reset_index()
        df_agg['ë‚ ì§œ'] = pd.to_datetime(df_agg['ë‚ ì§œ'])
        
        if not df_agg.empty:
            date_range = pd.date_range(start=df_agg['ë‚ ì§œ'].min(), end=df_agg['ë‚ ì§œ'].max())
            df_agg = df_agg.set_index('ë‚ ì§œ').reindex(date_range, fill_value=0).reset_index()
            df_agg.rename(columns={'index': 'ë‚ ì§œ'}, inplace=True)
        
        df_prophet = df_agg[['ë‚ ì§œ', 'ìˆ˜ëŸ‰']].rename(columns={"ë‚ ì§œ": "ds", "ìˆ˜ëŸ‰": "y"})

        if len(df_prophet) < 7: # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì˜ˆì¸¡ ë¶ˆê°€
            return None, None

        m = Prophet(weekly_seasonality=True, yearly_seasonality=False, daily_seasonality=False)
        m.fit(df_prophet)
        future = m.make_future_dataframe(periods=days_to_forecast)
        forecast = m.predict(future)
        
        # ìŒìˆ˜ ì˜ˆì¸¡ì€ 0ìœ¼ë¡œ
        forecast['yhat'] = forecast['yhat'].clip(lower=0) 
        predicted_sum = forecast.iloc[-days_to_forecast:]['yhat'].sum()
        
        return max(predicted_sum, 0), forecast

    except Exception as e:
        st.warning(f"Prophet ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None
    
# === [AI/ML í†µí•© ì¶”ê°€] ===


# ----------
# [AI/ML í†µí•© ìˆ˜ì •] 
# ( compute_ingredient_metrics_for_menu )
# SPRINT 2: ML ìˆ˜ìš” ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ê¸°ì¡´ ROP ê³„ì‚° ë¡œì§ì— í†µí•©
# ----------
# ----------
# [AI/ML í†µí•© ìˆ˜ì • 3] 
# ( compute_ingredient_metrics_for_menu )
# SPRINT 2: ML ìˆ˜ìš” ì˜ˆì¸¡ ë¡œì§ ìˆ˜ì •
# - 'target_days'ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë¡œì§ì˜ ë²„ê·¸ë¥¼ ìˆ˜ì •
# - ì˜ˆì¸¡ ê¸°ê°„ì„ 21ì¼ë¡œ ê³ ì •í•˜ì—¬ ë‹¨ìˆœí™”/ì•ˆì •í™”
# ----------
# ----------
# [AI/ML í†µí•© ìˆ˜ì • 5] 
# ( compute_ingredient_metrics_for_menu )
# SPRINT 2: ML ìˆ˜ìš” ì˜ˆì¸¡ ë¡œì§ ìˆ˜ì •
# - [ì˜¤íƒ€ ìˆ˜ì •] 'ì¼í‰Yê· ì†Œì§„' -> 'ì¼í‰ê· ì†Œì§„'
# - [ì˜¤íƒ€ ìˆ˜ì •] 'ì»¤ë²„ì¼S' -> 'ì»¤ë²„ì¼ìˆ˜'
# ----------
def compute_ingredient_metrics_for_menu(
    menu_sku_en: str,
    df_all_sales: pd.DataFrame, # ì „ì²´ íŒë§¤ ë°ì´í„°(df)
    df_inv: pd.DataFrame,
    df_params: pd.DataFrame,
    window_days: int = 28 # [ìˆ˜ì •] ì´ ê°’ì€ ì´ì œ AI ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©ë¨
) -> pd.DataFrame:
    """
    [AI ìˆ˜ì •ë¨] íŠ¹ì • ë©”ë‰´ì˜ ë ˆì‹œí”¼ì™€ *ë¯¸ë˜ ì˜ˆì¸¡ íŒë§¤ëŸ‰* ê¸°ë°˜ìœ¼ë¡œ ì¬ë£Œë³„ ì§€í‘œ ê³„ì‚°.
    ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ ê³¼ê±° ìœˆë„ìš°(window_days) í‰ê· ìœ¼ë¡œ ëŒ€ì²´.
    """
    items = load_recipe(menu_sku_en)
    if not items:
        return pd.DataFrame()

    # === [ë²„ê·¸ ìˆ˜ì •] ì´ë¦„ ë¶ˆì¼ì¹˜ í•´ê²° (Historical) ===
    # 'Americano Rg' -> 'Americano' (ê¸°ë³¸ ì´ë¦„)ìœ¼ë¡œ ë³€ê²½
    # 'ì•„ë©”ë¦¬ì¹´ë…¸ (ë ˆê·¤ëŸ¬)' -> 'ì•„ë©”ë¦¬ì¹´ë…¸' (ê¸°ë³¸ ì´ë¦„)ìœ¼ë¡œ ë³€ê²½
    base_sku_en = re.sub(r"\s+(Lg|Rg|Sm)$", "", menu_sku_en.strip())
    menu_name_kr_base = to_korean_detail(base_sku_en) # 'ì•„ë©”ë¦¬ì¹´ë…¸'
    # === [ë²„ê·¸ ìˆ˜ì • ë] ===

    # === [ìˆ˜ì •] ì˜ˆì¸¡ ê¸°ê°„ì„ 21ì¼ë¡œ ê³ ì •í•˜ì—¬ ë²„ê·¸ í•´ê²° ===
    target_days_forecast = 21
    window_days_fallback = 21 # AI ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„ë„ 21ì¼ë¡œ í†µì¼
    st.info(f"ğŸ¤– AI ìˆ˜ìš” ì˜ˆì¸¡ì„ í–¥í›„ **{target_days_forecast}ì¼** ê¸°ì¤€ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    # === [ìˆ˜ì • ë] ===

    # 1. (Fallbackìš©) ê³¼ê±° ìœˆë„ìš° íŒë§¤ëŸ‰ ì§‘ê³„
    sold_sum_historical = 0.0
    if "ë‚ ì§œ" in df_all_sales.columns and pd.api.types.is_datetime64_any_dtype(df_all_sales["ë‚ ì§œ"]):
        max_day = df_all_sales["ë‚ ì§œ"].max()
        min_day = max_day - pd.Timedelta(days=window_days_fallback - 1)
        df_win = df_all_sales[(df_all_sales["ë‚ ì§œ"] >= min_day) & (df_all_sales["ë‚ ì§œ"] <= max_day)]
        
        # [ìˆ˜ì •] menu_name_kr ëŒ€ì‹  menu_name_kr_base ì‚¬ìš©
        sold_sum_historical = df_win[df_win['ìƒí’ˆìƒì„¸'] == menu_name_kr_base]['ìˆ˜ëŸ‰'].sum()
    
    # 2. [AI/ML] ë¯¸ë˜ ìˆ˜ìš” ì˜ˆì¸¡
    # (ì´ í•¨ìˆ˜ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” menu_sku_en ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬)
    predicted_menu_sales, forecast_chart_data = get_item_forecast(
        df_all_sales, menu_sku_en, days_to_forecast=target_days_forecast
    )

    # 3. ì‚¬ìš©í•  íŒë§¤ëŸ‰(sold_sum) ë° ê¸°ì¤€ì¼(days) ê²°ì •
    use_historical_fallback = False
    
    if predicted_menu_sales is None or predicted_menu_sales == 0:
        st.warning(f"ğŸ¤– AI ì˜ˆì¸¡: '{to_korean_detail(menu_sku_en)}'ì˜ íŒë§¤ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ê³¼ê±° {window_days_fallback}ì¼ íŒë§¤ëŸ‰: {sold_sum_historical}ê°œ)ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        sold_sum = sold_sum_historical # ê³¼ê±° ë°ì´í„° ì‚¬ìš©
        days = window_days_fallback
        use_historical_fallback = True
    else:
        st.success(f"ğŸ¤– **AI ì˜ˆì¸¡**: '{to_korean_detail(menu_sku_en)}'ì˜ í–¥í›„ **{target_days_forecast}ì¼ê°„** ì˜ˆìƒ íŒë§¤ëŸ‰ì„ **{predicted_menu_sales:,.0f}ê°œ**ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.")
        sold_sum = predicted_menu_sales # ì˜ˆì¸¡ê°’ìœ¼ë¡œ ëŒ€ì²´
        days = target_days_forecast # ê¸°ì¤€ì¼ë„ ì˜ˆì¸¡ ê¸°ê°„ìœ¼ë¡œ ë³€ê²½
        
        # (ì˜µì…˜) ì˜ˆì¸¡ ì°¨íŠ¸ í‘œì‹œ
        if forecast_chart_data is not None:
            try:
                fig = px.line(forecast_chart_data.iloc[-90:], x='ds', y='yhat', 
                                title=f"'{to_korean_detail(menu_sku_en)}' ìˆ˜ìš” ì˜ˆì¸¡ (í–¥í›„ {target_days_forecast}ì¼)", 
                                labels={'ds':'ë‚ ì§œ', 'yhat':'ì˜ˆì¸¡ íŒë§¤ëŸ‰'})
                fig.add_scatter(x=forecast_chart_data['ds'], y=forecast_chart_data['yhat_lower'], fill='tozeroy', mode='lines', line=dict(color='rgba(0,0,0,0)'), name='ë¶ˆí™•ì‹¤ì„±')
                fig.add_scatter(x=forecast_chart_data['ds'], y=forecast_chart_data['yhat_upper'], fill='tonexty', mode='lines', line=dict(color='rgba(0,0,0,0)'), fillcolor='rgba(231, 234, 241, 0.5)', name='')
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

    # 4. ë ˆì‹œí”¼ ê¸°ë°˜ ì›ì¬ë£Œ ì†Œì§„ëŸ‰ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ í™œìš©)
    rows = []
    for item in items:
        sku_en = item["ingredient_en"]
        qty_per_unit = safe_float(item.get("qty", 0.0))
        uom = normalize_uom(item.get("uom", "ea"))
        waste_pct = safe_float(item.get("waste_pct", 0.0))
        
        total_used = (qty_per_unit * sold_sum) * (1 + (waste_pct / 100.0))
        
        rows.append({
            "sku_en": sku_en,
            "uom_recipe": uom,
            "total_consumption": total_used # ì˜ˆì¸¡/ê³¼ê±° ê¸°ë°˜ ì´ ì†Œì§„ëŸ‰
        })

    if not rows:
        return pd.DataFrame()
    
    use_df = pd.DataFrame(rows).groupby("sku_en").agg({
        "total_consumption": "sum",
        "uom_recipe": "first" 
    }).reset_index()
    
    base = use_df.rename(columns={"total_consumption": "ìµœê·¼ì†Œì§„í•©"})

    # 5. ì¬ê³  ì§€í‘œ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ í™œìš©)
    base["ì¼í‰ê· ì†Œì§„"] = (base["ìµœê·¼ì†Œì§„í•©"] / max(days, 1)).round(3)
    base.loc[base["ì¼í‰ê· ì†Œì§„"].eq(0), "ì¼í‰ê· ì†Œì§„"] = 0.01

    base = base.merge(df_inv[['ìƒí’ˆìƒì„¸_en', 'í˜„ì¬ì¬ê³ ', 'ì´ˆê¸°ì¬ê³ ', 'uom']], left_on='sku_en', right_on='ìƒí’ˆìƒì„¸_en', how='left')
    base['í˜„ì¬ì¬ê³ '] = base['í˜„ì¬ì¬ê³ '].fillna(0)
    base['ì´ˆê¸°ì¬ê³ '] = base['ì´ˆê¸°ì¬ê³ '].fillna(DEFAULT_INITIAL_STOCK)
    base['uom'] = base['uom'].fillna('ea').apply(normalize_uom)

    base["ì»¤ë²„ì¼ìˆ˜"] = (base["í˜„ì¬ì¬ê³ "] / base["ì¼í‰ê· ì†Œì§„"]).round(1)

    # 6. ROP ë° ê¶Œì¥ ë°œì£¼ëŸ‰ ê³„ì‚°
    base = base.merge(df_params, on="sku_en", how="left")
    
    # íŒŒë¼ë¯¸í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
    base['lead_time_days'] = base['lead_time_days'].fillna(3)
    base['safety_stock_units'] = base['safety_stock_units'].fillna(0)
    base['target_days'] = base['target_days'].fillna(21) # ì¬ë£Œì˜ ëª©í‘œì¼ìˆ˜

    # === [ì˜¤íƒ€ ìˆ˜ì •] 'ì¼í‰Yê· ì†Œì§„' -> 'ì¼í‰ê· ì†Œì§„' ===
    base["ROP"] = (base["ì¼í‰ê· ì†Œì§„"] * base["lead_time_days"] + base["safety_stock_units"]).round(0).astype(int)
    
    # [í•µì‹¬] ê¶Œì¥ ë°œì£¼ëŸ‰: (AIê°€ ì˜ˆì¸¡í•œ ì´ ì†Œì§„ëŸ‰) - (í˜„ì¬ ì¬ê³ )
    base["ê¶Œì¥ë°œì£¼"] = (base["ìµœê·¼ì†Œì§„í•©"] - base["í˜„ì¬ì¬ê³ "]).apply(lambda x: max(int(ceil(x)), 0))
    
    base["ìƒíƒœ"] = base.apply(lambda r: "ğŸš¨ ë°œì£¼ìš”ë§" if r["í˜„ì¬ì¬ê³ "] <= r["ROP"] else "âœ… ì •ìƒ", axis=1)

    base["ìƒí’ˆìƒì„¸"] = base["sku_en"].apply(to_korean_detail)
    cols = ["ìƒí’ˆìƒì„¸","sku_en","í˜„ì¬ì¬ê³ ","ì´ˆê¸°ì¬ê³ ","uom","ìµœê·¼ì†Œì§„í•©","ì¼í‰ê· ì†Œì§„","ì»¤ë²„ì¼ìˆ˜",
            "lead_time_days","safety_stock_units","target_days","ROP","ê¶Œì¥ë°œì£¼","ìƒíƒœ"]
    for c in cols:
        if c not in base.columns:
            base[c] = None
            
    # === [ì˜¤íƒ€ ìˆ˜ì •] 'ì»¤ë²„ì¼S' -> 'ì»¤ë²„ì¼ìˆ˜' ===
    return base[cols].sort_values(["ìƒíƒœ","ì»¤ë²„ì¼ìˆ˜"])
# ---------- [AI/ML í†µí•© ìˆ˜ì • ì¢…ë£Œ] ----------


# ----------------------
# 5ï¸âƒ£ ì‚¬ì´ë“œë°” ë©”ë‰´
# ----------------------
# [AI/ML í†µí•© ìˆ˜ì •] "AI ë¹„ì„œ" ë©”ë‰´ ì¶”ê°€
menu = st.sidebar.radio(
    " ë©”ë‰´ ì„ íƒ",
    ["ê²½ì˜ í˜„í™©", "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ", "ê¸°ê°„ë³„ ë¶„ì„", "ê±°ë˜ ì¶”ê°€", "ì¬ê³  ê´€ë¦¬", "ğŸ¤– AI ë¹„ì„œ", "ë°ì´í„° í¸ì§‘", "ê±°ë˜ ë‚´ì—­", "ë„ì›€ë§"]
)

# ==============================================================
# ğŸ§¾ ê±°ë˜ ì¶”ê°€
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
if menu == "ê±°ë˜ ì¶”ê°€":
    st.header(" ê±°ë˜ ë°ì´í„° ì¶”ê°€")
    category_options = sorted(pd.Series(df['ìƒí’ˆì¹´í…Œê³ ë¦¬']).dropna().unique().tolist())
    type_options = sorted(pd.Series(df['ìƒí’ˆíƒ€ì…']).dropna().unique().tolist())
    detail_options = sorted(pd.Series(df['ìƒí’ˆìƒì„¸']).dropna().unique().tolist())

    with st.form("add_transaction"):
        col1, col2 = st.columns(2)
        with col1:
            ë‚ ì§œ = st.date_input("ë‚ ì§œ", value=datetime.now().date())
            ìƒí’ˆì¹´í…Œê³ ë¦¬_ko = st.selectbox("ìƒí’ˆì¹´í…Œê³ ë¦¬", category_options)
            ìƒí’ˆíƒ€ì…_ko = st.selectbox("ìƒí’ˆíƒ€ì…", type_options)
        with col2:
            ìƒí’ˆìƒì„¸_ko = st.selectbox("ìƒí’ˆìƒì„¸", detail_options)
            ìˆ˜ëŸ‰ = st.number_input("ìˆ˜ëŸ‰", min_value=1, value=1)
            ë‹¨ê°€ = st.number_input("ë‹¨ê°€(ì›)", min_value=0.0, value=1000.0, step=100.0)
        
        ìˆ˜ìµ = ìˆ˜ëŸ‰ * ë‹¨ê°€
        st.markdown(f"### ğŸ’° ê³„ì‚°ëœ ìˆ˜ìµ: **{format_krw(ìˆ˜ìµ)}**")
        
        submitted = st.form_submit_button("ë°ì´í„° ì¶”ê°€")
        
        if submitted:
            ìƒí’ˆì¹´í…Œê³ ë¦¬_en = rev_category_map.get(ìƒí’ˆì¹´í…Œê³ ë¦¬_ko, ìƒí’ˆì¹´í…Œê³ ë¦¬_ko)
            ìƒí’ˆíƒ€ì…_en = rev_type_map.get(ìƒí’ˆíƒ€ì…_ko, ìƒí’ˆíƒ€ì…_ko)
            ìƒí’ˆìƒì„¸_en = from_korean_detail(ìƒí’ˆìƒì„¸_ko)
            
            new_doc = {
                "ë‚ ì§œ": str(ë‚ ì§œ),
                "ì‹œê°„": datetime.now().strftime("%H:%M:%S"),
                "ìƒí’ˆì¹´í…Œê³ ë¦¬": ìƒí’ˆì¹´í…Œê³ ë¦¬_en,
                "ìƒí’ˆíƒ€ì…": ìƒí’ˆíƒ€ì…_en,
                "ìƒí’ˆìƒì„¸": ìƒí’ˆìƒì„¸_en,
                "ìˆ˜ëŸ‰": ìˆ˜ëŸ‰,
                "ë‹¨ê°€": ë‹¨ê°€,
                "ìˆ˜ìµ": ìˆ˜ìµ,
                "ê°€ê²Œìœ„ì¹˜": "Firebase",
            }
            
            try:
                db.collection(SALES_COLLECTION).add(new_doc)
                st.success(f"âœ… '{ìƒí’ˆìƒì„¸_ko}' {ìˆ˜ëŸ‰}ê±´ ì¶”ê°€ ì™„ë£Œ!")
                
                # ì¬ê³  ìë™ ì°¨ê°
                with st.spinner("ì¬ê³  ìë™ ì°¨ê° ì ìš© ì¤‘..."):
                    adjust_inventory_by_recipe(
                        ìƒí’ˆìƒì„¸_en,
                        ìˆ˜ëŸ‰,
                        move_type="sale",
                        note=f"ê±°ë˜ ì¶”ê°€: {ìƒí’ˆìƒì„¸_ko} x{ìˆ˜ëŸ‰}"
                    )
                st.success("âœ… ì¬ê³  ì°¨ê° ì™„ë£Œ!")
                safe_rerun()
                
            except Exception as e:
                st.error(f"ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {e}")

# ==============================================================
# ğŸ“Š ê²½ì˜ í˜„í™©
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê²½ì˜ í˜„í™©":
    st.header("ğŸ“Š ê²½ì˜ í˜„í™©")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        total_revenue = df['ìˆ˜ìµ'].sum()
        total_sales_count = df.shape[0]
        avg_revenue_per_sale = total_revenue / total_sales_count if total_sales_count > 0 else 0
        
        st.markdown(
            f"""
            <div style="display:grid; grid-template-columns:1fr 1fr 1fr; gap:16px; margin-bottom:20px;">
                <div class="metric-card">
                    <div class="metric-title">ì´ ë§¤ì¶œ</div>
                    <div class="metric-value">{format_krw(total_revenue)}</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">ì´ íŒë§¤ ê±´ìˆ˜</div>
                    <div class="metric-value">{total_sales_count:,} ê±´</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">ê±´ë‹¹ í‰ê·  ë§¤ì¶œ</div>
                    <div class="metric-value">{format_krw(avg_revenue_per_sale)}</div>
                </div>
            </div>
            """, unsafe_allow_html=True
        )

        if not df.empty:
            try:
                top_cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
                top_prod = df.groupby('ìƒí’ˆíƒ€ì…')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(1)
                st.info(f"ğŸ† ê°€ì¥ ë§¤ì¶œ ë†’ì€ ì¹´í…Œê³ ë¦¬: **{top_cat.index[0]}** ({format_krw(top_cat.iloc[0])}) / ìƒí’ˆ: **{top_prod.index[0]}**")
            except Exception:
                st.info("ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ìƒìœ„ í•­ëª©ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        col4, col5 = st.columns(2)
        with col4:
            cat = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().reset_index()
            fig_cat = px.pie(cat, values='ìˆ˜ìµ', names='ìƒí’ˆì¹´í…Œê³ ë¦¬', title="ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ë¹„ì¤‘")
            st.plotly_chart(fig_cat, use_container_width=True)
        with col5:
            daily = df.groupby('ë‚ ì§œ')['ìˆ˜ìµ'].sum().reset_index()
            fig_trend = px.line(daily, x='ë‚ ì§œ', y='ìˆ˜ìµ', title="ì¼ìë³„ ë§¤ì¶œ ì¶”ì´")
            st.plotly_chart(fig_trend, use_container_width=True)

# ==============================================================
# ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ":
    st.header("ğŸ’¹ ë§¤ì¶œ ëŒ€ì‹œë³´ë“œ")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        col1, col2 = st.columns(2)
        monthly = df.groupby(df['ë‚ ì§œ'].dt.to_period("M"))['ìˆ˜ìµ'].sum().reset_index()
        monthly['ë‚ ì§œ'] = monthly['ë‚ ì§œ'].dt.to_timestamp()
        
        with col1:
            fig_month = px.bar(monthly, x='ë‚ ì§œ', y='ìˆ˜ìµ', title="ì›”ë³„ ë§¤ì¶œ")
            st.plotly_chart(fig_month, use_container_width=True)
        with col2:
            cat_sales = df.groupby('ìƒí’ˆì¹´í…Œê³ ë¦¬')['ìˆ˜ìµ'].sum().reset_index()
            fig_cat2 = px.bar(cat_sales, x='ìƒí’ˆì¹´í…Œê³ ë¦¬', y='ìˆ˜ìµ', title="ìƒí’ˆ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ")
            st.plotly_chart(fig_cat2, use_container_width=True)

        prod_sales = df.groupby(['ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸'])['ìˆ˜ìµ'].sum().reset_index()
        fig_sun = px.sunburst(prod_sales, path=['ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸'], values='ìˆ˜ìµ', title="ìƒí’ˆ êµ¬ì¡°ë³„ ë§¤ì¶œ")
        st.plotly_chart(fig_sun, use_container_width=True)

# ==============================================================
# ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê¸°ê°„ë³„ ë¶„ì„":
    st.header("ğŸ“ˆ ê¸°ê°„ë³„ ë¶„ì„")
    if df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        min_date = df['ë‚ ì§œ'].min().date()
        max_date = df['ë‚ ì§œ'].max().date()
        
        date_filter = st.slider(
            "ì¡°íšŒ ê¸°ê°„",
            min_value=min_date, max_value=max_date,
            value=(min_date, max_date),
            format="YYYY/MM/DD"
        )
        
        filtered_df = df[
            (df['ë‚ ì§œ'].dt.date >= date_filter[0]) &
            (df['ë‚ ì§œ'].dt.date <= date_filter[1])
        ]
        
        if filtered_df.empty:
            st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            c1, c2 = st.columns(2)
            with c1:
                week_sales = filtered_df.groupby('ìš”ì¼')['ìˆ˜ìµ'].sum().reindex(weekday_order_kr)
                fig_week = px.bar(week_sales, x=week_sales.index, y='ìˆ˜ìµ', title="ìš”ì¼ë³„ ë§¤ì¶œ")
                st.plotly_chart(fig_week, use_container_width=True)
            with c2:
                hour_sales = filtered_df.groupby('ì‹œ')['ìˆ˜ìµ'].sum().reset_index()
                fig_hour = px.bar(hour_sales, x='ì‹œ', y='ìˆ˜ìµ', title="ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ")
                st.plotly_chart(fig_hour, use_container_width=True)

# ==============================================================
# ğŸ“¦ ì¬ê³  ê´€ë¦¬
# (ì›ë³¸ ì½”ë“œ ìƒëµ, [AI/ML í†µí•© ìˆ˜ì •]ì´ ì ìš©ëœ í•¨ìˆ˜ë¥¼ ì‚¬ìš©)
# ==============================================================
elif menu == "ì¬ê³  ê´€ë¦¬":
    st.header("ğŸ“¦ ì¬ê³  ê´€ë¦¬ (AI ì˜ˆì¸¡ ê¸°ë°˜)")
    
    df_inv = load_inventory_df()
    df_params = load_sku_params()
    
    # === [ìˆ˜ì •] íƒ­ ì´ë¦„ ë³€ê²½ ===
    tab1, tab2 = st.tabs(["ğŸ›ï¸ ë©”ë‰´ë³„ ì¬ê³  í˜„í™©", "ğŸ”— ë ˆì‹œí”¼ & ì¬ë£Œ ê´€ë¦¬ í—ˆë¸Œ"])

    # ==============================================================
    # TAB 1: ë©”ë‰´ë³„ ì¬ê³  í˜„í™© (AI ì˜ˆì¸¡) - (ë³€ê²½ ì—†ìŒ)
    # ==============================================================
    with tab1:
        st.subheader("ğŸ›ï¸ ë©”ë‰´ë³„ ì¬ê³  í˜„í™© (AI ì˜ˆì¸¡ ê¸°ë°˜)")
        
        # ë ˆì‹œí”¼ê°€ ë“±ë¡ëœ ë©”ë‰´ë§Œ ì„ íƒì§€ë¡œ
        try:
            recipe_docs = db.collection(RECIPES_COLLECTION).stream()
            menu_list_en = [doc.id for doc in recipe_docs if doc.id]
        except Exception:
            menu_list_en = []

        if not menu_list_en:
            st.warning("ë¨¼ì € 'ë ˆì‹œí”¼ & ì¬ë£Œ ê´€ë¦¬ í—ˆë¸Œ' íƒ­ì—ì„œ ë©”ë‰´ì˜ ë ˆì‹œí”¼ë¥¼ 1ê°œ ì´ìƒ ë“±ë¡í•´ì•¼ í•©ë‹ˆë‹¤.")
            st.stop()

        menu_list_kr = sorted([to_korean_detail(sku) for sku in menu_list_en])
        
        selected_menu_kr = st.selectbox("ë¶„ì„í•  ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", menu_list_kr, index=0)
        selected_menu_en = from_korean_detail(selected_menu_kr)
        
        st.markdown("---")
        
        try:
            report_df = compute_ingredient_metrics_for_menu(
                selected_menu_en,
                df, # ì „ì²´ 'df' ì „ë‹¬
                df_inv,
                df_params
            )
            
            if report_df.empty:
                st.info(f"'{selected_menu_kr}'ì— ëŒ€í•œ ë ˆì‹œí”¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                display_cols = [
                    'ìƒí’ˆìƒì„¸', 'ìƒíƒœ', 'í˜„ì¬ì¬ê³ ', 'uom', 'ê¶Œì¥ë°œì£¼', 'ì»¤ë²„ì¼ìˆ˜', 'ì¼í‰ê· ì†Œì§„', 'ROP',
                ]
                
                # ë‹¨ìœ„ í¬ë§·íŒ…
                formatted_df = report_df[display_cols].copy()
                formatted_df['í˜„ì¬ì¬ê³ '] = formatted_df.apply(lambda r: f"{r['í˜„ì¬ì¬ê³ ']:,.1f} {r['uom']}", axis=1)
                formatted_df['ê¶Œì¥ë°œì£¼'] = formatted_df.apply(lambda r: f"{r['ê¶Œì¥ë°œì£¼']:,.1f} {r['uom']}", axis=1)
                formatted_df['ì¼í‰ê· ì†Œì§„'] = formatted_df.apply(lambda r: f"{r['ì¼í‰ê· ì†Œì§„']:,.1f} {r['uom']}", axis=1)
                formatted_df['ROP'] = formatted_df.apply(lambda r: f"{r['ROP']:,.1f} {r['uom']}", axis=1)
                formatted_df['ì»¤ë²„ì¼ìˆ˜'] = formatted_df['ì»¤ë²„ì¼ìˆ˜'].apply(lambda x: f"{x}ì¼")
                
                st.dataframe(
                    formatted_df[['ìƒí’ˆìƒì„¸', 'ìƒíƒœ', 'í˜„ì¬ì¬ê³ ', 'ê¶Œì¥ë°œì£¼', 'ì»¤ë²„ì¼ìˆ˜', 'ì¼í‰ê· ì†Œì§„', 'ROP']],
                    use_container_width=True
                )
        except Exception as e:
            st.error(f"ì¬ê³  ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            import traceback
            st.exception(traceback.format_exc())

    # ==============================================================
    # === [ìˆ˜ì •] "ë²”ìš© ë ˆì‹œí”¼ & ì¬ë£Œ ê´€ë¦¬ í—ˆë¸Œ"ë¡œ ì™„ì „ êµì²´ ===
    # ==============================================================
    with tab2:
        st.subheader("âœ¨ ë²”ìš© ë ˆì‹œí”¼ & ì¬ë£Œ ê´€ë¦¬ í—ˆë¸Œ")
        st.caption("ì—¬ê¸°ì„œ (1) ì¬ë£Œë¡œ ì“¸ í’ˆëª©ì„ ì§€ì •í•˜ê³ , (2) í•´ë‹¹ ì¬ë£Œë¡œ ë ˆì‹œí”¼ë¥¼ ë§Œë“­ë‹ˆë‹¤.")

        # === [ì‹ ê·œ] ì„œë¸Œ íƒ­ìœ¼ë¡œ ì‘ì—… íë¦„ ë¶„ë¦¬ ===
        sub_tab1, sub_tab2 = st.tabs(["ğŸ“¦ 1. ì¬ë£Œ ëª©ë¡ ê´€ë¦¬", "ğŸ“œ 2. ë ˆì‹œí”¼ í¸ì§‘ê¸°"])

        # --- 1. ì¬ë£Œ ëª©ë¡ ê´€ë¦¬ (ì‹ ê·œ ê¸°ëŠ¥) ---
        with sub_tab1:
            st.info("ë ˆì‹œí”¼ì— ì‚¬ìš©í•  **'ì¬ë£Œ'** í’ˆëª©ì„ ì—¬ê¸°ì„œ ì²´í¬(True)í•˜ì„¸ìš”.")
            st.caption("('ì›ë‘ A', 'ìš°ìœ  (1L)' ë“±ì€ ì²´í¬O, 'ì•„ë©”ë¦¬ì¹´ë…¸ ì™„ì œí’ˆ' ë“±ì€ ì²´í¬X)")

            df_inv_edit = df_inv.copy()
            df_inv_edit = df_inv_edit.sort_values('ìƒí’ˆìƒì„¸')
            
            # ì¬ë£Œ ëª©ë¡ í¸ì§‘ê¸°
            edited_inv_df = st.data_editor(
                df_inv_edit[['ìƒí’ˆìƒì„¸_en', 'ìƒí’ˆìƒì„¸', 'is_ingredient', 'uom']],
                column_config={
                    "ìƒí’ˆìƒì„¸_en": st.column_config.TextColumn("SKU (Eng)", disabled=True),
                    "ìƒí’ˆìƒì„¸": st.column_config.TextColumn("í’ˆëª©ëª…", disabled=True),
                    "is_ingredient": st.column_config.CheckboxColumn("ì¬ë£Œ ì—¬ë¶€ (ì²´í¬)"),
                    "uom": st.column_config.TextColumn("ê¸°ë³¸ ë‹¨ìœ„", disabled=True),
                },
                hide_index=True,
                use_container_width=True
            )

            if st.button("ğŸ’¾ 'ì¬ë£Œ ì—¬ë¶€' ì„¤ì • ì €ì¥í•˜ê¸°", type="primary"):
                changed = 0
                batch = db.batch()
                
                # ì›ë³¸ê³¼ ë¹„êµ
                original_map = {row['ìƒí’ˆìƒì„¸_en']: row['is_ingredient'] for _, row in df_inv.iterrows()}

                for _, item in edited_inv_df.iterrows():
                    sku_en = item['ìƒí’ˆìƒì„¸_en']
                    is_ingr_new = bool(item['is_ingredient'])
                    
                    if sku_en in original_map and original_map[sku_en] != is_ingr_new:
                        doc_ref = db.collection(INVENTORY_COLLECTION).document(sku_en)
                        batch.update(doc_ref, {'is_ingredient': is_ingr_new})
                        changed += 1
                
                if changed > 0:
                    batch.commit()
                    st.success(f"âœ… {changed}ê±´ì˜ ì¬ë£Œ ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.balloons()
                    safe_rerun()
                else:
                    st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

        # --- 2. ë ˆì‹œí”¼ í¸ì§‘ê¸° (ê¸°ì¡´ ê¸°ëŠ¥ + ì—…ê·¸ë ˆì´ë“œ) ---
        with sub_tab2:
            st.info("ìœ„ '1. ì¬ë£Œ ëª©ë¡ ê´€ë¦¬'ì—ì„œ ì²´í¬í•œ ì¬ë£Œë“¤ë¡œ ë ˆì‹œí”¼ë¥¼ ë§Œë“­ë‹ˆë‹¤.")
            
            # --- 2-1. ì¬ë£Œ ëª©ë¡ ì¤€ë¹„ (1ë²ˆ íƒ­ì˜ ê²°ê³¼ë¬¼) ---
            try:
                # [ìˆ˜ì •] 'is_ingredient'ê°€ Trueì¸ í’ˆëª©ë§Œ ì¬ë£Œë¡œ ê°„ì£¼ (df_inv ì›ë³¸ ì‚¬ìš©)
                df_ingredients = df_inv[df_inv['is_ingredient'] == True].copy()
                
                if df_ingredients.empty:
                    st.error("ì˜¤ë¥˜: '1. ì¬ë£Œ ëª©ë¡ ê´€ë¦¬' íƒ­ì—ì„œ ì¬ë£Œë¥¼ 1ê°œ ì´ìƒ ì²´í¬í•´ì•¼ í•©ë‹ˆë‹¤.")
                    st.stop()
                
                # ì¬ë£Œ ëª©ë¡ (í•œê¸€)
                ingredient_options_kr = sorted(df_ingredients['ìƒí’ˆìƒì„¸'].unique().tolist())
                
                # í•œê¸€ <-> ì˜ë¬¸ ë³€í™˜ ë§µ
                ing_kr_to_en_map = dict(zip(df_ingredients['ìƒí’ˆìƒì„¸'], df_ingredients['ìƒí’ˆìƒì„¸_en']))
                ing_en_to_kr_map = dict(zip(df_ingredients['ìƒí’ˆìƒì„¸_en'], df_ingredients['ìƒí’ˆìƒì„¸']))

            except Exception as e:
                st.error(f"ì¬ë£Œ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
                st.stop()

            # --- 2-2. ë©”ë‰´ ì„ íƒ (ì‚¬ì¥ë‹˜ì´ íŒë§¤í•˜ëŠ” ëª¨ë“  ë©”ë‰´) ---
            all_menus_kr = sorted(df['ìƒí’ˆìƒì„¸'].unique().tolist())
            selected_menu_kr = st.selectbox(
                "ë ˆì‹œí”¼ë¥¼ ë“±ë¡/ìˆ˜ì •í•  ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                all_menus_kr
            )
            selected_menu_en = from_korean_detail(selected_menu_kr)
            
            st.caption(f"(Firebase ë¬¸ì„œ ID: `{selected_menu_en}`)")
            st.markdown("---")

            # --- 2-3. í˜„ì¬ ë ˆì‹œí”¼ ë¶ˆëŸ¬ì˜¤ê¸° & í¸ì§‘ê¸° UI ---
            current_recipe_items = load_recipe(selected_menu_en)
            recipe_df_rows = []
            if current_recipe_items:
                for item in current_recipe_items:
                    sku_en = item.get("ingredient_en")
                    recipe_df_rows.append({
                        "ì¬ë£Œ": ing_en_to_kr_map.get(sku_en, f"ì˜¤ë¥˜: {sku_en}?"), # ì˜ë¬¸ -> í•œê¸€
                        "ìˆ˜ëŸ‰": safe_float(item.get("qty", 0.0)),
                        "ë‹¨ìœ„": normalize_uom(item.get("uom", "g")),
                        "ì†ì‹¤ë¥ (%)": safe_float(item.get("waste_pct", 0.0)),
                    })
            
            if not recipe_df_rows:
                recipe_df_rows = [{"ì¬ë£Œ": None, "ìˆ˜ëŸ‰": 0.0, "ë‹¨ìœ„": "g", "ì†ì‹¤ë¥ (%)": 0.0}]

            df_recipe_editor = pd.DataFrame(recipe_df_rows)

            st.subheader(f"ğŸ“ `{selected_menu_kr}` ë ˆì‹œí”¼ í¸ì§‘")
            
            edited_df = st.data_editor(
                df_recipe_editor,
                column_config={
                    "ì¬ë£Œ": st.column_config.SelectboxColumn(
                        "ì¬ë£Œ (í•„ìˆ˜)",
                        options=ingredient_options_kr, # [ì—°ë™] 1ë²ˆ íƒ­ì˜ ê²°ê³¼
                        required=True,
                    ),
                    "ìˆ˜ëŸ‰": st.column_config.NumberColumn(
                        "ìˆ˜ëŸ‰", min_value=0.0, format="%.2f", required=True,
                    ),
                    "ë‹¨ìœ„": st.column_config.SelectboxColumn(
                        "ë‹¨ìœ„", options=["g", "ml", "ea"], required=True,
                    ),
                    "ì†ì‹¤ë¥ (%)": st.column_config.NumberColumn(
                        "ì†ì‹¤ë¥ (%)", min_value=0.0, max_value=100.0, format="%.1f %%", required=True,
                    ),
                },
                num_rows="dynamic", # í–‰ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥
                use_container_width=True
            )

            # --- 2-4. ì €ì¥ ë¡œì§ ---
            if st.button(f"ğŸ’¾ `{selected_menu_kr}` ë ˆì‹œí”¼ ì €ì¥í•˜ê¸°", type="primary"):
                final_ingredients = []
                valid = True
                
                for index, row in edited_df.iterrows():
                    ì¬ë£Œ_kr = row["ì¬ë£Œ"]
                    if not ì¬ë£Œ_kr:
                        continue # ë¹ˆ í–‰ì€ ë¬´ì‹œ

                    ì¬ë£Œ_en = ing_kr_to_en_map.get(ì¬ë£Œ_kr)
                    
                    if not ì¬ë£Œ_en:
                        st.error(f"'{ì¬ë£Œ_kr}'ëŠ” ìœ íš¨í•œ ì¬ë£Œê°€ ì•„ë‹™ë‹ˆë‹¤. '1. ì¬ë£Œ ëª©ë¡ ê´€ë¦¬' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
                        valid = False
                        break
                    
                    final_ingredients.append({
                        "ingredient_en": ì¬ë£Œ_en,
                        "qty": safe_float(row["ìˆ˜ëŸ‰"]),
                        "uom": normalize_uom(row["ë‹¨ìœ„"]),
                        "waste_pct": safe_float(row["ì†ì‹¤ë¥ (%)"]),
                    })

                if valid and not final_ingredients:
                    st.warning("ì €ì¥í•  ì¬ë£Œê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  í–‰ì´ ë¹„ì–´ìˆìŒ)")
                    # (ì„ íƒ) ë ˆì‹œí”¼ë¥¼ ë¹„ìš°ê³  ì‹¶ë‹¤ë©´ ì‚­ì œ
                    # db.collection(RECIPES_COLLECTION).document(selected_menu_en).delete()
                    # st.success(f"'{selected_menu_kr}' ë ˆì‹œí”¼ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                elif valid and final_ingredients:
                    try:
                        db.collection(RECIPES_COLLECTION).document(selected_menu_en).set({
                            "ingredients": final_ingredients
                        })
                        st.success(f"âœ… `{selected_menu_kr}` ë ˆì‹œí”¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.balloons()
                        safe_rerun()
                    except Exception as e:
                        st.error(f"Firebase ì €ì¥ ì‹¤íŒ¨: {e}")

# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [AI/ML í†µí•© ì¶”ê°€] ===
# =============================================================
# =============================================================
# ğŸ¤– AI ë¹„ì„œ (SPRINT 1)
# === [AI/ML í†µí•© ìˆ˜ì • 2] ===
# AIê°€ 'ê±°ì§“ë§'ì„ í•˜ì§€ ì•Šë„ë¡ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ì™€ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ë¦¬
# =============================================================
elif menu == "ğŸ¤– AI ë¹„ì„œ":
    st.header("ğŸ¤– AI ë§ˆì¼€íŒ…/ìš´ì˜ ë¹„ì„œ")
    st.markdown("í˜„ì¬ íŒë§¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ë§ˆì¼€íŒ… ë¬¸êµ¬ë‚˜ ìš´ì˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    if df.empty:
        st.info("ì•„ì§ íŒë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ìŒ“ì´ë©´ AI ë¹„ì„œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        try:
            # 1. [ìˆ˜ì •] ë°ì´í„° ì»¨í…ìŠ¤íŠ¸(ì‚¬ì‹¤)ë¥¼ ëª…í™•í•˜ê²Œ ìˆ˜ì§‘
            total_revenue = df['ìˆ˜ìµ'].sum()
            total_sales_count = len(df)
            
            top_prod_series = df.groupby('ìƒí’ˆìƒì„¸')['ìˆ˜ìµ'].sum().sort_values(ascending=False).head(3)
            top_prod_list = [f"{idx} ({format_krw(val)})" for idx, val in top_prod_series.items()]
            top_prod_str = ", ".join(top_prod_list)
            
            # AIì—ê²Œ ì „ë‹¬í•  'ì‚¬ì‹¤' ë°ì´í„° ë¬¶ìŒ
            data_context_string = f"""
            - ì´ ë§¤ì¶œ: {format_krw(total_revenue)}
            - ì´ íŒë§¤ ê±´ìˆ˜: {total_sales_count}ê±´
            - ë§¤ì¶œ ê¸°ì¤€ ë² ìŠ¤íŠ¸ì…€ëŸ¬ Top 3: {top_prod_str}
            """
            
            st.info(f"AIì—ê²Œ ì „ë‹¬ë  ì‹¤ì œ ë°ì´í„°: {data_context_string.strip()}")

            # 2. [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ ì„ íƒì§€ (ì‚¬ìš©ìì˜ 'ìš”ì²­' ë¶€ë¶„ë§Œ ë‚¨ê¹€)
            prompt_options = {
                "ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ (í™œê¸°ì°¬ í†¤)": "í˜„ì¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë©”ë‰´ë¥¼ ê°•ì¡°í•˜ëŠ” ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ê²Œì‹œë¬¼ì„ 'ë§¤ìš°' ì¹œê·¼í•˜ê³  í™œê¸°ì°¬ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì¤˜. ì´ëª¨ì§€ë„ íŒíŒ ë„£ì–´ì£¼ê³  í•´ì‹œíƒœê·¸ë„ 5ê°œ ì´ìƒ ë‹¬ì•„ì¤˜.",
                "ë‹¨ê³¨ì†ë‹˜ ê°ì‚¬ ë¬¸ì (ì •ì¤‘í•œ í†¤)": "í˜„ì¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë‹¨ê³¨ì†ë‹˜ì—ê²Œ ê°ì‚¬ë¥¼ í‘œí•˜ëŠ” SMS ë¬¸ì ë©”ì‹œì§€ë¥¼ ì •ì¤‘í•˜ì§€ë§Œ ë”°ëœ»í•˜ê²Œ ì‘ì„±í•´ì¤˜.",
                "ì¼ì¼ ìš´ì˜ ë³´ê³  (ë§¤ë‹ˆì €ìš©)": "í˜„ì¬ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ë‹ˆì €ì—ê²Œ ë³´ê³ í•  ê°„ê²°í•œ ì¼ì¼ ìš´ì˜ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜. (ìˆ«ì ìš”ì•½ í¬í•¨)"
            }
            
            selected_prompt_key = st.selectbox("AIì—ê²Œ ìš”ì²­í•  ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”:", list(prompt_options.keys()))
            
            custom_prompt_area = st.text_area("ë˜ëŠ”, AIì—ê²Œ ì§ì ‘ ìš”ì²­í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:", 
                                              placeholder="ì˜ˆ: í˜„ì¬ ë² ìŠ¤íŠ¸ì…€ëŸ¬ 3ê°€ì§€ë¥¼ í™œìš©í•œ ì‹ ê·œ ì„¸íŠ¸ ë©”ë‰´ ì•„ì´ë””ì–´ 3ê°€ì§€ ì œì•ˆí•´ì¤˜")
            
            if st.button("AI ìƒì„±í•˜ê¸° ğŸš€", type="primary"):
                
                # 3. [ìˆ˜ì •] ì‚¬ìš©ì ìš”ì²­(user_prompt)ì„ í™•ì •
                user_request_prompt = ""
                if custom_prompt_area:
                    st.info("ì§ì ‘ ì…ë ¥í•œ í”„ë¡¬í”„íŠ¸ë¡œ ìš”ì²­í•©ë‹ˆë‹¤...")
                    user_request_prompt = custom_prompt_area
                else:
                    user_request_prompt = prompt_options[selected_prompt_key]

                with st.spinner("AIê°€ ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒê° ì¤‘ì…ë‹ˆë‹¤... ğŸ§ "):
                    
                    # 4. [ìˆ˜ì •] 'ë°ì´í„° ì»¨í…ìŠ¤íŠ¸'ì™€ 'ì‚¬ìš©ì ìš”ì²­'ì„ ë¶„ë¦¬í•˜ì—¬ í˜¸ì¶œ
                    result_text = call_openai_api(
                        user_prompt=user_request_prompt,
                        data_context=data_context_string
                    )
                    
                    if result_text:
                        st.success("AI ìƒì„± ì™„ë£Œ!")
                        st.text_area("ê²°ê³¼ë¬¼:", result_text, height=300)
                    else:
                        st.error("AI ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
# ==============================================================
# âœï¸ ë°ì´í„° í¸ì§‘
# === [ë¹ˆí‹ˆ ìˆ˜ì •] 'ê°€ê²Œìœ„ì¹˜' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°(ì•± ì¶”ê°€ 0ê±´)ì—ë„ ì˜¤ë¥˜ ì—†ë„ë¡ ìˆ˜ì • ===
# ==============================================================
elif menu == "ë°ì´í„° í¸ì§‘":
    st.header("âœï¸ ë°ì´í„° í¸ì§‘")
    tab1, tab2 = st.tabs(["ê±°ë˜ ìˆ˜ì •/ì‚­ì œ", "ì¬ê³  ì¼ê´„ìˆ˜ì •"])

    # ------------------ ê±°ë˜ ìˆ˜ì •/ì‚­ì œ ------------------
    with tab1:
        df_raw, df_view = load_sales_with_id()
        if df_view.empty:
            st.info("ìˆ˜ì •í•  Firebase ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (CSVëŠ” ì½ê¸° ì „ìš©)")
        else:
            st.caption("ğŸ’¡ Firebaseì— ì €ì¥ëœ ê±°ë˜ ë‚´ì—­ë§Œ ìˆ˜ì •/ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê°€ê²Œìœ„ì¹˜=Firebase)")
            
            # === [ë¹ˆí‹ˆ ìˆ˜ì •] ===
            # 'ê°€ê²Œìœ„ì¹˜' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°(ì•±ìœ¼ë¡œ ì¶”ê°€ëœ ë°ì´í„°ê°€ 0ê±´)ì— ëŒ€í•œ ë°©ì–´ ì½”ë“œ
            if 'ê°€ê²Œìœ„ì¹˜' in df_view.columns:
                df_view_fb = df_view[df_view['ê°€ê²Œìœ„ì¹˜'] == 'Firebase'].copy()
            else:
                # 'ê°€ê²Œìœ„ì¹˜' ì»¬ëŸ¼ ìì²´ê°€ ì—†ìœ¼ë©´, ì•±ìœ¼ë¡œ ì¶”ê°€ëœ ë°ì´í„°ê°€ 0ê±´ì´ë¼ëŠ” ëœ».
                # ë¹ˆ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€.
                df_view_fb = pd.DataFrame(columns=df_view.columns) 
            # === [ìˆ˜ì • ì™„ë£Œ] ===
            
            if df_view_fb.empty:
                st.info("ì•„ì§ ì•±ì„ í†µí•´ ì¶”ê°€ëœ(ìˆ˜ì • ê°€ëŠ¥í•œ) ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                edited_df = st.data_editor(
                    df_view_fb[['_id','ë‚ ì§œ','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ']],
                    column_config={
                        "_id": st.column_config.TextColumn("ë¬¸ì„œID", disabled=True),
                        "ë‚ ì§œ": st.column_config.DateColumn("ë‚ ì§œ", format="YYYY-MM-DD"),
                    },
                    hide_index=True,
                    num_rows="dynamic"
                )
                
                reflect_inv = st.checkbox("ì €ì¥ ì‹œ ì¬ê³ ì— ë°˜ì˜(ì°¨ê°/ë³µì›)", value=True)
                
                if st.button("ë³€ê²½ëœ ë‚´ìš© ì €ì¥í•˜ê¸° ğŸ’¾"):
                    changed = 0
                    for i, new in edited_df.iterrows():
                        doc_id = new['_id']
                        orig = df_raw[df_raw['_id'] == doc_id].iloc[0]
                        patch = {}
                        
                        try:
                            new_date_str = str(pd.to_datetime(new['ë‚ ì§œ']).date())
                        except Exception:
                            new_date_str = str(orig.get('ë‚ ì§œ'))

                        if new_date_str != str(orig.get('ë‚ ì§œ')):
                            patch['ë‚ ì§œ'] = new_date_str
                        
                        detail_en = from_korean_detail(new['ìƒí’ˆìƒì„¸'])
                        if detail_en != orig.get('ìƒí’ˆìƒì„¸'):
                            patch['ìƒí’ˆìƒì„¸'] = detail_en
                        
                        qty_new = int(new['ìˆ˜ëŸ‰'])
                        if qty_new != int(orig.get('ìˆ˜ëŸ‰', 0)):
                            patch['ìˆ˜ëŸ‰'] = qty_new
                        
                        unit_new = float(new['ë‹¨ê°€'])
                        rev_new = float(new['ìˆ˜ìµ'])
                        
                        if unit_new != float(orig.get('ë‹¨ê°€', 0)):
                            patch['ë‹¨ê°€'] = unit_new
                        if rev_new != float(orig.get('ìˆ˜ìµ', 0)):
                            patch['ìˆ˜ìµ'] = rev_new
                        
                        if patch:
                            if reflect_inv and 'ìˆ˜ëŸ‰' in patch:
                                diff = qty_new - int(orig.get('ìˆ˜ëŸ‰', 0))
                                adjust_inventory_by_recipe(detail_en, diff, move_type="edit_adjust", note=str(doc_id))
                            
                            db.collection(SALES_COLLECTION).document(doc_id).update(patch)
                            changed += 1
                    
                    if changed:
                        st.success(f"âœ… {changed}ê±´ ì €ì¥ ì™„ë£Œ")
                        safe_rerun()
                    else:
                        st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            st.markdown("---")
            
            # [ìˆ˜ì •] df_view_fbì—ì„œ ID ëª©ë¡ì„ ê°€ì ¸ì˜¤ë„ë¡ ë³€ê²½
            del_options = df_view_fb['_id'].tolist() if not df_view_fb.empty else []

            del_ids = st.multiselect(
                "ğŸ—‘ï¸ ì‚­ì œí•  ê±°ë˜ ì„ íƒ (ë¬¸ì„œID ê¸°ì¤€)",
                options=del_options
            )
            colx, _ = st.columns([1,3])
            with colx:
                restore_inv_on_delete = st.checkbox("ì‚­ì œ ì‹œ ì¬ê³  ë³µì›", value=True)
            
            if st.button("ì‚­ì œ ì‹¤í–‰", type="primary", disabled=(len(del_ids) == 0)):
                for did in del_ids:
                    if restore_inv_on_delete:
                        try:
                            raw = df_raw[df_raw['_id'] == did].iloc[0]
                            qty_to_restore = -int(raw.get('ìˆ˜ëŸ‰', 0)) # ìˆ˜ëŸ‰ì„ ìŒìˆ˜ë¡œ
                            detail_en = raw.get('ìƒí’ˆìƒì„¸')
                            if qty_to_restore != 0 and detail_en:
                                adjust_inventory_by_recipe(detail_en, qty_to_restore, move_type="delete_restore", note=str(did))
                        except Exception as e:
                            st.warning(f"{did} ì¬ê³  ë³µì› ì‹¤íŒ¨: {e}")
                    
                    db.collection(SALES_COLLECTION).document(did).delete()
                
                st.success(f"âœ… {len(del_ids)}ê±´ ì‚­ì œ ì™„ë£Œ")
                safe_rerun()

    # ------------------ ì¬ê³  ì¼ê´„ìˆ˜ì • ------------------
    with tab2:
        st.subheader("âœï¸ ì¬ê³  ìˆ˜ê¸° ê´€ë¦¬ (ì‹¤ì‚¬ ë°˜ì˜)")
        st.info("ì‹¤ì œ ì¬ê³ ë¥¼ í™•ì¸í•œ í›„, ìˆ˜ëŸ‰ì„ ì§ì ‘ ìˆ˜ì •í•˜ê³  ì €ì¥í•˜ì„¸ìš”.")
        
        df_inv = load_inventory_df()
        
        if df_inv.empty:
            st.warning("ì¬ê³  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            edited_inv = st.data_editor(
                df_inv,
                column_config={
                    "ìƒí’ˆìƒì„¸_en": st.column_config.TextColumn("SKU (Eng)", disabled=True),
                    "ìƒí’ˆìƒì„¸": st.column_config.TextColumn("í’ˆëª©ëª…", disabled=True),
                    "ì´ˆê¸°ì¬ê³ ": st.column_config.NumberColumn("ì´ˆê¸° ì¬ê³ ", disabled=True),
                    "í˜„ì¬ì¬ê³ ": st.column_config.NumberColumn("í˜„ì¬ ì¬ê³ ", min_value=0.0, format="%.2f"),
                    "uom": st.column_config.TextColumn("ë‹¨ìœ„", disabled=True),
                    "is_ingredient": st.column_config.CheckboxColumn("ì¬ë£Œ ì—¬ë¶€", disabled=True),
                },
                hide_index=True,
                use_container_width=True
            )
            
            if st.button("ì‹¤ì‚¬ ì¬ê³  ì €ì¥í•˜ê¸° ğŸ’¾", type="primary"):
                changed = 0
                original_map = {row['ìƒí’ˆìƒì„¸_en']: row['í˜„ì¬ì¬ê³ '] for _, row in df_inv.iterrows()}
                
                batch = db.batch()
                
                for item in edited_inv:
                    sku = item['ìƒí’ˆìƒì„¸_en']
                    new_stock = safe_float(item['í˜„ì¬ì¬ê³ '])
                    
                    if sku in original_map and original_map[sku] != new_stock:
                        doc_ref = db.collection(INVENTORY_COLLECTION).document(sku)
                        batch.update(doc_ref, {'í˜„ì¬ì¬ê³ ': new_stock})
                        changed += 1
                        
                if changed > 0:
                    batch.commit()
                    st.success(f"âœ… ì¬ê³  {changed}ê±´ ì €ì¥ ì™„ë£Œ")
                    safe_rerun()
                else:
                    st.info("ë³€ê²½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

# ==============================================================
# ğŸ“‹ ê±°ë˜ ë‚´ì—­
# (ì›ë³¸ ì½”ë“œ ìƒëµ)
# ==============================================================
elif menu == "ê±°ë˜ ë‚´ì—­":
    st.header("ğŸ“‹ ì „ì²´ ê±°ë˜ ë‚´ì—­")
    if df.empty:
        st.info("í‘œì‹œí•  ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        cols = ['ë‚ ì§œ','ìƒí’ˆì¹´í…Œê³ ë¦¬','ìƒí’ˆíƒ€ì…','ìƒí’ˆìƒì„¸','ìˆ˜ëŸ‰','ë‹¨ê°€','ìˆ˜ìµ','ìš”ì¼','ì‹œ']
        cols = [c for c in cols if c in df.columns]
        st.caption(f"í˜„ì¬ ë°ì´í„° í¬ê¸°: {len(df)}í–‰")
        
        # [ìˆ˜ì •] ì›ë³¸ì˜ st.dataframe(df.head(1000)) ì¤‘ë³µ ì œê±°
        st.dataframe(df[cols].sort_values('ë‚ ì§œ', ascending=False), width=None, use_container_width=True)


# ==============================================================
# â“ ë„ì›€ë§
# ==============================================================
else:  # menu == "ë„ì›€ë§"
    st.header("â˜•ï¸ ì»¤í”¼ ì›ë‘ ì¬ê³ ê´€ë¦¬ íŒŒì´í”„ë¼ì¸ ì‰½ê²Œ ì´í•´í•˜ê¸°")
    
    # [AI/ML í†µí•© ìˆ˜ì •] ë„ì›€ë§ ë‚´ìš© ì—…ë°ì´íŠ¸
    st.markdown("""
> **â€œì»¤í”¼ ì›ë‘ê°€ ì–´ë–»ê²Œ ë“¤ì–´ì˜¤ê³ , ì–¼ë§ˆë‚˜ ì“°ì´ê³ , ì–¸ì œ ë‹¤ì‹œ ì£¼ë¬¸ë¼ì•¼ í•˜ëŠ”ì§€ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ì!â€** ì—‘ì…€ ëŒ€ì‹  ERPê°€ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì¤ë‹ˆë‹¤.

### 1. (AI) ìŠ¤ë§ˆíŠ¸ ë°œì£¼ ë¡œì§ (ì¬ê³  ê´€ë¦¬ íƒ­)
| ë‹¨ê³„ | í•˜ëŠ” ì¼ | ì˜ˆì‹œ |
| --- | --- | --- |
| **1. (AI) ìˆ˜ìš” ì˜ˆì¸¡** | Prophet (ML)ì´ "ì•„ë©”ë¦¬ì¹´ë…¸"ì˜ **ë¯¸ë˜ 21ì¼** íŒë§¤ëŸ‰ì„ **[500ì”]**ìœ¼ë¡œ ì˜ˆì¸¡ |
| **2. ì†Œì§„ëŸ‰ ê³„ì‚°** | [500ì”] x [ë ˆì‹œí”¼: ì”ë‹¹ 20g] = **[10,000g]** (ì˜ˆìƒ ì´ ì†Œì§„ëŸ‰) |
| **3. ê¶Œì¥ ë°œì£¼ëŸ‰** | [10,000g] - [í˜„ì¬ ì¬ê³ : 3,000g] = **[7,000g]** (ê¶Œì¥ ë°œì£¼ëŸ‰) |
| **4. ROP (ë°œì£¼ì )** | (ì¼í‰ê· ì†Œì§„ * ë¦¬ë“œíƒ€ì„) + ì•ˆì „ì¬ê³ . ì´ë³´ë‹¤ ì¬ê³ ê°€ ë‚®ìœ¼ë©´ **'ğŸš¨ ë°œì£¼ìš”ë§'** ì•Œë¦¼ |
| **(ëŒ€ì²´)** | AI ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ, ê³¼ê±° 28ì¼ í‰ê·  íŒë§¤ëŸ‰ìœ¼ë¡œ ìë™ ì „í™˜ë˜ì–´ ê³„ì‚°ë©ë‹ˆë‹¤. |

### 2. (AI) ë§ˆì¼€íŒ… ë³´ì¡° (AI ë¹„ì„œ íƒ­)
| ê¸°ëŠ¥ | ì„¤ëª… |
| --- | --- |
| **ì¸ìŠ¤íƒ€ê·¸ë¨ ìƒì„±** | í˜„ì¬ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ í™ë³´ ë¬¸êµ¬ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤. |
| **ìš´ì˜ ë³´ê³ ** | ì¼ì¼ ë§¤ì¶œ, íŒë§¤ ê±´ìˆ˜ ë“±ì„ ìš”ì•½í•˜ì—¬ ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. |

### 3. ê¸°ë³¸ ë°ì´í„° íë¦„
| ë‹¨ê³„ | í•˜ëŠ” ì¼ | ì˜ˆì‹œ |
| --- | --- | --- |
| **1. ì›ë‘ ì…ê³ ** | 'ë°ì´í„° í¸ì§‘' > 'ì¬ê³  ì¼ê´„ìˆ˜ì •' íƒ­ì—ì„œ **[+10,000g]** ìˆ˜ë™ ì…ë ¥ |
| **2. íŒë§¤ ë°œìƒ** | 'ê±°ë˜ ì¶”ê°€' íƒ­ ë˜ëŠ” POSì—ì„œ 'ì•„ë©”ë¦¬ì¹´ë…¸' 1ì” íŒë§¤ (Firestore 'coffee_sales'ì— ê¸°ë¡) |
| **3. ìë™ ì°¨ê°** | ì‹œìŠ¤í…œì´ 'ì•„ë©”ë¦¬ì¹´ë…¸' ë ˆì‹œí”¼(BOM)ë¥¼ ì¡°íšŒí•˜ì—¬ [ì›ë‘: 20g] ì‚¬ìš© í™•ì¸ |
| **4. ì¬ê³  ë°˜ì˜** | 'inventory' DBì˜ 'ì›ë‘' ì¬ê³ ë¥¼ **[-20g]** ìë™ ì°¨ê° (ì¬ê³  ì´ë™ ë¡œê·¸ ê¸°ë¡) |
""")